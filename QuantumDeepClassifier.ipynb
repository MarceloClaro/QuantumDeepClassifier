{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/QqEGG8kDKEQSwCJP1m1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Caminho do arquivo zip carregado\n",
        "zip_path = '/content/melanomas.zip'\n",
        "extract_path = '/content/melanomas'\n",
        "\n",
        "# Extraindo o arquivo zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Listando os arquivos extraídos\n",
        "extracted_files = []\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "extracted_files[:10]  # Mostrando os primeiros 10 arquivos para análise\n"
      ],
      "metadata": {
        "id": "tVVgYLXl54gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Caminho de amostra para imagens\n",
        "sample_image_path = extracted_files[0]\n",
        "\n",
        "# Abrindo e processando a imagem\n",
        "image = Image.open(sample_image_path)\n",
        "image_resized = image.resize((64, 64))  # Redimensionando para 64x64 pixels\n",
        "image_array = np.array(image_resized) / 255.0  # Normalizando os valores entre 0 e 1\n",
        "\n",
        "# Verificando as dimensões e valores da imagem processada\n",
        "image_array.shape, image_array[:5, :5, 0]  # Mostrando a dimensão e parte da matriz para confirmação\n"
      ],
      "metadata": {
        "id": "O2db95Fv6j4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Função para processar imagens\n",
        "def process_images(image_paths, image_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Identificando a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrindo, redimensionando e normalizando a imagem\n",
        "        image = Image.open(image_path).resize(image_size)\n",
        "        image_array = np.array(image) / 255.0\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletando todas as imagens do diretório\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Mostrando o formato dos dados processados\n",
        "processed_images.shape, len(labels)\n"
      ],
      "metadata": {
        "id": "k9dwC_MK6wJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convertendo rótulos de texto para valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mostrando as dimensões dos dados preparados\n",
        "X_train.shape, X_test.shape, len(y_train), len(y_test)\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10  # Número de qubits usados\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    \"\"\"Embed dados clássicos em estados quânticos\"\"\"\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    \"\"\"Modelo quântico parametrizado\"\"\"\n",
        "    data_embedding(features, range(n_qubits))  # Embedding dos dados\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))  # Medida no primeiro qubit\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 3\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)  # Pesos com formato 2D\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Exemplo de execução com os primeiros 10 elementos de uma amostra\n",
        "sample_features = X_train[0][:n_qubits]  # Selecionando exatamente 10 elementos\n",
        "\n",
        "# Certificando-se de que sample_features tem o tamanho correto\n",
        "sample_features = np.pad(sample_features, (0, n_qubits - len(sample_features))) if len(sample_features) < n_qubits else sample_features[:n_qubits]\n",
        "\n",
        "# Executando o circuito\n",
        "print(\"Resultado do circuito:\", circuit(weights, sample_features))\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:50, :n_qubits], y_train[:50]), weights)  # Usando um subset para demonstração\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:50, :n_qubits], y_train[:50])\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avaliação\n",
        "test_cost = cost(weights, X_test[:50, :n_qubits], y_test[:50])\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "22JKgaL78g7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribuição dos rótulos de treinamento:\", np.unique(y_train[:50], return_counts=True))\n",
        "print(\"Distribuição dos rótulos de teste:\", np.unique(y_test[:50], return_counts=True))\n"
      ],
      "metadata": {
        "id": "LjjjZYKCAa1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado confirma que o conjunto de treinamento contém apenas a classe \\( 0 \\), e a classe \\( 1 \\) está ausente. Isso é um problema, pois o modelo não pode aprender a diferenciar entre as classes se apenas uma delas estiver presente.\n",
        "\n",
        "### Soluções Possíveis\n",
        "1. **Verificar o Dataset Original**:\n",
        "   - Certifique-se de que o dataset original contém amostras de todas as classes e que os dados foram carregados corretamente.\n",
        "\n",
        "2. **Balancear o Dataset**:\n",
        "   - Se o dataset original for desequilibrado, tente aumentar ou incluir amostras da classe \\( 1 \\) no conjunto de treinamento.\n",
        "\n",
        "3. **Ajustar a Divisão dos Dados**:\n",
        "   - Reavalie a divisão de dados em treinamento e teste para garantir que ambos contenham todas as classes.\n",
        "\n",
        "4. **Código para Checar o Dataset Original**:\n",
        "   Para verificar a distribuição das classes no dataset completo:\n",
        "   ```python\n",
        "   print(\"Distribuição das classes no conjunto completo:\", np.unique(y_train + y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "5. **Exemplo de Balanceamento Manual**:\n",
        "   Caso o dataset original tenha classes suficientes, você pode aumentar a classe minoritária:\n",
        "   ```python\n",
        "   # Reamostrando manualmente\n",
        "   if len(class_1_indices) > 0:\n",
        "       min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "       balanced_indices = np.hstack((\n",
        "           resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "           resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "       ))\n",
        "\n",
        "       X_train_balanced = X_train[balanced_indices]\n",
        "       y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "       print(\"Distribuição balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "   else:\n",
        "       print(\"A classe 1 não está presente no conjunto original.\")\n",
        "   ```\n",
        "\n",
        "Se o problema persistir, você pode me informar sobre os detalhes do dataset original para que possamos ajustar o pipeline de pré-processamento."
      ],
      "metadata": {
        "id": "6TjjTiZXEVVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as classes presentes no conjunto de treinamento\n",
        "print(\"Distribuição original dos rótulos:\", np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Se não houver dados para uma classe, adicione ou corrija a amostragem\n",
        "if len(class_1_indices) == 0:\n",
        "    print(\"A classe 1 não está presente no conjunto de treinamento.\")\n",
        "else:\n",
        "    # Balancear os dados se ambas as classes estiverem presentes\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    # Balancear X_train e y_train\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribuição balanceada dos rótulos de treinamento:\", np.unique(y_train_balanced, return_counts=True))\n"
      ],
      "metadata": {
        "id": "ScJ3rD3IBbqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reamostrando manualmente\n",
        "if len(class_1_indices) > 0:\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribuição balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "else:\n",
        "    print(\"A classe 1 não está presente no conjunto original.\")\n"
      ],
      "metadata": {
        "id": "AWhMOjvvBo0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado indica que a classe \\( 1 \\) está completamente ausente no dataset, não apenas no conjunto de treinamento, mas aparentemente no conjunto original carregado. Isso pode ser causado por:\n",
        "\n",
        "1. **Problemas no Dataset Original**:\n",
        "   - O dataset fornecido contém apenas amostras da classe \\( 0 \\).\n",
        "2. **Erro na Organização do Dataset**:\n",
        "   - Pode haver uma falha no pré-processamento ou na separação das classes.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "#### 1. Verificar o Dataset Original\n",
        "Certifique-se de que o dataset original contém amostras de ambas as classes. Se houver subdiretórios como \"maligno\" e \"benigno\", confirme que ambos foram processados. Use o seguinte código para listar os diretórios e a contagem de arquivos em cada um:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Listar subdiretórios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diretório: {root}, Número de arquivos: {len(files)}\")\n",
        "```\n",
        "\n",
        "#### 2. Corrigir o Pipeline de Pré-processamento\n",
        "Caso o problema esteja na seleção dos dados, ajuste o pipeline para incluir todas as classes. Certifique-se de que o código está capturando ambas as classes:\n",
        "\n",
        "```python\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribuição\n",
        "print(\"Distribuição das classes no dataset completo:\", np.unique(labels, return_counts=True))\n",
        "```\n",
        "\n",
        "#### 3. Adicionar Amostras da Classe Minoritária\n",
        "Se o dataset original é desequilibrado, você pode adicionar manualmente mais amostras da classe \\( 1 \\) (maligno). Isso pode ser feito coletando mais dados ou duplicando algumas amostras existentes para balancear.\n",
        "\n",
        "Se precisar de ajuda para investigar o dataset ou ajustar o pipeline, avise!"
      ],
      "metadata": {
        "id": "HNXMMkQMEIFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar subdiretórios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diretório: {root}, Número de arquivos: {len(files)}\")\n"
      ],
      "metadata": {
        "id": "lYLT1udwB0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribuição\n",
        "print(\"Distribuição das classes no dataset completo:\", np.unique(labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "lqaO9eMjB-63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos uma distribuição equilibrada no dataset completo:\n",
        "\n",
        "- **500 amostras da classe \"benigno\"**.\n",
        "- **500 amostras da classe \"maligno\"**.\n",
        "\n",
        "Isso confirma que ambas as classes estão presentes e foram corretamente processadas. O problema anterior foi causado por um desequilíbrio ou erro na seleção dos dados para treinamento.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. **Codificar os Rótulos**:\n",
        "   - Converter os rótulos `['benigno', 'maligno']` para valores numéricos \\(0\\) e \\(1\\).\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "   # Codificar os rótulos\n",
        "   label_encoder = LabelEncoder()\n",
        "   encoded_labels = label_encoder.fit_transform(labels)\n",
        "   print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n",
        "   ```\n",
        "\n",
        "2. **Dividir o Dataset**:\n",
        "   - Separar os dados em conjuntos de treinamento e teste de forma balanceada.\n",
        "   \n",
        "   ```python\n",
        "   from sklearn.model_selection import train_test_split\n",
        "\n",
        "   # Dividir os dados\n",
        "   X_train, X_test, y_train, y_test = train_test_split(\n",
        "       processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "       encoded_labels,\n",
        "       test_size=0.2,\n",
        "       stratify=encoded_labels,  # Garantir balanceamento\n",
        "       random_state=42\n",
        "   )\n",
        "   print(\"Distribuição dos rótulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "   print(\"Distribuição dos rótulos no teste:\", np.unique(y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "3. **Treinar o Modelo Quântico**:\n",
        "   - Use os dados balanceados para treinar o modelo quântico e avaliar o desempenho.\n",
        "\n",
        "Deseja que eu implemente essas etapas ou passe direto para o treinamento?"
      ],
      "metadata": {
        "id": "jsWIBtxtDvUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar os rótulos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "F53QU2yYCJSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "    encoded_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=encoded_labels,  # Garantir balanceamento\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Distribuição dos rótulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Distribuição dos rótulos no teste:\", np.unique(y_test, return_counts=True))\n"
      ],
      "metadata": {
        "id": "SbRa_3cJCTO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora o dataset está devidamente balanceado:\n",
        "\n",
        "- **Treinamento**: 400 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "- **Teste**: 100 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "\n",
        "Com os dados preparados, podemos seguir para o treinamento do modelo quântico.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. **Treinar o Modelo Quântico**:\n",
        "   - Ajustar os pesos do circuito para minimizar a função de custo.\n",
        "   - Utilizar o conjunto de treinamento balanceado (\\( X\\_train \\) e \\( y\\_train \\)).\n",
        "\n",
        "2. **Avaliar o Modelo**:\n",
        "   - Calcular a precisão e a perda no conjunto de teste (\\( X\\_test \\) e \\( y\\_test \\)).\n",
        "\n",
        "### Código para Treinamento\n",
        "Aqui está o código atualizado para treinar e avaliar o modelo:\n",
        "\n",
        "```python\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n",
        "```\n",
        "\n",
        "### Explicação\n",
        "1. **Função de Custo**:\n",
        "   - Calcula o erro quadrático médio entre a previsão do circuito e os rótulos reais.\n",
        "2. **Otimização**:\n",
        "   - Usa Adam para ajustar os pesos do circuito.\n",
        "3. **Avaliação**:\n",
        "   - Mede o custo no conjunto de teste para verificar a generalização.\n",
        "\n",
        "Deseja executar este código ou ajustar algum parâmetro antes de seguir?"
      ],
      "metadata": {
        "id": "JEwGaoJzDhsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "# Configurando o gráfico\n",
        "plt.ion()  # Ativando o modo interativo\n",
        "fig, ax = plt.subplots()\n",
        "line1, = ax.plot([], [], label='Custo de Treinamento', color='blue')\n",
        "line2, = ax.plot([], [], label='Custo de Teste', color='orange')\n",
        "ax.set_xlim(0, steps)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlabel(\"Passo\")\n",
        "ax.set_ylabel(\"Custo\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Treinamento\n",
        "start_time = time.time()\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    train_cost = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "    test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "\n",
        "    # Armazenar custos\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Atualizar gráfico\n",
        "    line1.set_data(range(step + 1), train_costs)\n",
        "    line2.set_data(range(step + 1), test_costs)\n",
        "    ax.set_ylim(0, max(train_costs + test_costs) * 1.1)  # Ajustar limites do gráfico dinamicamente\n",
        "    clear_output(wait=True)\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)\n",
        "\n",
        "    # Print no console\n",
        "    print(f\"Passo {step}/{steps} | Custo de Treinamento: {train_cost:.4f} | Custo de Teste: {test_cost:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Treinamento concluído em {end_time - start_time:.2f} segundos.\")\n",
        "plt.ioff()  # Desativar o modo interativo\n",
        "plt.show()\n",
        "\n",
        "# Avaliação Final no Conjunto de Teste\n",
        "final_test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "1TylwODwCjzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred = [round(float(circuit(weights, x))) for x in X_test[:, :n_qubits]]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "69mk3xhTdn-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Relatório de classificação\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Benigno\", \"Maligno\"]))\n"
      ],
      "metadata": {
        "id": "Flu_IGkneQT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Parâmetros iniciais para testes\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Pesos aleatórios\n",
        "features = np.random.random(n_qubits)  # Exemplo de entrada\n",
        "\n",
        "# Testando o circuito\n",
        "output = circuit(weights, features)\n",
        "print(f\"Saída do circuito: {output}\")\n"
      ],
      "metadata": {
        "id": "Pmx4JWJLe0lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configuração do treinamento\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Inicialização dos pesos aleatórios\n",
        "opt = AdamOptimizer(stepsize=0.01)  # Otimizador Adam\n",
        "steps = 50  # Número de iterações\n",
        "\n",
        "# Dados simulados para teste\n",
        "X_train = np.random.random((100, n_qubits))  # 100 amostras, cada uma com 12 qubits\n",
        "y_train = np.random.choice([0, 1], size=100)  # Rótulos binários simulados\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)  # Atualizar pesos\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado final\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final após {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "ifCUQ5oBgKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane.numpy as pnp  # Usar NumPy do PennyLane para suporte a gradientes\n",
        "\n",
        "# Configuração dos pesos ajustada\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Otimizador com taxa de aprendizado maior\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "\n",
        "# Treinamento com ajustes\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final após {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "lq9f9d4ioAvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões com transformação para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "hH-ZFY7KsgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões com transformação para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "FHYzN1xKs14i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado com melhorias para aumentar a expressividade do circuito, regularização na função de custo e validação em dados de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo com regularização L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configuração do treinamento\n",
        "n_layers = 6  # Aumentar o número de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o número de iterações\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2%}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### O Que Foi Ajustado\n",
        "1. **Camadas Adicionais no Circuito**:\n",
        "   - O número de camadas foi aumentado para 6 para maior expressividade.\n",
        "2. **Regularização L2**:\n",
        "   - Adicionada regularização à função de custo para melhorar a estabilidade do modelo.\n",
        "3. **Mais Iterações**:\n",
        "   - O número de passos foi aumentado para 100 para permitir melhor convergência.\n",
        "4. **Avaliação no Conjunto de Teste**:\n",
        "   - Adicionado código para calcular a acurácia no conjunto de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "1. **Execute o Código**:\n",
        "   - Observe os custos e as acurácias no conjunto de treinamento e teste.\n",
        "2. **Analise os Resultados**:\n",
        "   - Verifique se há sinais de overfitting (acurácia no treino muito maior que no teste).\n",
        "\n",
        "Se precisar de mais ajustes, estou à disposição! 😊"
      ],
      "metadata": {
        "id": "IS2WKZ4burMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo com regularização L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configuração do treinamento\n",
        "n_layers = 6  # Aumentar o número de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o número de iterações\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "aBdq7hhAtuWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código implementa um pipeline quântico-clássico para classificação binária usando circuitos quânticos e o otimizador Adam para ajustar os parâmetros. Aqui está uma explicação detalhada do processo quântico envolvido:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Dispositivo Quântico**\n",
        "```python\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "```\n",
        "- **Descrição**: Um dispositivo quântico simulado, configurado para usar 12 qubits.\n",
        "- **Papel**: Serve como o \"computador quântico virtual\" onde os circuitos serão executados.\n",
        "- **Simulação Clássica**: O dispositivo `default.qubit` é um simulador baseado em estado vetorial.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Definição do Circuito**\n",
        "```python\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "\n",
        "#### a. **Embedding dos Dados**\n",
        "```python\n",
        "for i in range(n_qubits):\n",
        "    qml.RY(features[i], wires=i)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Os dados clássicos (features) são mapeados para estados quânticos usando rotações \\( RY \\).\n",
        "  - Cada feature é usada para parametrizar uma rotação em torno do eixo \\( Y \\) para o qubit correspondente.\n",
        "- **Papel**:\n",
        "  - Cria uma representação quântica dos dados.\n",
        "\n",
        "#### b. **Camadas Parametrizadas**\n",
        "```python\n",
        "qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Aplica camadas de entrelaçamento entre os qubits, usando parâmetros treináveis (\\( weights \\)).\n",
        "  - Permite que o modelo quântico capture interdependências complexas entre as features.\n",
        "- **Papel**:\n",
        "  - Adiciona expressividade ao circuito, permitindo que ele represente funções mais complexas.\n",
        "\n",
        "#### c. **Medida**\n",
        "```python\n",
        "return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Mede a expectativa do operador \\( Z \\) no primeiro qubit.\n",
        "  - Retorna um valor contínuo no intervalo \\([-1, 1]\\).\n",
        "- **Papel**:\n",
        "  - Converte o estado quântico final em um valor clássico utilizável.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Função de Custo**\n",
        "```python\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula o erro quadrático médio (\\( MSE \\)) entre as previsões do circuito e os rótulos reais.\n",
        "  - Adiciona um termo de regularização L2 para penalizar pesos altos e evitar overfitting.\n",
        "- **Papel**:\n",
        "  - Orienta o treinamento para ajustar os pesos e minimizar a discrepância entre previsões e rótulos.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Treinamento**\n",
        "```python\n",
        "weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - O otimizador Adam ajusta os pesos do circuito quântico, minimizando a função de custo.\n",
        "- **Papel**:\n",
        "  - Integra o aprendizado quântico ao pipeline clássico, otimizando os parâmetros do circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Classificação Binária**\n",
        "```python\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Converte as previsões contínuas do circuito (\\([-1, 1]\\)) em rótulos binários (\\( -1, 1 \\)) usando uma função de ativação baseada em threshold.\n",
        "- **Papel**:\n",
        "  - Permite que o modelo faça classificações compatíveis com os rótulos ajustados.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Métricas de Desempenho**\n",
        "```python\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula a proporção de previsões corretas.\n",
        "- **Papel**:\n",
        "  - Avalia o desempenho do modelo no conjunto de treinamento e teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo do Processo Quântico\n",
        "1. **Embedding**:\n",
        "   - Os dados clássicos são mapeados para estados quânticos usando rotações \\( RY \\).\n",
        "2. **Camadas Parametrizadas**:\n",
        "   - O circuito aprende padrões complexos nos dados ajustando os pesos.\n",
        "3. **Medida**:\n",
        "   - A expectativa do operador \\( Z \\) no primeiro qubit traduz o estado quântico final em um valor clássico.\n",
        "4. **Treinamento**:\n",
        "   - A função de custo e o otimizador ajustam os pesos para melhorar as previsões.\n",
        "5. **Classificação**:\n",
        "   - O valor contínuo retornado pelo circuito é transformado em rótulos binários.\n",
        "\n",
        "Se precisar de mais detalhes ou ajustes no modelo, estou à disposição! 😊"
      ],
      "metadata": {
        "id": "Ic9V71bYvaCY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_RiqRv-vXW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}