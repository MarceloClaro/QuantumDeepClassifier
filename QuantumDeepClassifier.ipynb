{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2J9wVr14Zw0upSD/PNxji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explicação dos Comandos de Instalação**\n",
        "\n",
        "Os comandos listados utilizam o gerenciador de pacotes **pip** para instalar bibliotecas específicas que são usadas em computação quântica, aprendizado de máquina e visualização de dados. Abaixo, explico cada uma delas:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. `!pip install qiskit`**\n",
        "- **O que é o Qiskit?**\n",
        "  - O Qiskit é uma biblioteca de código aberto para computação quântica desenvolvida pela IBM. Ele permite:\n",
        "    - Criar, simular e executar circuitos quânticos.\n",
        "    - Realizar experimentos em computadores quânticos reais da IBM Quantum ou simuladores locais.\n",
        "    - Trabalhar com algoritmos quânticos, como **VQE**, **QAOA** e **Shor**.\n",
        "\n",
        "- **Principais Módulos do Qiskit:**\n",
        "  - **`qiskit.circuit`**: Criação de circuitos quânticos.\n",
        "  - **`qiskit.aer`**: Simulação de circuitos quânticos.\n",
        "  - **`qiskit.ibmq`**: Conexão com dispositivos quânticos reais na nuvem.\n",
        "  - **`qiskit.visualization`**: Visualização de circuitos quânticos.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver aplicações quânticas em áreas como criptografia, otimização, química e aprendizado de máquina.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `!pip install pennylane`**\n",
        "- **O que é o PennyLane?**\n",
        "  - O PennyLane é uma biblioteca de código aberto para **computação quântica diferencial**. Ele integra computação quântica com aprendizado de máquina (AM) e frameworks como PyTorch, TensorFlow e NumPy.\n",
        "\n",
        "- **Principais Recursos do PennyLane:**\n",
        "  - Suporte a **diferenciação automática**: Permite calcular gradientes de circuitos quânticos para ajustar parâmetros durante o treinamento.\n",
        "  - Compatibilidade com dispositivos quânticos reais e simuladores.\n",
        "  - Ferramentas para implementar algoritmos híbridos (quânticos e clássicos).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Criar modelos híbridos que combinam redes neurais e circuitos quânticos.\n",
        "  - Aplicar aprendizado de máquina quântico em tarefas como classificação, regressão e redução de dimensionalidade.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `!pip install tensorflow-quantum`**\n",
        "- **O que é o TensorFlow Quantum (TFQ)?**\n",
        "  - O TensorFlow Quantum é uma extensão do TensorFlow que facilita a integração de circuitos quânticos com aprendizado de máquina clássico.\n",
        "  - Ele é desenvolvido pela Google AI e permite:\n",
        "    - Construir e treinar modelos híbridos (quânticos e clássicos).\n",
        "    - Simular circuitos quânticos dentro do fluxo de trabalho do TensorFlow.\n",
        "\n",
        "- **Principais Recursos do TFQ:**\n",
        "  - **Integração com TensorFlow**: Usado com outras APIs TensorFlow, como `tf.keras` e `tf.data`.\n",
        "  - **Diferenciação automática** para parâmetros de circuitos quânticos.\n",
        "  - **Simuladores de dispositivos quânticos** otimizados para desempenho.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver modelos híbridos para tarefas de aprendizado supervisionado, não supervisionado e reforçado.\n",
        "  - Aplicar computação quântica em AM em escala usando a infraestrutura do TensorFlow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `!pip install matplotlib`**\n",
        "- **O que é o Matplotlib?**\n",
        "  - O Matplotlib é uma biblioteca de Python usada para criar gráficos estáticos, interativos e animados.\n",
        "\n",
        "- **Principais Recursos do Matplotlib:**\n",
        "  - Criação de gráficos de linha, dispersão, histogramas, barras e muito mais.\n",
        "  - Personalização total de estilos, rótulos, títulos e cores.\n",
        "  - Compatibilidade com notebooks interativos (Jupyter Notebook, Google Colab).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Visualizar resultados de simulações e treinamentos de modelos quânticos e clássicos.\n",
        "  - Interpretar dados e métricas por meio de gráficos.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `!pip install pillow`**\n",
        "- **O que é o Pillow?**\n",
        "  - O Pillow (ou PIL, Python Imaging Library) é uma biblioteca de manipulação de imagens.\n",
        "\n",
        "- **Principais Recursos do Pillow:**\n",
        "  - Abrir, modificar e salvar imagens em vários formatos (JPEG, PNG, BMP, etc.).\n",
        "  - Redimensionar, cortar, converter para escala de cinza e normalizar imagens.\n",
        "  - Integrar pipelines de visão computacional.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Pré-processar dados de imagens antes de usá-los em modelos quânticos ou clássicos.\n",
        "  - Trabalhar com datasets de imagens em tarefas de classificação ou detecção de objetos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo e Propósito Geral**\n",
        "Esses pacotes combinados permitem a construção de modelos de aprendizado de máquina quânticos e híbridos. Com eles, você pode:\n",
        "1. **Simular e executar circuitos quânticos**: Usando Qiskit e PennyLane.\n",
        "2. **Integrar computação quântica e aprendizado de máquina clássico**: Com PennyLane e TensorFlow Quantum.\n",
        "3. **Pré-processar e visualizar dados**: Usando Matplotlib e Pillow.\n",
        "\n"
      ],
      "metadata": {
        "id": "JbK2j_xVL92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Completo para Carregar, Visualizar e Salvar as Imagens no Drive\n",
        "\n",
        "Aqui está o código ajustado para solicitar o arquivo `melanomas.zip`, organizar, visualizar as imagens das classes, e salvar os dados processados na pasta \"quantum\" no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Código Ajustado**\n",
        "\n",
        "```python\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo não encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extraídos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Número total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extraídos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Função para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padrão para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Passo a Passo do Código**\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para armazenar os dados processados.\n",
        "2. **Solicitar o Arquivo `melanomas.zip`**:\n",
        "   - O código pede ao usuário o caminho do arquivo ZIP no Drive.\n",
        "   - Exemplo: `/content/drive/My Drive/melanomas.zip`.\n",
        "3. **Extrair Imagens**:\n",
        "   - As imagens são extraídas para a pasta temporária `/content/melanomas`.\n",
        "   - Apenas arquivos com extensões `.jpg` e `.png` são incluídos.\n",
        "4. **Visualizar Imagens por Classe**:\n",
        "   - As imagens são agrupadas com base no nome das subpastas (representando as classes).\n",
        "   - As primeiras `n` imagens de cada classe são exibidas em gráficos.\n",
        "5. **Salvar Imagens no Google Drive**:\n",
        "   - As imagens são redimensionadas para 64x64 pixels.\n",
        "   - Elas são organizadas em pastas no Drive, em `My Drive/quantum/<nome_da_classe>`.\n",
        "6. **Exibir Imagens Redimensionadas**:\n",
        "   - Após salvar, as imagens redimensionadas são exibidas novamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Exemplo de Execução**\n",
        "- O código irá:\n",
        "  - Solicitar o arquivo `melanomas.zip`.\n",
        "  - Extrair e organizar as imagens por classe.\n",
        "  - Exibir as primeiras 5 imagens de cada classe.\n",
        "  - Salvar as imagens redimensionadas no Google Drive para posterior uso.\n",
        "\n"
      ],
      "metadata": {
        "id": "jFku01OHyA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo não encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extraídos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Número total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extraídos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Função para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padrão para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n"
      ],
      "metadata": {
        "id": "kMS-AgHXM7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sim, podemos ajustar o código para:\n",
        "\n",
        "1. **Visualizar a imagem original e redimensionada**.\n",
        "2. **Salvar os dados redimensionados em um DataFrame e exportá-lo para um arquivo, se necessário.**\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado para Visualização e Criação de DataFrame\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Função para processar e redimensionar imagens\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "    \n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "sample_image_path = extracted_files[0]\n",
        "processed_image = process_and_visualize_image(sample_image_path)\n",
        "\n",
        "# Criar um DataFrame com os dados redimensionados\n",
        "def create_dataframe(image_paths, resize_to=(64, 64)):\n",
        "    \"\"\"Processa imagens e cria um DataFrame com arrays normalizados\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image_resized = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image_resized).flatten() / 255.0  # Achatar a matriz\n",
        "        \n",
        "        # Obter o rótulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "    \n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "    return df\n",
        "\n",
        "# Criar o DataFrame com todas as imagens\n",
        "df = create_dataframe(extracted_files)\n",
        "\n",
        "# Visualizar parte do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "output_path = \"processed_images.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"DataFrame salvo em: {output_path}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explicação do Código\n",
        "\n",
        "1. **Visualização da Imagem**:\n",
        "   - A função `process_and_visualize_image` exibe a imagem original e a redimensionada lado a lado.\n",
        "\n",
        "2. **Criação do DataFrame**:\n",
        "   - Cada imagem é convertida para um array 1D (achatar a matriz).\n",
        "   - Os arrays são armazenados como linhas no DataFrame, com uma coluna adicional para os rótulos das classes.\n",
        "\n",
        "3. **Exportação para CSV**:\n",
        "   - O DataFrame é salvo em um arquivo CSV (`processed_images.csv`), para ser reutilizado posteriormente.\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "- Você verá a imagem original e redimensionada para confirmar o processo de redimensionamento.\n",
        "- O DataFrame conterá os dados de todas as imagens redimensionadas e seus rótulos de classe.\n",
        "- O arquivo CSV permitirá reutilizar os dados sem necessidade de processar as imagens novamente.\n",
        "\n",
        "Teste o código e informe se precisar de mais ajustes! 😊"
      ],
      "metadata": {
        "id": "6PgjAaxZyotH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Função para processar e visualizar uma única imagem\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "\n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "if len(extracted_files) > 0:\n",
        "    sample_image_path = extracted_files[0]\n",
        "    processed_image = process_and_visualize_image(sample_image_path)\n",
        "else:\n",
        "    print(\"Nenhuma imagem foi encontrada para processamento.\")\n",
        "\n",
        "# Função para processar todas as imagens e criar um DataFrame\n",
        "def create_dataframe_and_save_images(image_paths, resize_to=(64, 64), save_dir=output_dir):\n",
        "    \"\"\"Processa imagens, cria um DataFrame e salva imagens redimensionadas\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image).flatten() / 255.0  # Achatar a matriz\n",
        "\n",
        "        # Obter o rótulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame na pasta \"quantum\"\n",
        "    df_output_path = os.path.join(save_dir, \"processed_images.csv\")\n",
        "    df.to_csv(df_output_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {df_output_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar imagens e salvar no Google Drive\n",
        "if len(extracted_files) > 0:\n",
        "    df = create_dataframe_and_save_images(extracted_files)\n",
        "    print(\"Primeiras linhas do DataFrame:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Nenhuma imagem encontrada para criar o DataFrame.\")\n"
      ],
      "metadata": {
        "id": "aw1NqaInzH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Ajustado para Visualizar, Normalizar Imagens e Salvar no Drive\n",
        "\n",
        "Este é o código modificado para salvar o DataFrame e imagens no Google Drive dentro da pasta \"quantum\". Ele processa as imagens, exibe as visualizações necessárias, cria um DataFrame e salva os resultados.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Função para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "    \n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normalização\n",
        "        \n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "        \n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diretório\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualização e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Função para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "    \n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explicação do Código**\n",
        "\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para salvar os arquivos na pasta \"quantum\".\n",
        "\n",
        "2. **Visualização e Processamento das Imagens**:\n",
        "   - Processa as imagens para redimensioná-las a um tamanho padrão de \\(64 \\times 64\\).\n",
        "   - Normaliza os valores dos pixels para o intervalo \\([0, 1]\\).\n",
        "   - Exibe as imagens originais e redimensionadas lado a lado.\n",
        "\n",
        "3. **Salvar Imagens Processadas**:\n",
        "   - As imagens redimensionadas são salvas na pasta \"quantum\", organizadas por subpastas das classes.\n",
        "\n",
        "4. **Criação do DataFrame**:\n",
        "   - Cria um DataFrame com:\n",
        "     - Vetores achatados das imagens (uma linha por imagem).\n",
        "     - Rótulos das classes como uma coluna separada.\n",
        "   - Salva o DataFrame no formato CSV na pasta \"quantum\".\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualização de Imagens**:\n",
        "   - As imagens originais e redimensionadas são exibidas no Colab.\n",
        "\n",
        "2. **Pasta `quantum` no Drive**:\n",
        "   - Contém subpastas para cada classe, com as imagens redimensionadas salvas.\n",
        "   - Um arquivo `processed_images_with_labels.csv` com os arrays das imagens e os rótulos.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - Um DataFrame com as imagens processadas e normalizadas, incluindo os rótulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "me-sYB307FFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Função para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normalização\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diretório\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualização e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Função para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "rk1TQzrJ6HJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado para salvar na pasta `quantum` no Google Drive e incluir todas as funcionalidades mencionadas: visualização, normalização, divisão dos dados e salvamento em DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo rótulos de texto para valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualização de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar rótulo numérico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os rótulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os rótulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Este Código Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Monta o Google Drive para salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "2. **Processamento de Rótulos e Dados**:\n",
        "   - Converte rótulos textuais em valores numéricos usando `LabelEncoder`.\n",
        "   - Redimensiona e achata as imagens processadas para vetores 1D.\n",
        "\n",
        "3. **Divisão de Dados**:\n",
        "   - Divide os dados em conjuntos de treino e teste usando `train_test_split`.\n",
        "\n",
        "4. **Visualização**:\n",
        "   - Exibe algumas imagens do conjunto de treino com seus rótulos decodificados.\n",
        "   - Mostra parte das matrizes normalizadas de cada imagem.\n",
        "\n",
        "5. **Criação de DataFrames**:\n",
        "   - Cria DataFrames para os conjuntos de treino e teste.\n",
        "   - Adiciona os rótulos decodificados como uma coluna.\n",
        "\n",
        "6. **Salvamento**:\n",
        "   - Salva os DataFrames como arquivos CSV (`train_data.csv` e `test_data.csv`) na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualizações**:\n",
        "   - Exibição de 5 imagens do conjunto de treino com seus rótulos decodificados.\n",
        "   - Matrizes normalizadas das imagens para análise.\n",
        "\n",
        "2. **Arquivos CSV**:\n",
        "   - Arquivos `train_data.csv` e `test_data.csv` contendo os dados processados e os rótulos, salvos na pasta `quantum`.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - DataFrames contendo:\n",
        "     - Colunas com os valores achatados dos pixels.\n",
        "     - Coluna `label` com os rótulos das imagens.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TROm3P5W8Isd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo rótulos de texto para valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualização de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar rótulo numérico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os rótulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os rótulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado para salvar os resultados no Google Drive na pasta **quantum**, com todas as explicações e etapas necessárias para análise e visualização avançada:\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribuição das Previsões por Classe\")\n",
        "    plt.xlabel(\"Previsão\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar rótulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simulação de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipotético para rodar o código:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com rótulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Esse Código Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Salva os arquivos na pasta `quantum` no Google Drive.\n",
        "\n",
        "2. **Processamento Quântico**:\n",
        "   - Cada amostra de imagem é normalizada, redimensionada e processada por um circuito quântico.\n",
        "   - O circuito aplica rotações \\( RY \\) para incorporar os dados e usa camadas de entanglement para capturar correlações.\n",
        "\n",
        "3. **Divisão de Dados**:\n",
        "   - As imagens e os rótulos são divididos em conjuntos de treino e teste.\n",
        "\n",
        "4. **Criação de DataFrames**:\n",
        "   - Cria DataFrames para treino e teste contendo:\n",
        "     - `features`: Dados normalizados e achatados.\n",
        "     - `label`: Classe da amostra.\n",
        "     - `prediction`: Saída do circuito quântico.\n",
        "     - `residual`: Diferença entre previsão e rótulo.\n",
        "\n",
        "5. **Salvamento de Resultados**:\n",
        "   - Salva os DataFrames (`train_data_quantum.csv`, `test_data_quantum.csv`) na pasta `quantum`.\n",
        "\n",
        "6. **Visualização**:\n",
        "   - Exibe histogramas das previsões para cada classe.\n",
        "   - Mostra o circuito quântico usado para processar algumas amostras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `train_data_quantum.csv` e `test_data_quantum.csv` contendo os resultados processados.\n",
        "\n",
        "2. **Visualizações**:\n",
        "   - Histogramas mostrando a distribuição das previsões por classe.\n",
        "   - Circuitos desenhados para algumas amostras, mostrando as rotações \\( RY \\) e as camadas de entanglement.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VemAfafo_VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribuição das Previsões por Classe\")\n",
        "    plt.xlabel(\"Previsão\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar rótulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simulação de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipotético para rodar o código:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com rótulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o **código ajustado para salvar todos os resultados na pasta \"quantum\"** do Google Drive. Ele inclui as etapas de treinamento, visualização e análise de resíduos, com os resultados salvos no formato adequado.\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Aumentar o número de camadas para maior expressividade\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicialização de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configuração do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "\n",
        "# Ajustando os dados para o número de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Avaliação final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previsões\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Criação do DataFrame com resíduos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualizações\n",
        "\n",
        "# 1. Gráfico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(steps), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(steps), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolução do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gráfico de dispersão (predição vs rótulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispersão: Previsão vs Rótulo\")\n",
        "plt.xlabel(\"Rótulo Verdadeiro\")\n",
        "plt.ylabel(\"Previsão\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de resíduos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribuição dos Resíduos\")\n",
        "plt.xlabel(\"Resíduo\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explicação do Código\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Os resultados são salvos na pasta `quantum` dentro do Google Drive.\n",
        "\n",
        "2. **Treinamento e Custo**:\n",
        "   - O modelo ajusta os pesos com base no custo médio quadrático, registrado para cada passo.\n",
        "\n",
        "3. **DataFrame com Resultados**:\n",
        "   - Inclui previsões, resíduos, e recursos (features) para análise posterior.\n",
        "   - Salvo como `quantum_model_results.csv`.\n",
        "\n",
        "4. **Visualizações**:\n",
        "   - **Gráfico de custo**: Mostra a evolução do custo de treino e teste durante o treinamento.\n",
        "   - **Dispersão**: Indica a correspondência entre os rótulos reais e as previsões.\n",
        "   - **Histograma de resíduos**: Analisa a distribuição dos erros das previsões.\n",
        "\n",
        "5. **Salvamento de Gráficos**:\n",
        "   - Cada gráfico é salvo no Google Drive na pasta `quantum` como imagem (`.png`).\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `quantum_model_results.csv`\n",
        "   - `training_costs.png`\n",
        "   - `scatter_predictions.png`\n",
        "   - `residuals_histogram.png`\n",
        "\n",
        "2. **Insights**:\n",
        "   - **Redução do Custo**: A curva de custo deve diminuir ao longo das iterações.\n",
        "   - **Relação Previsão-Rótulo**: Idealmente, os pontos de dispersão devem estar próximos da linha \\( y = x \\).\n",
        "   - **Resíduos Pequenos**: Um bom modelo terá resíduos concentrados próximos a 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "doIDRTIDAane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Aumentar o número de camadas para maior expressividade\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicialização de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configuração do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "\n",
        "# Ajustando os dados para o número de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Avaliação final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previsões\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Criação do DataFrame com resíduos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualizações\n",
        "\n",
        "# 1. Gráfico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(steps), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(steps), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolução do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gráfico de dispersão (predição vs rótulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispersão: Previsão vs Rótulo\")\n",
        "plt.xlabel(\"Rótulo Verdadeiro\")\n",
        "plt.ylabel(\"Previsão\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de resíduos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribuição dos Resíduos\")\n",
        "plt.xlabel(\"Resíduo\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pJzLNFF-UlyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Ajustado com Early Stopping, Data Augmentation, e Armazenamento no Google Drive\n",
        "\n",
        "O código a seguir inclui:\n",
        "1. **Early Stopping**: Parar o treinamento quando a melhoria no custo for insignificante.\n",
        "2. **Data Augmentation**: Balancear os embeddings criando variações nos dados.\n",
        "3. **Armazenamento dos Resultados no Google Drive**: Salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "---\n",
        "\n",
        "### Código\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Circuito\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_cost = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def check(self, current_cost):\n",
        "        if self.best_cost is None or current_cost < self.best_cost - self.delta:\n",
        "            self.best_cost = current_cost\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "# Data Augmentation\n",
        "def augment_data(X, y):\n",
        "    classes = np.unique(y)\n",
        "    max_size = max([np.sum(y == c) for c in classes])\n",
        "    X_aug, y_aug = [], []\n",
        "    for c in classes:\n",
        "        X_class = X[y == c]\n",
        "        X_resampled = resample(X_class, replace=True, n_samples=max_size, random_state=42)\n",
        "        X_aug.append(X_resampled)\n",
        "        y_aug += [c] * max_size\n",
        "    return np.vstack(X_aug), np.array(y_aug)\n",
        "\n",
        "# Dados ajustados para número de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "y_train_aug, y_train_aug = augment_data(X_train_resized, y_train)\n",
        "\n",
        "# Treinamento\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "early_stopper = EarlyStopping(patience=5, delta=0.0001)\n",
        "train_costs, test_costs = [], []\n",
        "\n",
        "for step in range(50):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    print(f\"Step {step} | Train Cost: {train_cost:.4f} | Test Cost: {test_cost:.4f}\")\n",
        "    if early_stopper.check(train_cost):\n",
        "        print(f\"Early stopping at step {step}\")\n",
        "        break\n",
        "\n",
        "# Avaliação final\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar resultados\n",
        "df_results.to_csv(os.path.join(output_dir, \"quantum_model_results.csv\"), index=False)\n",
        "print(\"Resultados salvos na pasta quantum.\")\n",
        "\n",
        "# Visualizações\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_costs, label=\"Train Cost\", color=\"blue\")\n",
        "plt.plot(test_costs, label=\"Test Cost\", color=\"orange\")\n",
        "plt.title(\"Training Cost with Early Stopping\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_cost.png\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, label=\"Train\", alpha=0.7, color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, label=\"Test\", alpha=0.7, color=\"orange\")\n",
        "plt.title(\"Predictions vs True Labels\")\n",
        "plt.xlabel(\"True Labels\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"predictions_scatter.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Ajustes Incluídos\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Monitora o custo de treinamento.\n",
        "   - Interrompe o treinamento se a melhoria for insignificante por várias iterações.\n",
        "\n",
        "2. **Data Augmentation**:\n",
        "   - Balanceia o conjunto de dados aumentando o número de amostras para a classe minoritária.\n",
        "\n",
        "3. **Salvamento no Google Drive**:\n",
        "   - Resultados salvos em `quantum_model_results.csv`.\n",
        "   - Gráficos salvos como imagens (`.png`).\n",
        "\n",
        "---\n",
        "\n",
        "### Arquivos Gerados\n",
        "\n",
        "- `quantum_model_results.csv`: Resultados do modelo.\n",
        "- `training_cost.png`: Gráfico do custo.\n",
        "- `predictions_scatter.png`: Gráfico de dispersão.\n",
        "\n",
        "### Benefícios\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Evita treinamento desnecessário, economizando recursos.\n",
        "\n",
        "2. **Data Augmentation**:\n",
        "   - Resolve o problema de classes desbalanceadas.\n",
        "\n",
        "3. **Resultados Salvos**:\n",
        "   - Os arquivos podem ser acessados posteriormente para análise."
      ],
      "metadata": {
        "id": "ztUtdHcjEZI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Circuito\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_cost = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def check(self, current_cost):\n",
        "        if self.best_cost is None or current_cost < self.best_cost - self.delta:\n",
        "            self.best_cost = current_cost\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "# Data Augmentation\n",
        "def augment_data(X, y):\n",
        "    classes = np.unique(y)\n",
        "    max_size = max([np.sum(y == c) for c in classes])\n",
        "    X_aug, y_aug = [], []\n",
        "    for c in classes:\n",
        "        X_class = X[y == c]\n",
        "        X_resampled = resample(X_class, replace=True, n_samples=max_size, random_state=42)\n",
        "        X_aug.append(X_resampled)\n",
        "        y_aug += [c] * max_size\n",
        "    return np.vstack(X_aug), np.array(y_aug)\n",
        "\n",
        "# Dados ajustados para número de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "y_train_aug, y_train_aug = augment_data(X_train_resized, y_train)\n",
        "\n",
        "# Treinamento\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "early_stopper = EarlyStopping(patience=5, delta=0.0001)\n",
        "train_costs, test_costs = [], []\n",
        "\n",
        "for step in range(50):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    print(f\"Step {step} | Train Cost: {train_cost:.4f} | Test Cost: {test_cost:.4f}\")\n",
        "    if early_stopper.check(train_cost):\n",
        "        print(f\"Early stopping at step {step}\")\n",
        "        break\n",
        "\n",
        "# Avaliação final\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar resultados\n",
        "df_results.to_csv(os.path.join(output_dir, \"quantum_model_results.csv\"), index=False)\n",
        "print(\"Resultados salvos na pasta quantum.\")\n",
        "\n",
        "# Visualizações\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_costs, label=\"Train Cost\", color=\"blue\")\n",
        "plt.plot(test_costs, label=\"Test Cost\", color=\"orange\")\n",
        "plt.title(\"Training Cost with Early Stopping\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_cost.png\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, label=\"Train\", alpha=0.7, color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, label=\"Test\", alpha=0.7, color=\"orange\")\n",
        "plt.title(\"Predictions vs True Labels\")\n",
        "plt.xlabel(\"True Labels\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"predictions_scatter.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "otA1OMV__y0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:50, :n_qubits], y_train[:50]), weights)  # Usando um subset para demonstração\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:50, :n_qubits], y_train[:50])\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avaliação\n",
        "test_cost = cost(weights, X_test[:50, :n_qubits], y_test[:50])\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "22JKgaL78g7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribuição dos rótulos de treinamento:\", np.unique(y_train[:50], return_counts=True))\n",
        "print(\"Distribuição dos rótulos de teste:\", np.unique(y_test[:50], return_counts=True))\n"
      ],
      "metadata": {
        "id": "LjjjZYKCAa1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado confirma que o conjunto de treinamento contém apenas a classe \\( 0 \\), e a classe \\( 1 \\) está ausente. Isso é um problema, pois o modelo não pode aprender a diferenciar entre as classes se apenas uma delas estiver presente.\n",
        "\n",
        "### Soluções Possíveis\n",
        "1. **Verificar o Dataset Original**:\n",
        "   - Certifique-se de que o dataset original contém amostras de todas as classes e que os dados foram carregados corretamente.\n",
        "\n",
        "2. **Balancear o Dataset**:\n",
        "   - Se o dataset original for desequilibrado, tente aumentar ou incluir amostras da classe \\( 1 \\) no conjunto de treinamento.\n",
        "\n",
        "3. **Ajustar a Divisão dos Dados**:\n",
        "   - Reavalie a divisão de dados em treinamento e teste para garantir que ambos contenham todas as classes.\n",
        "\n",
        "4. **Código para Checar o Dataset Original**:\n",
        "   Para verificar a distribuição das classes no dataset completo:\n",
        "   ```python\n",
        "   print(\"Distribuição das classes no conjunto completo:\", np.unique(y_train + y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "5. **Exemplo de Balanceamento Manual**:\n",
        "   Caso o dataset original tenha classes suficientes, você pode aumentar a classe minoritária:\n",
        "   ```python\n",
        "   # Reamostrando manualmente\n",
        "   if len(class_1_indices) > 0:\n",
        "       min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "       balanced_indices = np.hstack((\n",
        "           resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "           resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "       ))\n",
        "\n",
        "       X_train_balanced = X_train[balanced_indices]\n",
        "       y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "       print(\"Distribuição balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "   else:\n",
        "       print(\"A classe 1 não está presente no conjunto original.\")\n",
        "   ```\n",
        "\n",
        "Se o problema persistir, você pode me informar sobre os detalhes do dataset original para que possamos ajustar o pipeline de pré-processamento."
      ],
      "metadata": {
        "id": "6TjjTiZXEVVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as classes presentes no conjunto de treinamento\n",
        "print(\"Distribuição original dos rótulos:\", np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Se não houver dados para uma classe, adicione ou corrija a amostragem\n",
        "if len(class_1_indices) == 0:\n",
        "    print(\"A classe 1 não está presente no conjunto de treinamento.\")\n",
        "else:\n",
        "    # Balancear os dados se ambas as classes estiverem presentes\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    # Balancear X_train e y_train\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribuição balanceada dos rótulos de treinamento:\", np.unique(y_train_balanced, return_counts=True))\n"
      ],
      "metadata": {
        "id": "ScJ3rD3IBbqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reamostrando manualmente\n",
        "if len(class_1_indices) > 0:\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribuição balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "else:\n",
        "    print(\"A classe 1 não está presente no conjunto original.\")\n"
      ],
      "metadata": {
        "id": "AWhMOjvvBo0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado indica que a classe \\( 1 \\) está completamente ausente no dataset, não apenas no conjunto de treinamento, mas aparentemente no conjunto original carregado. Isso pode ser causado por:\n",
        "\n",
        "1. **Problemas no Dataset Original**:\n",
        "   - O dataset fornecido contém apenas amostras da classe \\( 0 \\).\n",
        "2. **Erro na Organização do Dataset**:\n",
        "   - Pode haver uma falha no pré-processamento ou na separação das classes.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "#### 1. Verificar o Dataset Original\n",
        "Certifique-se de que o dataset original contém amostras de ambas as classes. Se houver subdiretórios como \"maligno\" e \"benigno\", confirme que ambos foram processados. Use o seguinte código para listar os diretórios e a contagem de arquivos em cada um:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Listar subdiretórios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diretório: {root}, Número de arquivos: {len(files)}\")\n",
        "```\n",
        "\n",
        "#### 2. Corrigir o Pipeline de Pré-processamento\n",
        "Caso o problema esteja na seleção dos dados, ajuste o pipeline para incluir todas as classes. Certifique-se de que o código está capturando ambas as classes:\n",
        "\n",
        "```python\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribuição\n",
        "print(\"Distribuição das classes no dataset completo:\", np.unique(labels, return_counts=True))\n",
        "```\n",
        "\n",
        "#### 3. Adicionar Amostras da Classe Minoritária\n",
        "Se o dataset original é desequilibrado, você pode adicionar manualmente mais amostras da classe \\( 1 \\) (maligno). Isso pode ser feito coletando mais dados ou duplicando algumas amostras existentes para balancear.\n",
        "\n",
        "Se precisar de ajuda para investigar o dataset ou ajustar o pipeline, avise!"
      ],
      "metadata": {
        "id": "HNXMMkQMEIFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar subdiretórios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diretório: {root}, Número de arquivos: {len(files)}\")\n"
      ],
      "metadata": {
        "id": "lYLT1udwB0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribuição\n",
        "print(\"Distribuição das classes no dataset completo:\", np.unique(labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "lqaO9eMjB-63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos uma distribuição equilibrada no dataset completo:\n",
        "\n",
        "- **500 amostras da classe \"benigno\"**.\n",
        "- **500 amostras da classe \"maligno\"**.\n",
        "\n",
        "Isso confirma que ambas as classes estão presentes e foram corretamente processadas. O problema anterior foi causado por um desequilíbrio ou erro na seleção dos dados para treinamento.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. **Codificar os Rótulos**:\n",
        "   - Converter os rótulos `['benigno', 'maligno']` para valores numéricos \\(0\\) e \\(1\\).\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "   # Codificar os rótulos\n",
        "   label_encoder = LabelEncoder()\n",
        "   encoded_labels = label_encoder.fit_transform(labels)\n",
        "   print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n",
        "   ```\n",
        "\n",
        "2. **Dividir o Dataset**:\n",
        "   - Separar os dados em conjuntos de treinamento e teste de forma balanceada.\n",
        "   \n",
        "   ```python\n",
        "   from sklearn.model_selection import train_test_split\n",
        "\n",
        "   # Dividir os dados\n",
        "   X_train, X_test, y_train, y_test = train_test_split(\n",
        "       processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "       encoded_labels,\n",
        "       test_size=0.2,\n",
        "       stratify=encoded_labels,  # Garantir balanceamento\n",
        "       random_state=42\n",
        "   )\n",
        "   print(\"Distribuição dos rótulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "   print(\"Distribuição dos rótulos no teste:\", np.unique(y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "3. **Treinar o Modelo Quântico**:\n",
        "   - Use os dados balanceados para treinar o modelo quântico e avaliar o desempenho.\n",
        "\n",
        "Deseja que eu implemente essas etapas ou passe direto para o treinamento?"
      ],
      "metadata": {
        "id": "jsWIBtxtDvUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar os rótulos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "F53QU2yYCJSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "    encoded_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=encoded_labels,  # Garantir balanceamento\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Distribuição dos rótulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Distribuição dos rótulos no teste:\", np.unique(y_test, return_counts=True))\n"
      ],
      "metadata": {
        "id": "SbRa_3cJCTO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora o dataset está devidamente balanceado:\n",
        "\n",
        "- **Treinamento**: 400 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "- **Teste**: 100 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "\n",
        "Com os dados preparados, podemos seguir para o treinamento do modelo quântico.\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "1. **Treinar o Modelo Quântico**:\n",
        "   - Ajustar os pesos do circuito para minimizar a função de custo.\n",
        "   - Utilizar o conjunto de treinamento balanceado (\\( X\\_train \\) e \\( y\\_train \\)).\n",
        "\n",
        "2. **Avaliar o Modelo**:\n",
        "   - Calcular a precisão e a perda no conjunto de teste (\\( X\\_test \\) e \\( y\\_test \\)).\n",
        "\n",
        "### Código para Treinamento\n",
        "Aqui está o código atualizado para treinar e avaliar o modelo:\n",
        "\n",
        "```python\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n",
        "```\n",
        "\n",
        "### Explicação\n",
        "1. **Função de Custo**:\n",
        "   - Calcula o erro quadrático médio entre a previsão do circuito e os rótulos reais.\n",
        "2. **Otimização**:\n",
        "   - Usa Adam para ajustar os pesos do circuito.\n",
        "3. **Avaliação**:\n",
        "   - Mede o custo no conjunto de teste para verificar a generalização.\n",
        "\n",
        "Deseja executar este código ou ajustar algum parâmetro antes de seguir?"
      ],
      "metadata": {
        "id": "JEwGaoJzDhsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # Número de iterações\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "# Configurando o gráfico\n",
        "plt.ion()  # Ativando o modo interativo\n",
        "fig, ax = plt.subplots()\n",
        "line1, = ax.plot([], [], label='Custo de Treinamento', color='blue')\n",
        "line2, = ax.plot([], [], label='Custo de Teste', color='orange')\n",
        "ax.set_xlim(0, steps)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlabel(\"Passo\")\n",
        "ax.set_ylabel(\"Custo\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Treinamento\n",
        "start_time = time.time()\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    train_cost = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "    test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "\n",
        "    # Armazenar custos\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Atualizar gráfico\n",
        "    line1.set_data(range(step + 1), train_costs)\n",
        "    line2.set_data(range(step + 1), test_costs)\n",
        "    ax.set_ylim(0, max(train_costs + test_costs) * 1.1)  # Ajustar limites do gráfico dinamicamente\n",
        "    clear_output(wait=True)\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)\n",
        "\n",
        "    # Print no console\n",
        "    print(f\"Passo {step}/{steps} | Custo de Treinamento: {train_cost:.4f} | Custo de Teste: {test_cost:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Treinamento concluído em {end_time - start_time:.2f} segundos.\")\n",
        "plt.ioff()  # Desativar o modo interativo\n",
        "plt.show()\n",
        "\n",
        "# Avaliação Final no Conjunto de Teste\n",
        "final_test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "1TylwODwCjzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred = [round(float(circuit(weights, x))) for x in X_test[:, :n_qubits]]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "69mk3xhTdn-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Relatório de classificação\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Benigno\", \"Maligno\"]))\n"
      ],
      "metadata": {
        "id": "Flu_IGkneQT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Parâmetros iniciais para testes\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Pesos aleatórios\n",
        "features = np.random.random(n_qubits)  # Exemplo de entrada\n",
        "\n",
        "# Testando o circuito\n",
        "output = circuit(weights, features)\n",
        "print(f\"Saída do circuito: {output}\")\n"
      ],
      "metadata": {
        "id": "Pmx4JWJLe0lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configuração do treinamento\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Inicialização dos pesos aleatórios\n",
        "opt = AdamOptimizer(stepsize=0.01)  # Otimizador Adam\n",
        "steps = 50  # Número de iterações\n",
        "\n",
        "# Dados simulados para teste\n",
        "X_train = np.random.random((100, n_qubits))  # 100 amostras, cada uma com 12 qubits\n",
        "y_train = np.random.choice([0, 1], size=100)  # Rótulos binários simulados\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)  # Atualizar pesos\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado final\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final após {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "ifCUQ5oBgKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane.numpy as pnp  # Usar NumPy do PennyLane para suporte a gradientes\n",
        "\n",
        "# Configuração dos pesos ajustada\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Otimizador com taxa de aprendizado maior\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "\n",
        "# Treinamento com ajustes\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final após {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "lq9f9d4ioAvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões com transformação para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "hH-ZFY7KsgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previsões com transformação para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "FHYzN1xKs14i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado com melhorias para aumentar a expressividade do circuito, regularização na função de custo e validação em dados de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo com regularização L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configuração do treinamento\n",
        "n_layers = 6  # Aumentar o número de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o número de iterações\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2%}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### O Que Foi Ajustado\n",
        "1. **Camadas Adicionais no Circuito**:\n",
        "   - O número de camadas foi aumentado para 6 para maior expressividade.\n",
        "2. **Regularização L2**:\n",
        "   - Adicionada regularização à função de custo para melhorar a estabilidade do modelo.\n",
        "3. **Mais Iterações**:\n",
        "   - O número de passos foi aumentado para 100 para permitir melhor convergência.\n",
        "4. **Avaliação no Conjunto de Teste**:\n",
        "   - Adicionado código para calcular a acurácia no conjunto de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "1. **Execute o Código**:\n",
        "   - Observe os custos e as acurácias no conjunto de treinamento e teste.\n",
        "2. **Analise os Resultados**:\n",
        "   - Verifique se há sinais de overfitting (acurácia no treino muito maior que no teste).\n",
        "\n",
        "Se precisar de mais ajustes, estou à disposição! 😊"
      ],
      "metadata": {
        "id": "IS2WKZ4burMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo quântico\n",
        "n_qubits = 12  # Número de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Função de custo com regularização L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configuração do treinamento\n",
        "n_layers = 6  # Aumentar o número de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o número de iterações\n",
        "\n",
        "# Ajustar rótulos para intervalo compatível\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 iterações\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acurácia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avaliação no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "aBdq7hhAtuWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código implementa um pipeline quântico-clássico para classificação binária usando circuitos quânticos e o otimizador Adam para ajustar os parâmetros. Aqui está uma explicação detalhada do processo quântico envolvido:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Dispositivo Quântico**\n",
        "```python\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "```\n",
        "- **Descrição**: Um dispositivo quântico simulado, configurado para usar 12 qubits.\n",
        "- **Papel**: Serve como o \"computador quântico virtual\" onde os circuitos serão executados.\n",
        "- **Simulação Clássica**: O dispositivo `default.qubit` é um simulador baseado em estado vetorial.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Definição do Circuito**\n",
        "```python\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rotações RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "\n",
        "#### a. **Embedding dos Dados**\n",
        "```python\n",
        "for i in range(n_qubits):\n",
        "    qml.RY(features[i], wires=i)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Os dados clássicos (features) são mapeados para estados quânticos usando rotações \\( RY \\).\n",
        "  - Cada feature é usada para parametrizar uma rotação em torno do eixo \\( Y \\) para o qubit correspondente.\n",
        "- **Papel**:\n",
        "  - Cria uma representação quântica dos dados.\n",
        "\n",
        "#### b. **Camadas Parametrizadas**\n",
        "```python\n",
        "qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Aplica camadas de entrelaçamento entre os qubits, usando parâmetros treináveis (\\( weights \\)).\n",
        "  - Permite que o modelo quântico capture interdependências complexas entre as features.\n",
        "- **Papel**:\n",
        "  - Adiciona expressividade ao circuito, permitindo que ele represente funções mais complexas.\n",
        "\n",
        "#### c. **Medida**\n",
        "```python\n",
        "return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Mede a expectativa do operador \\( Z \\) no primeiro qubit.\n",
        "  - Retorna um valor contínuo no intervalo \\([-1, 1]\\).\n",
        "- **Papel**:\n",
        "  - Converte o estado quântico final em um valor clássico utilizável.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Função de Custo**\n",
        "```python\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadrático\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regularização L2\n",
        "    return loss / len(X) + reg_term\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula o erro quadrático médio (\\( MSE \\)) entre as previsões do circuito e os rótulos reais.\n",
        "  - Adiciona um termo de regularização L2 para penalizar pesos altos e evitar overfitting.\n",
        "- **Papel**:\n",
        "  - Orienta o treinamento para ajustar os pesos e minimizar a discrepância entre previsões e rótulos.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Treinamento**\n",
        "```python\n",
        "weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - O otimizador Adam ajusta os pesos do circuito quântico, minimizando a função de custo.\n",
        "- **Papel**:\n",
        "  - Integra o aprendizado quântico ao pipeline clássico, otimizando os parâmetros do circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Classificação Binária**\n",
        "```python\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Converte as previsões contínuas do circuito (\\([-1, 1]\\)) em rótulos binários (\\( -1, 1 \\)) usando uma função de ativação baseada em threshold.\n",
        "- **Papel**:\n",
        "  - Permite que o modelo faça classificações compatíveis com os rótulos ajustados.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Métricas de Desempenho**\n",
        "```python\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula a proporção de previsões corretas.\n",
        "- **Papel**:\n",
        "  - Avalia o desempenho do modelo no conjunto de treinamento e teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo do Processo Quântico\n",
        "1. **Embedding**:\n",
        "   - Os dados clássicos são mapeados para estados quânticos usando rotações \\( RY \\).\n",
        "2. **Camadas Parametrizadas**:\n",
        "   - O circuito aprende padrões complexos nos dados ajustando os pesos.\n",
        "3. **Medida**:\n",
        "   - A expectativa do operador \\( Z \\) no primeiro qubit traduz o estado quântico final em um valor clássico.\n",
        "4. **Treinamento**:\n",
        "   - A função de custo e o otimizador ajustam os pesos para melhorar as previsões.\n",
        "5. **Classificação**:\n",
        "   - O valor contínuo retornado pelo circuito é transformado em rótulos binários.\n",
        "\n",
        "Se precisar de mais detalhes ou ajustes no modelo, estou à disposição! 😊"
      ],
      "metadata": {
        "id": "Ic9V71bYvaCY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_RiqRv-vXW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}