{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/QqEGG8kDKEQSwCJP1m1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Caminho do arquivo zip carregado\n",
        "zip_path = '/content/melanomas.zip'\n",
        "extract_path = '/content/melanomas'\n",
        "\n",
        "# Extraindo o arquivo zip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Listando os arquivos extra√≠dos\n",
        "extracted_files = []\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "extracted_files[:10]  # Mostrando os primeiros 10 arquivos para an√°lise\n"
      ],
      "metadata": {
        "id": "tVVgYLXl54gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Caminho de amostra para imagens\n",
        "sample_image_path = extracted_files[0]\n",
        "\n",
        "# Abrindo e processando a imagem\n",
        "image = Image.open(sample_image_path)\n",
        "image_resized = image.resize((64, 64))  # Redimensionando para 64x64 pixels\n",
        "image_array = np.array(image_resized) / 255.0  # Normalizando os valores entre 0 e 1\n",
        "\n",
        "# Verificando as dimens√µes e valores da imagem processada\n",
        "image_array.shape, image_array[:5, :5, 0]  # Mostrando a dimens√£o e parte da matriz para confirma√ß√£o\n"
      ],
      "metadata": {
        "id": "O2db95Fv6j4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Fun√ß√£o para processar imagens\n",
        "def process_images(image_paths, image_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Identificando a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrindo, redimensionando e normalizando a imagem\n",
        "        image = Image.open(image_path).resize(image_size)\n",
        "        image_array = np.array(image) / 255.0\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletando todas as imagens do diret√≥rio\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Mostrando o formato dos dados processados\n",
        "processed_images.shape, len(labels)\n"
      ],
      "metadata": {
        "id": "k9dwC_MK6wJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convertendo r√≥tulos de texto para valores num√©ricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mostrando as dimens√µes dos dados preparados\n",
        "X_train.shape, X_test.shape, len(y_train), len(y_test)\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10  # N√∫mero de qubits usados\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    \"\"\"Embed dados cl√°ssicos em estados qu√¢nticos\"\"\"\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    \"\"\"Modelo qu√¢ntico parametrizado\"\"\"\n",
        "    data_embedding(features, range(n_qubits))  # Embedding dos dados\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))  # Medida no primeiro qubit\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 3\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)  # Pesos com formato 2D\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Exemplo de execu√ß√£o com os primeiros 10 elementos de uma amostra\n",
        "sample_features = X_train[0][:n_qubits]  # Selecionando exatamente 10 elementos\n",
        "\n",
        "# Certificando-se de que sample_features tem o tamanho correto\n",
        "sample_features = np.pad(sample_features, (0, n_qubits - len(sample_features))) if len(sample_features) < n_qubits else sample_features[:n_qubits]\n",
        "\n",
        "# Executando o circuito\n",
        "print(\"Resultado do circuito:\", circuit(weights, sample_features))\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:50, :n_qubits], y_train[:50]), weights)  # Usando um subset para demonstra√ß√£o\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:50, :n_qubits], y_train[:50])\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o\n",
        "test_cost = cost(weights, X_test[:50, :n_qubits], y_test[:50])\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "22JKgaL78g7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribui√ß√£o dos r√≥tulos de treinamento:\", np.unique(y_train[:50], return_counts=True))\n",
        "print(\"Distribui√ß√£o dos r√≥tulos de teste:\", np.unique(y_test[:50], return_counts=True))\n"
      ],
      "metadata": {
        "id": "LjjjZYKCAa1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado confirma que o conjunto de treinamento cont√©m apenas a classe \\( 0 \\), e a classe \\( 1 \\) est√° ausente. Isso √© um problema, pois o modelo n√£o pode aprender a diferenciar entre as classes se apenas uma delas estiver presente.\n",
        "\n",
        "### Solu√ß√µes Poss√≠veis\n",
        "1. **Verificar o Dataset Original**:\n",
        "   - Certifique-se de que o dataset original cont√©m amostras de todas as classes e que os dados foram carregados corretamente.\n",
        "\n",
        "2. **Balancear o Dataset**:\n",
        "   - Se o dataset original for desequilibrado, tente aumentar ou incluir amostras da classe \\( 1 \\) no conjunto de treinamento.\n",
        "\n",
        "3. **Ajustar a Divis√£o dos Dados**:\n",
        "   - Reavalie a divis√£o de dados em treinamento e teste para garantir que ambos contenham todas as classes.\n",
        "\n",
        "4. **C√≥digo para Checar o Dataset Original**:\n",
        "   Para verificar a distribui√ß√£o das classes no dataset completo:\n",
        "   ```python\n",
        "   print(\"Distribui√ß√£o das classes no conjunto completo:\", np.unique(y_train + y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "5. **Exemplo de Balanceamento Manual**:\n",
        "   Caso o dataset original tenha classes suficientes, voc√™ pode aumentar a classe minorit√°ria:\n",
        "   ```python\n",
        "   # Reamostrando manualmente\n",
        "   if len(class_1_indices) > 0:\n",
        "       min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "       balanced_indices = np.hstack((\n",
        "           resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "           resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "       ))\n",
        "\n",
        "       X_train_balanced = X_train[balanced_indices]\n",
        "       y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "       print(\"Distribui√ß√£o balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "   else:\n",
        "       print(\"A classe 1 n√£o est√° presente no conjunto original.\")\n",
        "   ```\n",
        "\n",
        "Se o problema persistir, voc√™ pode me informar sobre os detalhes do dataset original para que possamos ajustar o pipeline de pr√©-processamento."
      ],
      "metadata": {
        "id": "6TjjTiZXEVVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as classes presentes no conjunto de treinamento\n",
        "print(\"Distribui√ß√£o original dos r√≥tulos:\", np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Se n√£o houver dados para uma classe, adicione ou corrija a amostragem\n",
        "if len(class_1_indices) == 0:\n",
        "    print(\"A classe 1 n√£o est√° presente no conjunto de treinamento.\")\n",
        "else:\n",
        "    # Balancear os dados se ambas as classes estiverem presentes\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    # Balancear X_train e y_train\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribui√ß√£o balanceada dos r√≥tulos de treinamento:\", np.unique(y_train_balanced, return_counts=True))\n"
      ],
      "metadata": {
        "id": "ScJ3rD3IBbqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reamostrando manualmente\n",
        "if len(class_1_indices) > 0:\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribui√ß√£o balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "else:\n",
        "    print(\"A classe 1 n√£o est√° presente no conjunto original.\")\n"
      ],
      "metadata": {
        "id": "AWhMOjvvBo0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado indica que a classe \\( 1 \\) est√° completamente ausente no dataset, n√£o apenas no conjunto de treinamento, mas aparentemente no conjunto original carregado. Isso pode ser causado por:\n",
        "\n",
        "1. **Problemas no Dataset Original**:\n",
        "   - O dataset fornecido cont√©m apenas amostras da classe \\( 0 \\).\n",
        "2. **Erro na Organiza√ß√£o do Dataset**:\n",
        "   - Pode haver uma falha no pr√©-processamento ou na separa√ß√£o das classes.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "#### 1. Verificar o Dataset Original\n",
        "Certifique-se de que o dataset original cont√©m amostras de ambas as classes. Se houver subdiret√≥rios como \"maligno\" e \"benigno\", confirme que ambos foram processados. Use o seguinte c√≥digo para listar os diret√≥rios e a contagem de arquivos em cada um:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Listar subdiret√≥rios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diret√≥rio: {root}, N√∫mero de arquivos: {len(files)}\")\n",
        "```\n",
        "\n",
        "#### 2. Corrigir o Pipeline de Pr√©-processamento\n",
        "Caso o problema esteja na sele√ß√£o dos dados, ajuste o pipeline para incluir todas as classes. Certifique-se de que o c√≥digo est√° capturando ambas as classes:\n",
        "\n",
        "```python\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribui√ß√£o\n",
        "print(\"Distribui√ß√£o das classes no dataset completo:\", np.unique(labels, return_counts=True))\n",
        "```\n",
        "\n",
        "#### 3. Adicionar Amostras da Classe Minorit√°ria\n",
        "Se o dataset original √© desequilibrado, voc√™ pode adicionar manualmente mais amostras da classe \\( 1 \\) (maligno). Isso pode ser feito coletando mais dados ou duplicando algumas amostras existentes para balancear.\n",
        "\n",
        "Se precisar de ajuda para investigar o dataset ou ajustar o pipeline, avise!"
      ],
      "metadata": {
        "id": "HNXMMkQMEIFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar subdiret√≥rios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diret√≥rio: {root}, N√∫mero de arquivos: {len(files)}\")\n"
      ],
      "metadata": {
        "id": "lYLT1udwB0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribui√ß√£o\n",
        "print(\"Distribui√ß√£o das classes no dataset completo:\", np.unique(labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "lqaO9eMjB-63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos uma distribui√ß√£o equilibrada no dataset completo:\n",
        "\n",
        "- **500 amostras da classe \"benigno\"**.\n",
        "- **500 amostras da classe \"maligno\"**.\n",
        "\n",
        "Isso confirma que ambas as classes est√£o presentes e foram corretamente processadas. O problema anterior foi causado por um desequil√≠brio ou erro na sele√ß√£o dos dados para treinamento.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "1. **Codificar os R√≥tulos**:\n",
        "   - Converter os r√≥tulos `['benigno', 'maligno']` para valores num√©ricos \\(0\\) e \\(1\\).\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "   # Codificar os r√≥tulos\n",
        "   label_encoder = LabelEncoder()\n",
        "   encoded_labels = label_encoder.fit_transform(labels)\n",
        "   print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n",
        "   ```\n",
        "\n",
        "2. **Dividir o Dataset**:\n",
        "   - Separar os dados em conjuntos de treinamento e teste de forma balanceada.\n",
        "   \n",
        "   ```python\n",
        "   from sklearn.model_selection import train_test_split\n",
        "\n",
        "   # Dividir os dados\n",
        "   X_train, X_test, y_train, y_test = train_test_split(\n",
        "       processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "       encoded_labels,\n",
        "       test_size=0.2,\n",
        "       stratify=encoded_labels,  # Garantir balanceamento\n",
        "       random_state=42\n",
        "   )\n",
        "   print(\"Distribui√ß√£o dos r√≥tulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "   print(\"Distribui√ß√£o dos r√≥tulos no teste:\", np.unique(y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "3. **Treinar o Modelo Qu√¢ntico**:\n",
        "   - Use os dados balanceados para treinar o modelo qu√¢ntico e avaliar o desempenho.\n",
        "\n",
        "Deseja que eu implemente essas etapas ou passe direto para o treinamento?"
      ],
      "metadata": {
        "id": "jsWIBtxtDvUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar os r√≥tulos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "F53QU2yYCJSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "    encoded_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=encoded_labels,  # Garantir balanceamento\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Distribui√ß√£o dos r√≥tulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Distribui√ß√£o dos r√≥tulos no teste:\", np.unique(y_test, return_counts=True))\n"
      ],
      "metadata": {
        "id": "SbRa_3cJCTO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora o dataset est√° devidamente balanceado:\n",
        "\n",
        "- **Treinamento**: 400 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "- **Teste**: 100 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "\n",
        "Com os dados preparados, podemos seguir para o treinamento do modelo qu√¢ntico.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "1. **Treinar o Modelo Qu√¢ntico**:\n",
        "   - Ajustar os pesos do circuito para minimizar a fun√ß√£o de custo.\n",
        "   - Utilizar o conjunto de treinamento balanceado (\\( X\\_train \\) e \\( y\\_train \\)).\n",
        "\n",
        "2. **Avaliar o Modelo**:\n",
        "   - Calcular a precis√£o e a perda no conjunto de teste (\\( X\\_test \\) e \\( y\\_test \\)).\n",
        "\n",
        "### C√≥digo para Treinamento\n",
        "Aqui est√° o c√≥digo atualizado para treinar e avaliar o modelo:\n",
        "\n",
        "```python\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n",
        "```\n",
        "\n",
        "### Explica√ß√£o\n",
        "1. **Fun√ß√£o de Custo**:\n",
        "   - Calcula o erro quadr√°tico m√©dio entre a previs√£o do circuito e os r√≥tulos reais.\n",
        "2. **Otimiza√ß√£o**:\n",
        "   - Usa Adam para ajustar os pesos do circuito.\n",
        "3. **Avalia√ß√£o**:\n",
        "   - Mede o custo no conjunto de teste para verificar a generaliza√ß√£o.\n",
        "\n",
        "Deseja executar este c√≥digo ou ajustar algum par√¢metro antes de seguir?"
      ],
      "metadata": {
        "id": "JEwGaoJzDhsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "# Configurando o gr√°fico\n",
        "plt.ion()  # Ativando o modo interativo\n",
        "fig, ax = plt.subplots()\n",
        "line1, = ax.plot([], [], label='Custo de Treinamento', color='blue')\n",
        "line2, = ax.plot([], [], label='Custo de Teste', color='orange')\n",
        "ax.set_xlim(0, steps)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlabel(\"Passo\")\n",
        "ax.set_ylabel(\"Custo\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Treinamento\n",
        "start_time = time.time()\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    train_cost = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "    test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "\n",
        "    # Armazenar custos\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Atualizar gr√°fico\n",
        "    line1.set_data(range(step + 1), train_costs)\n",
        "    line2.set_data(range(step + 1), test_costs)\n",
        "    ax.set_ylim(0, max(train_costs + test_costs) * 1.1)  # Ajustar limites do gr√°fico dinamicamente\n",
        "    clear_output(wait=True)\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)\n",
        "\n",
        "    # Print no console\n",
        "    print(f\"Passo {step}/{steps} | Custo de Treinamento: {train_cost:.4f} | Custo de Teste: {test_cost:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Treinamento conclu√≠do em {end_time - start_time:.2f} segundos.\")\n",
        "plt.ioff()  # Desativar o modo interativo\n",
        "plt.show()\n",
        "\n",
        "# Avalia√ß√£o Final no Conjunto de Teste\n",
        "final_test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "1TylwODwCjzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes no conjunto de teste\n",
        "y_pred = [round(float(circuit(weights, x))) for x in X_test[:, :n_qubits]]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "69mk3xhTdn-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Relat√≥rio de classifica√ß√£o\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Benigno\", \"Maligno\"]))\n"
      ],
      "metadata": {
        "id": "Flu_IGkneQT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Par√¢metros iniciais para testes\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Pesos aleat√≥rios\n",
        "features = np.random.random(n_qubits)  # Exemplo de entrada\n",
        "\n",
        "# Testando o circuito\n",
        "output = circuit(weights, features)\n",
        "print(f\"Sa√≠da do circuito: {output}\")\n"
      ],
      "metadata": {
        "id": "Pmx4JWJLe0lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Inicializa√ß√£o dos pesos aleat√≥rios\n",
        "opt = AdamOptimizer(stepsize=0.01)  # Otimizador Adam\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "\n",
        "# Dados simulados para teste\n",
        "X_train = np.random.random((100, n_qubits))  # 100 amostras, cada uma com 12 qubits\n",
        "y_train = np.random.choice([0, 1], size=100)  # R√≥tulos bin√°rios simulados\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)  # Atualizar pesos\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado final\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final ap√≥s {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "ifCUQ5oBgKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane.numpy as pnp  # Usar NumPy do PennyLane para suporte a gradientes\n",
        "\n",
        "# Configura√ß√£o dos pesos ajustada\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Otimizador com taxa de aprendizado maior\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "\n",
        "# Treinamento com ajustes\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final ap√≥s {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "lq9f9d4ioAvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes com transforma√ß√£o para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "hH-ZFY7KsgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes com transforma√ß√£o para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "FHYzN1xKs14i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado com melhorias para aumentar a expressividade do circuito, regulariza√ß√£o na fun√ß√£o de custo e valida√ß√£o em dados de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo com regulariza√ß√£o L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "n_layers = 6  # Aumentar o n√∫mero de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o n√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_accuracy:.2%}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### O Que Foi Ajustado\n",
        "1. **Camadas Adicionais no Circuito**:\n",
        "   - O n√∫mero de camadas foi aumentado para 6 para maior expressividade.\n",
        "2. **Regulariza√ß√£o L2**:\n",
        "   - Adicionada regulariza√ß√£o √† fun√ß√£o de custo para melhorar a estabilidade do modelo.\n",
        "3. **Mais Itera√ß√µes**:\n",
        "   - O n√∫mero de passos foi aumentado para 100 para permitir melhor converg√™ncia.\n",
        "4. **Avalia√ß√£o no Conjunto de Teste**:\n",
        "   - Adicionado c√≥digo para calcular a acur√°cia no conjunto de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "1. **Execute o C√≥digo**:\n",
        "   - Observe os custos e as acur√°cias no conjunto de treinamento e teste.\n",
        "2. **Analise os Resultados**:\n",
        "   - Verifique se h√° sinais de overfitting (acur√°cia no treino muito maior que no teste).\n",
        "\n",
        "Se precisar de mais ajustes, estou √† disposi√ß√£o! üòä"
      ],
      "metadata": {
        "id": "IS2WKZ4burMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo com regulariza√ß√£o L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "n_layers = 6  # Aumentar o n√∫mero de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o n√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "aBdq7hhAtuWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O c√≥digo implementa um pipeline qu√¢ntico-cl√°ssico para classifica√ß√£o bin√°ria usando circuitos qu√¢nticos e o otimizador Adam para ajustar os par√¢metros. Aqui est√° uma explica√ß√£o detalhada do processo qu√¢ntico envolvido:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Dispositivo Qu√¢ntico**\n",
        "```python\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "```\n",
        "- **Descri√ß√£o**: Um dispositivo qu√¢ntico simulado, configurado para usar 12 qubits.\n",
        "- **Papel**: Serve como o \"computador qu√¢ntico virtual\" onde os circuitos ser√£o executados.\n",
        "- **Simula√ß√£o Cl√°ssica**: O dispositivo `default.qubit` √© um simulador baseado em estado vetorial.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Defini√ß√£o do Circuito**\n",
        "```python\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "\n",
        "#### a. **Embedding dos Dados**\n",
        "```python\n",
        "for i in range(n_qubits):\n",
        "    qml.RY(features[i], wires=i)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Os dados cl√°ssicos (features) s√£o mapeados para estados qu√¢nticos usando rota√ß√µes \\( RY \\).\n",
        "  - Cada feature √© usada para parametrizar uma rota√ß√£o em torno do eixo \\( Y \\) para o qubit correspondente.\n",
        "- **Papel**:\n",
        "  - Cria uma representa√ß√£o qu√¢ntica dos dados.\n",
        "\n",
        "#### b. **Camadas Parametrizadas**\n",
        "```python\n",
        "qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Aplica camadas de entrela√ßamento entre os qubits, usando par√¢metros trein√°veis (\\( weights \\)).\n",
        "  - Permite que o modelo qu√¢ntico capture interdepend√™ncias complexas entre as features.\n",
        "- **Papel**:\n",
        "  - Adiciona expressividade ao circuito, permitindo que ele represente fun√ß√µes mais complexas.\n",
        "\n",
        "#### c. **Medida**\n",
        "```python\n",
        "return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Mede a expectativa do operador \\( Z \\) no primeiro qubit.\n",
        "  - Retorna um valor cont√≠nuo no intervalo \\([-1, 1]\\).\n",
        "- **Papel**:\n",
        "  - Converte o estado qu√¢ntico final em um valor cl√°ssico utiliz√°vel.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Fun√ß√£o de Custo**\n",
        "```python\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula o erro quadr√°tico m√©dio (\\( MSE \\)) entre as previs√µes do circuito e os r√≥tulos reais.\n",
        "  - Adiciona um termo de regulariza√ß√£o L2 para penalizar pesos altos e evitar overfitting.\n",
        "- **Papel**:\n",
        "  - Orienta o treinamento para ajustar os pesos e minimizar a discrep√¢ncia entre previs√µes e r√≥tulos.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Treinamento**\n",
        "```python\n",
        "weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - O otimizador Adam ajusta os pesos do circuito qu√¢ntico, minimizando a fun√ß√£o de custo.\n",
        "- **Papel**:\n",
        "  - Integra o aprendizado qu√¢ntico ao pipeline cl√°ssico, otimizando os par√¢metros do circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Classifica√ß√£o Bin√°ria**\n",
        "```python\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Converte as previs√µes cont√≠nuas do circuito (\\([-1, 1]\\)) em r√≥tulos bin√°rios (\\( -1, 1 \\)) usando uma fun√ß√£o de ativa√ß√£o baseada em threshold.\n",
        "- **Papel**:\n",
        "  - Permite que o modelo fa√ßa classifica√ß√µes compat√≠veis com os r√≥tulos ajustados.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **M√©tricas de Desempenho**\n",
        "```python\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula a propor√ß√£o de previs√µes corretas.\n",
        "- **Papel**:\n",
        "  - Avalia o desempenho do modelo no conjunto de treinamento e teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo do Processo Qu√¢ntico\n",
        "1. **Embedding**:\n",
        "   - Os dados cl√°ssicos s√£o mapeados para estados qu√¢nticos usando rota√ß√µes \\( RY \\).\n",
        "2. **Camadas Parametrizadas**:\n",
        "   - O circuito aprende padr√µes complexos nos dados ajustando os pesos.\n",
        "3. **Medida**:\n",
        "   - A expectativa do operador \\( Z \\) no primeiro qubit traduz o estado qu√¢ntico final em um valor cl√°ssico.\n",
        "4. **Treinamento**:\n",
        "   - A fun√ß√£o de custo e o otimizador ajustam os pesos para melhorar as previs√µes.\n",
        "5. **Classifica√ß√£o**:\n",
        "   - O valor cont√≠nuo retornado pelo circuito √© transformado em r√≥tulos bin√°rios.\n",
        "\n",
        "Se precisar de mais detalhes ou ajustes no modelo, estou √† disposi√ß√£o! üòä"
      ],
      "metadata": {
        "id": "Ic9V71bYvaCY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_RiqRv-vXW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}