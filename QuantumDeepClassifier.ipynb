{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRZq/btk58AjqAgKNowW4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explica√ß√£o dos Comandos de Instala√ß√£o**\n",
        "\n",
        "Os comandos listados utilizam o gerenciador de pacotes **pip** para instalar bibliotecas espec√≠ficas que s√£o usadas em computa√ß√£o qu√¢ntica, aprendizado de m√°quina e visualiza√ß√£o de dados. Abaixo, explico cada uma delas:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. `!pip install qiskit`**\n",
        "- **O que √© o Qiskit?**\n",
        "  - O Qiskit √© uma biblioteca de c√≥digo aberto para computa√ß√£o qu√¢ntica desenvolvida pela IBM. Ele permite:\n",
        "    - Criar, simular e executar circuitos qu√¢nticos.\n",
        "    - Realizar experimentos em computadores qu√¢nticos reais da IBM Quantum ou simuladores locais.\n",
        "    - Trabalhar com algoritmos qu√¢nticos, como **VQE**, **QAOA** e **Shor**.\n",
        "\n",
        "- **Principais M√≥dulos do Qiskit:**\n",
        "  - **`qiskit.circuit`**: Cria√ß√£o de circuitos qu√¢nticos.\n",
        "  - **`qiskit.aer`**: Simula√ß√£o de circuitos qu√¢nticos.\n",
        "  - **`qiskit.ibmq`**: Conex√£o com dispositivos qu√¢nticos reais na nuvem.\n",
        "  - **`qiskit.visualization`**: Visualiza√ß√£o de circuitos qu√¢nticos.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver aplica√ß√µes qu√¢nticas em √°reas como criptografia, otimiza√ß√£o, qu√≠mica e aprendizado de m√°quina.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `!pip install pennylane`**\n",
        "- **O que √© o PennyLane?**\n",
        "  - O PennyLane √© uma biblioteca de c√≥digo aberto para **computa√ß√£o qu√¢ntica diferencial**. Ele integra computa√ß√£o qu√¢ntica com aprendizado de m√°quina (AM) e frameworks como PyTorch, TensorFlow e NumPy.\n",
        "\n",
        "- **Principais Recursos do PennyLane:**\n",
        "  - Suporte a **diferencia√ß√£o autom√°tica**: Permite calcular gradientes de circuitos qu√¢nticos para ajustar par√¢metros durante o treinamento.\n",
        "  - Compatibilidade com dispositivos qu√¢nticos reais e simuladores.\n",
        "  - Ferramentas para implementar algoritmos h√≠bridos (qu√¢nticos e cl√°ssicos).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Criar modelos h√≠bridos que combinam redes neurais e circuitos qu√¢nticos.\n",
        "  - Aplicar aprendizado de m√°quina qu√¢ntico em tarefas como classifica√ß√£o, regress√£o e redu√ß√£o de dimensionalidade.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `!pip install tensorflow-quantum`**\n",
        "- **O que √© o TensorFlow Quantum (TFQ)?**\n",
        "  - O TensorFlow Quantum √© uma extens√£o do TensorFlow que facilita a integra√ß√£o de circuitos qu√¢nticos com aprendizado de m√°quina cl√°ssico.\n",
        "  - Ele √© desenvolvido pela Google AI e permite:\n",
        "    - Construir e treinar modelos h√≠bridos (qu√¢nticos e cl√°ssicos).\n",
        "    - Simular circuitos qu√¢nticos dentro do fluxo de trabalho do TensorFlow.\n",
        "\n",
        "- **Principais Recursos do TFQ:**\n",
        "  - **Integra√ß√£o com TensorFlow**: Usado com outras APIs TensorFlow, como `tf.keras` e `tf.data`.\n",
        "  - **Diferencia√ß√£o autom√°tica** para par√¢metros de circuitos qu√¢nticos.\n",
        "  - **Simuladores de dispositivos qu√¢nticos** otimizados para desempenho.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver modelos h√≠bridos para tarefas de aprendizado supervisionado, n√£o supervisionado e refor√ßado.\n",
        "  - Aplicar computa√ß√£o qu√¢ntica em AM em escala usando a infraestrutura do TensorFlow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `!pip install matplotlib`**\n",
        "- **O que √© o Matplotlib?**\n",
        "  - O Matplotlib √© uma biblioteca de Python usada para criar gr√°ficos est√°ticos, interativos e animados.\n",
        "\n",
        "- **Principais Recursos do Matplotlib:**\n",
        "  - Cria√ß√£o de gr√°ficos de linha, dispers√£o, histogramas, barras e muito mais.\n",
        "  - Personaliza√ß√£o total de estilos, r√≥tulos, t√≠tulos e cores.\n",
        "  - Compatibilidade com notebooks interativos (Jupyter Notebook, Google Colab).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Visualizar resultados de simula√ß√µes e treinamentos de modelos qu√¢nticos e cl√°ssicos.\n",
        "  - Interpretar dados e m√©tricas por meio de gr√°ficos.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `!pip install pillow`**\n",
        "- **O que √© o Pillow?**\n",
        "  - O Pillow (ou PIL, Python Imaging Library) √© uma biblioteca de manipula√ß√£o de imagens.\n",
        "\n",
        "- **Principais Recursos do Pillow:**\n",
        "  - Abrir, modificar e salvar imagens em v√°rios formatos (JPEG, PNG, BMP, etc.).\n",
        "  - Redimensionar, cortar, converter para escala de cinza e normalizar imagens.\n",
        "  - Integrar pipelines de vis√£o computacional.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Pr√©-processar dados de imagens antes de us√°-los em modelos qu√¢nticos ou cl√°ssicos.\n",
        "  - Trabalhar com datasets de imagens em tarefas de classifica√ß√£o ou detec√ß√£o de objetos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo e Prop√≥sito Geral**\n",
        "Esses pacotes combinados permitem a constru√ß√£o de modelos de aprendizado de m√°quina qu√¢nticos e h√≠bridos. Com eles, voc√™ pode:\n",
        "1. **Simular e executar circuitos qu√¢nticos**: Usando Qiskit e PennyLane.\n",
        "2. **Integrar computa√ß√£o qu√¢ntica e aprendizado de m√°quina cl√°ssico**: Com PennyLane e TensorFlow Quantum.\n",
        "3. **Pr√©-processar e visualizar dados**: Usando Matplotlib e Pillow.\n",
        "\n"
      ],
      "metadata": {
        "id": "JbK2j_xVL92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C√≥digo Completo para Carregar, Visualizar e Salvar as Imagens no Drive\n",
        "\n",
        "Aqui est√° o c√≥digo ajustado para solicitar o arquivo `melanomas.zip`, organizar, visualizar as imagens das classes, e salvar os dados processados na pasta \"quantum\" no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "#### **C√≥digo Ajustado**\n",
        "\n",
        "```python\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo n√£o encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extra√≠dos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"N√∫mero total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extra√≠dos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Fun√ß√£o para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padr√£o para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Passo a Passo do C√≥digo**\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para armazenar os dados processados.\n",
        "2. **Solicitar o Arquivo `melanomas.zip`**:\n",
        "   - O c√≥digo pede ao usu√°rio o caminho do arquivo ZIP no Drive.\n",
        "   - Exemplo: `/content/drive/My Drive/melanomas.zip`.\n",
        "3. **Extrair Imagens**:\n",
        "   - As imagens s√£o extra√≠das para a pasta tempor√°ria `/content/melanomas`.\n",
        "   - Apenas arquivos com extens√µes `.jpg` e `.png` s√£o inclu√≠dos.\n",
        "4. **Visualizar Imagens por Classe**:\n",
        "   - As imagens s√£o agrupadas com base no nome das subpastas (representando as classes).\n",
        "   - As primeiras `n` imagens de cada classe s√£o exibidas em gr√°ficos.\n",
        "5. **Salvar Imagens no Google Drive**:\n",
        "   - As imagens s√£o redimensionadas para 64x64 pixels.\n",
        "   - Elas s√£o organizadas em pastas no Drive, em `My Drive/quantum/<nome_da_classe>`.\n",
        "6. **Exibir Imagens Redimensionadas**:\n",
        "   - Ap√≥s salvar, as imagens redimensionadas s√£o exibidas novamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Exemplo de Execu√ß√£o**\n",
        "- O c√≥digo ir√°:\n",
        "  - Solicitar o arquivo `melanomas.zip`.\n",
        "  - Extrair e organizar as imagens por classe.\n",
        "  - Exibir as primeiras 5 imagens de cada classe.\n",
        "  - Salvar as imagens redimensionadas no Google Drive para posterior uso.\n",
        "\n"
      ],
      "metadata": {
        "id": "jFku01OHyA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo n√£o encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extra√≠dos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"N√∫mero total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extra√≠dos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Fun√ß√£o para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padr√£o para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n"
      ],
      "metadata": {
        "id": "kMS-AgHXM7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sim, podemos ajustar o c√≥digo para:\n",
        "\n",
        "1. **Visualizar a imagem original e redimensionada**.\n",
        "2. **Salvar os dados redimensionados em um DataFrame e export√°-lo para um arquivo, se necess√°rio.**\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado para Visualiza√ß√£o e Cria√ß√£o de DataFrame\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fun√ß√£o para processar e redimensionar imagens\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "    \n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "sample_image_path = extracted_files[0]\n",
        "processed_image = process_and_visualize_image(sample_image_path)\n",
        "\n",
        "# Criar um DataFrame com os dados redimensionados\n",
        "def create_dataframe(image_paths, resize_to=(64, 64)):\n",
        "    \"\"\"Processa imagens e cria um DataFrame com arrays normalizados\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image_resized = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image_resized).flatten() / 255.0  # Achatar a matriz\n",
        "        \n",
        "        # Obter o r√≥tulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "    \n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "    return df\n",
        "\n",
        "# Criar o DataFrame com todas as imagens\n",
        "df = create_dataframe(extracted_files)\n",
        "\n",
        "# Visualizar parte do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "output_path = \"processed_images.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"DataFrame salvo em: {output_path}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explica√ß√£o do C√≥digo\n",
        "\n",
        "1. **Visualiza√ß√£o da Imagem**:\n",
        "   - A fun√ß√£o `process_and_visualize_image` exibe a imagem original e a redimensionada lado a lado.\n",
        "\n",
        "2. **Cria√ß√£o do DataFrame**:\n",
        "   - Cada imagem √© convertida para um array 1D (achatar a matriz).\n",
        "   - Os arrays s√£o armazenados como linhas no DataFrame, com uma coluna adicional para os r√≥tulos das classes.\n",
        "\n",
        "3. **Exporta√ß√£o para CSV**:\n",
        "   - O DataFrame √© salvo em um arquivo CSV (`processed_images.csv`), para ser reutilizado posteriormente.\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "- Voc√™ ver√° a imagem original e redimensionada para confirmar o processo de redimensionamento.\n",
        "- O DataFrame conter√° os dados de todas as imagens redimensionadas e seus r√≥tulos de classe.\n",
        "- O arquivo CSV permitir√° reutilizar os dados sem necessidade de processar as imagens novamente.\n",
        "\n",
        "Teste o c√≥digo e informe se precisar de mais ajustes! üòä"
      ],
      "metadata": {
        "id": "6PgjAaxZyotH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Fun√ß√£o para processar e visualizar uma √∫nica imagem\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "\n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "if len(extracted_files) > 0:\n",
        "    sample_image_path = extracted_files[0]\n",
        "    processed_image = process_and_visualize_image(sample_image_path)\n",
        "else:\n",
        "    print(\"Nenhuma imagem foi encontrada para processamento.\")\n",
        "\n",
        "# Fun√ß√£o para processar todas as imagens e criar um DataFrame\n",
        "def create_dataframe_and_save_images(image_paths, resize_to=(64, 64), save_dir=output_dir):\n",
        "    \"\"\"Processa imagens, cria um DataFrame e salva imagens redimensionadas\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image).flatten() / 255.0  # Achatar a matriz\n",
        "\n",
        "        # Obter o r√≥tulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame na pasta \"quantum\"\n",
        "    df_output_path = os.path.join(save_dir, \"processed_images.csv\")\n",
        "    df.to_csv(df_output_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {df_output_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar imagens e salvar no Google Drive\n",
        "if len(extracted_files) > 0:\n",
        "    df = create_dataframe_and_save_images(extracted_files)\n",
        "    print(\"Primeiras linhas do DataFrame:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Nenhuma imagem encontrada para criar o DataFrame.\")\n"
      ],
      "metadata": {
        "id": "aw1NqaInzH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C√≥digo Ajustado para Visualizar, Normalizar Imagens e Salvar no Drive\n",
        "\n",
        "Este √© o c√≥digo modificado para salvar o DataFrame e imagens no Google Drive dentro da pasta \"quantum\". Ele processa as imagens, exibe as visualiza√ß√µes necess√°rias, cria um DataFrame e salva os resultados.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Fun√ß√£o para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "    \n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normaliza√ß√£o\n",
        "        \n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "        \n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diret√≥rio\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualiza√ß√£o e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Fun√ß√£o para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "    \n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explica√ß√£o do C√≥digo**\n",
        "\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para salvar os arquivos na pasta \"quantum\".\n",
        "\n",
        "2. **Visualiza√ß√£o e Processamento das Imagens**:\n",
        "   - Processa as imagens para redimension√°-las a um tamanho padr√£o de \\(64 \\times 64\\).\n",
        "   - Normaliza os valores dos pixels para o intervalo \\([0, 1]\\).\n",
        "   - Exibe as imagens originais e redimensionadas lado a lado.\n",
        "\n",
        "3. **Salvar Imagens Processadas**:\n",
        "   - As imagens redimensionadas s√£o salvas na pasta \"quantum\", organizadas por subpastas das classes.\n",
        "\n",
        "4. **Cria√ß√£o do DataFrame**:\n",
        "   - Cria um DataFrame com:\n",
        "     - Vetores achatados das imagens (uma linha por imagem).\n",
        "     - R√≥tulos das classes como uma coluna separada.\n",
        "   - Salva o DataFrame no formato CSV na pasta \"quantum\".\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualiza√ß√£o de Imagens**:\n",
        "   - As imagens originais e redimensionadas s√£o exibidas no Colab.\n",
        "\n",
        "2. **Pasta `quantum` no Drive**:\n",
        "   - Cont√©m subpastas para cada classe, com as imagens redimensionadas salvas.\n",
        "   - Um arquivo `processed_images_with_labels.csv` com os arrays das imagens e os r√≥tulos.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - Um DataFrame com as imagens processadas e normalizadas, incluindo os r√≥tulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "me-sYB307FFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Fun√ß√£o para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normaliza√ß√£o\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diret√≥rio\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualiza√ß√£o e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Fun√ß√£o para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "rk1TQzrJ6HJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado para salvar na pasta `quantum` no Google Drive e incluir todas as funcionalidades mencionadas: visualiza√ß√£o, normaliza√ß√£o, divis√£o dos dados e salvamento em DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo r√≥tulos de texto para valores num√©ricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualiza√ß√£o de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar r√≥tulo num√©rico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os r√≥tulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os r√≥tulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Este C√≥digo Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Monta o Google Drive para salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "2. **Processamento de R√≥tulos e Dados**:\n",
        "   - Converte r√≥tulos textuais em valores num√©ricos usando `LabelEncoder`.\n",
        "   - Redimensiona e achata as imagens processadas para vetores 1D.\n",
        "\n",
        "3. **Divis√£o de Dados**:\n",
        "   - Divide os dados em conjuntos de treino e teste usando `train_test_split`.\n",
        "\n",
        "4. **Visualiza√ß√£o**:\n",
        "   - Exibe algumas imagens do conjunto de treino com seus r√≥tulos decodificados.\n",
        "   - Mostra parte das matrizes normalizadas de cada imagem.\n",
        "\n",
        "5. **Cria√ß√£o de DataFrames**:\n",
        "   - Cria DataFrames para os conjuntos de treino e teste.\n",
        "   - Adiciona os r√≥tulos decodificados como uma coluna.\n",
        "\n",
        "6. **Salvamento**:\n",
        "   - Salva os DataFrames como arquivos CSV (`train_data.csv` e `test_data.csv`) na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualiza√ß√µes**:\n",
        "   - Exibi√ß√£o de 5 imagens do conjunto de treino com seus r√≥tulos decodificados.\n",
        "   - Matrizes normalizadas das imagens para an√°lise.\n",
        "\n",
        "2. **Arquivos CSV**:\n",
        "   - Arquivos `train_data.csv` e `test_data.csv` contendo os dados processados e os r√≥tulos, salvos na pasta `quantum`.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - DataFrames contendo:\n",
        "     - Colunas com os valores achatados dos pixels.\n",
        "     - Coluna `label` com os r√≥tulos das imagens.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TROm3P5W8Isd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo r√≥tulos de texto para valores num√©ricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualiza√ß√£o de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar r√≥tulo num√©rico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os r√≥tulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os r√≥tulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado para salvar os resultados no Google Drive na pasta **quantum**, com todas as explica√ß√µes e etapas necess√°rias para an√°lise e visualiza√ß√£o avan√ßada:\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribui√ß√£o das Previs√µes por Classe\")\n",
        "    plt.xlabel(\"Previs√£o\")\n",
        "    plt.ylabel(\"Frequ√™ncia\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar r√≥tulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simula√ß√£o de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipot√©tico para rodar o c√≥digo:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com r√≥tulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Esse C√≥digo Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Salva os arquivos na pasta `quantum` no Google Drive.\n",
        "\n",
        "2. **Processamento Qu√¢ntico**:\n",
        "   - Cada amostra de imagem √© normalizada, redimensionada e processada por um circuito qu√¢ntico.\n",
        "   - O circuito aplica rota√ß√µes \\( RY \\) para incorporar os dados e usa camadas de entanglement para capturar correla√ß√µes.\n",
        "\n",
        "3. **Divis√£o de Dados**:\n",
        "   - As imagens e os r√≥tulos s√£o divididos em conjuntos de treino e teste.\n",
        "\n",
        "4. **Cria√ß√£o de DataFrames**:\n",
        "   - Cria DataFrames para treino e teste contendo:\n",
        "     - `features`: Dados normalizados e achatados.\n",
        "     - `label`: Classe da amostra.\n",
        "     - `prediction`: Sa√≠da do circuito qu√¢ntico.\n",
        "     - `residual`: Diferen√ßa entre previs√£o e r√≥tulo.\n",
        "\n",
        "5. **Salvamento de Resultados**:\n",
        "   - Salva os DataFrames (`train_data_quantum.csv`, `test_data_quantum.csv`) na pasta `quantum`.\n",
        "\n",
        "6. **Visualiza√ß√£o**:\n",
        "   - Exibe histogramas das previs√µes para cada classe.\n",
        "   - Mostra o circuito qu√¢ntico usado para processar algumas amostras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `train_data_quantum.csv` e `test_data_quantum.csv` contendo os resultados processados.\n",
        "\n",
        "2. **Visualiza√ß√µes**:\n",
        "   - Histogramas mostrando a distribui√ß√£o das previs√µes por classe.\n",
        "   - Circuitos desenhados para algumas amostras, mostrando as rota√ß√µes \\( RY \\) e as camadas de entanglement.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VemAfafo_VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribui√ß√£o das Previs√µes por Classe\")\n",
        "    plt.xlabel(\"Previs√£o\")\n",
        "    plt.ylabel(\"Frequ√™ncia\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar r√≥tulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simula√ß√£o de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipot√©tico para rodar o c√≥digo:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com r√≥tulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado que inclui **Early Stopping** e **parametriza√ß√£o dos embeddings** para um melhor equil√≠brio durante o treinamento e avalia√ß√£o do modelo qu√¢ntico, salvando todos os resultados na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **C√≥digo com Early Stopping e Parametriza√ß√£o**\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Camadas do modelo qu√¢ntico\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico parametrizada\n",
        "def data_embedding(features, wires, scale=1.0):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i] * scale, wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features, scale=1.0):\n",
        "    data_embedding(features, range(n_qubits), scale)\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features, scale=1.0):\n",
        "    return quantum_model(weights, features, scale)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y, scale=1.0):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i], scale)\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicializa√ß√£o de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configura√ß√£o do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # N√∫mero de itera√ß√µes\n",
        "early_stopping_patience = 10  # Crit√©rio de Early Stopping\n",
        "min_delta = 1e-4  # Toler√¢ncia m√≠nima para melhoria no custo\n",
        "\n",
        "# Dados ajustados\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Vari√°veis para Early Stopping\n",
        "best_weights = None\n",
        "best_test_cost = float('inf')\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train, scale=1.0), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "    test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "    \n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    \n",
        "    # Early Stopping\n",
        "    if test_cost < best_test_cost - min_delta:\n",
        "        best_test_cost = test_cost\n",
        "        best_weights = weights\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "    \n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Parada antecipada no passo {step}. Melhor custo no teste: {best_test_cost:.4f}\")\n",
        "        break\n",
        "    \n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Usar os melhores pesos encontrados\n",
        "weights = best_weights\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previs√µes\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Cria√ß√£o do DataFrame com res√≠duos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "\n",
        "# 1. Gr√°fico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(len(train_costs)), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(len(test_costs)), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolu√ß√£o do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gr√°fico de dispers√£o (predi√ß√£o vs r√≥tulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispers√£o: Previs√£o vs R√≥tulo\")\n",
        "plt.xlabel(\"R√≥tulo Verdadeiro\")\n",
        "plt.ylabel(\"Previs√£o\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de res√≠duos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribui√ß√£o dos Res√≠duos\")\n",
        "plt.xlabel(\"Res√≠duo\")\n",
        "plt.ylabel(\"Frequ√™ncia\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explica√ß√µes Adicionais**\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Interrompe o treinamento se n√£o houver melhoria significativa no custo do conjunto de teste por um n√∫mero definido de itera√ß√µes (`early_stopping_patience`).\n",
        "\n",
        "2. **Parametriza√ß√£o dos Embeddings**:\n",
        "   - Permite ajustar o impacto dos valores de entrada nos qubits, usando o par√¢metro `scale`.\n",
        "\n",
        "3. **Resultados Salvos**:\n",
        "   - Arquivo `quantum_model_results.csv` com previs√µes, res√≠duos e features.\n",
        "   - Gr√°ficos salvos na pasta `quantum`:\n",
        "     - `training_costs.png`\n",
        "     - `scatter_predictions.png`\n",
        "     - `residuals_histogram.png`\n",
        "\n"
      ],
      "metadata": {
        "id": "ztUtdHcjEZI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O c√≥digo em execu√ß√£o combina **aprendizado qu√¢ntico** e **otimiza√ß√£o cl√°ssica** para treinar um modelo qu√¢ntico, salvando os resultados e visualiza√ß√µes no Google Drive, dentro da pasta `quantum`. Aqui est√° o que ocorre em cada etapa e o que esperar dos resultados:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Configura√ß√£o do Ambiente**\n",
        "- Monta o Google Drive e cria a pasta `quantum` para armazenar os resultados.\n",
        "- Configura o dispositivo qu√¢ntico `default.qubit` com 10 qubits e 4 camadas no circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Embedding Qu√¢ntico**\n",
        "- Converte os dados cl√°ssicos (`features`) em rota√ß√µes \\( RY \\), mapeando-os para o espa√ßo qu√¢ntico.\n",
        "- O par√¢metro `scale` ajusta a amplitude das rota√ß√µes, permitindo balancear a influ√™ncia dos dados.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Modelo e Circuito**\n",
        "- **Camadas Entangled**:\n",
        "  - Introduzem correla√ß√µes qu√¢nticas entre os qubits, aumentando a capacidade do modelo.\n",
        "- **Expectativa \\( \\langle Z \\rangle \\)**:\n",
        "  - Mede a proje√ß√£o dos estados qu√¢nticos no eixo \\( Z \\), gerando uma sa√≠da cont√≠nua para cada entrada.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Fun√ß√£o de Custo**\n",
        "- Calcula o **Erro Quadr√°tico M√©dio (MSE)** entre as previs√µes e os r√≥tulos verdadeiros.\n",
        "- √â usado pelo otimizador para ajustar os pesos do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Otimiza√ß√£o com Early Stopping**\n",
        "- **AdamOptimizer**:\n",
        "  - Atualiza os pesos do circuito para minimizar o custo.\n",
        "- **Early Stopping**:\n",
        "  - Monitora o custo no conjunto de teste.\n",
        "  - Para o treinamento se n√£o houver melhoria ap√≥s 10 itera√ß√µes consecutivas (definido por `early_stopping_patience`).\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Avalia√ß√£o**\n",
        "- Ap√≥s o treinamento, calcula o custo final para os conjuntos de treino e teste.\n",
        "- Usa os pesos ajustados para gerar previs√µes para ambos os conjuntos.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Resultados no DataFrame**\n",
        "- O `df_results` inclui:\n",
        "  - **`train_features`** e **`test_features`**: Dados de entrada (ap√≥s redimensionamento).\n",
        "  - **`train_labels`** e **`test_labels`**: R√≥tulos verdadeiros.\n",
        "  - **`train_predictions`** e **`test_predictions`**: Previs√µes do modelo.\n",
        "  - **`train_residuals`** e **`test_residuals`**: Diferen√ßa entre previs√£o e r√≥tulo verdadeiro (erros).\n",
        "- Salva o DataFrame como `quantum_model_results.csv` na pasta `quantum`.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Visualiza√ß√µes**\n",
        "#### **Gr√°fico de Custo**\n",
        "- Mostra a evolu√ß√£o do custo durante o treinamento.\n",
        "- **Azul**: Custo no conjunto de treino.\n",
        "- **Laranja**: Custo no conjunto de teste.\n",
        "  \n",
        "#### **Gr√°fico de Dispers√£o**\n",
        "- Compara previs√µes e r√≥tulos verdadeiros.\n",
        "- Padr√£o esperado:\n",
        "  - Pontos pr√≥ximos √† linha \\( y = x \\) indicam previs√µes precisas.\n",
        "\n",
        "#### **Histograma de Res√≠duos**\n",
        "- Mostra a distribui√ß√£o dos erros (previs√£o - r√≥tulo).\n",
        "- Res√≠duos pr√≥ximos de zero indicam um bom ajuste.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "1. **Treinamento**:\n",
        "   - Redu√ß√£o do custo nos conjuntos de treino e teste ao longo das itera√ß√µes.\n",
        "   - Early Stopping pode ocorrer se o custo no teste estabilizar.\n",
        "\n",
        "2. **Visualiza√ß√µes**:\n",
        "   - Gr√°ficos salvos na pasta `quantum`:\n",
        "     - `training_costs.png`: Evolu√ß√£o do custo.\n",
        "     - `scatter_predictions.png`: Dispers√£o previs√£o vs r√≥tulo.\n",
        "     - `residuals_histogram.png`: Distribui√ß√£o dos res√≠duos.\n",
        "\n",
        "3. **Arquivo CSV**:\n",
        "   - **`quantum_model_results.csv`**: Cont√©m previs√µes, res√≠duos e features, permitindo an√°lise detalhada.\n",
        "\n",
        "Se o processamento ainda est√° em andamento, aguarde os gr√°ficos e o arquivo `quantum_model_results.csv` no Drive para valida√ß√£o dos resultados. üòä"
      ],
      "metadata": {
        "id": "B9b2wMTMYqrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Camadas do modelo qu√¢ntico\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico parametrizada\n",
        "def data_embedding(features, wires, scale=1.0):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i] * scale, wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features, scale=1.0):\n",
        "    data_embedding(features, range(n_qubits), scale)\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features, scale=1.0):\n",
        "    return quantum_model(weights, features, scale)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y, scale=1.0):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i], scale)\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicializa√ß√£o de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configura√ß√£o do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # N√∫mero de itera√ß√µes\n",
        "early_stopping_patience = 10  # Crit√©rio de Early Stopping\n",
        "min_delta = 1e-4  # Toler√¢ncia m√≠nima para melhoria no custo\n",
        "\n",
        "# Dados ajustados\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Vari√°veis para Early Stopping\n",
        "best_weights = None\n",
        "best_test_cost = float('inf')\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train, scale=1.0), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "    test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Early Stopping\n",
        "    if test_cost < best_test_cost - min_delta:\n",
        "        best_test_cost = test_cost\n",
        "        best_weights = weights\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Parada antecipada no passo {step}. Melhor custo no teste: {best_test_cost:.4f}\")\n",
        "        break\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Usar os melhores pesos encontrados\n",
        "weights = best_weights\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previs√µes\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Cria√ß√£o do DataFrame com res√≠duos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "\n",
        "# 1. Gr√°fico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(len(train_costs)), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(len(test_costs)), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolu√ß√£o do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gr√°fico de dispers√£o (predi√ß√£o vs r√≥tulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispers√£o: Previs√£o vs R√≥tulo\")\n",
        "plt.xlabel(\"R√≥tulo Verdadeiro\")\n",
        "plt.ylabel(\"Previs√£o\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de res√≠duos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribui√ß√£o dos Res√≠duos\")\n",
        "plt.xlabel(\"Res√≠duo\")\n",
        "plt.ylabel(\"Frequ√™ncia\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MTG1MV9QDpw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}