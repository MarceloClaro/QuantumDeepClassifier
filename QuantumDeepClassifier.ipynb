{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2J9wVr14Zw0upSD/PNxji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explica√ß√£o dos Comandos de Instala√ß√£o**\n",
        "\n",
        "Os comandos listados utilizam o gerenciador de pacotes **pip** para instalar bibliotecas espec√≠ficas que s√£o usadas em computa√ß√£o qu√¢ntica, aprendizado de m√°quina e visualiza√ß√£o de dados. Abaixo, explico cada uma delas:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. `!pip install qiskit`**\n",
        "- **O que √© o Qiskit?**\n",
        "  - O Qiskit √© uma biblioteca de c√≥digo aberto para computa√ß√£o qu√¢ntica desenvolvida pela IBM. Ele permite:\n",
        "    - Criar, simular e executar circuitos qu√¢nticos.\n",
        "    - Realizar experimentos em computadores qu√¢nticos reais da IBM Quantum ou simuladores locais.\n",
        "    - Trabalhar com algoritmos qu√¢nticos, como **VQE**, **QAOA** e **Shor**.\n",
        "\n",
        "- **Principais M√≥dulos do Qiskit:**\n",
        "  - **`qiskit.circuit`**: Cria√ß√£o de circuitos qu√¢nticos.\n",
        "  - **`qiskit.aer`**: Simula√ß√£o de circuitos qu√¢nticos.\n",
        "  - **`qiskit.ibmq`**: Conex√£o com dispositivos qu√¢nticos reais na nuvem.\n",
        "  - **`qiskit.visualization`**: Visualiza√ß√£o de circuitos qu√¢nticos.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver aplica√ß√µes qu√¢nticas em √°reas como criptografia, otimiza√ß√£o, qu√≠mica e aprendizado de m√°quina.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `!pip install pennylane`**\n",
        "- **O que √© o PennyLane?**\n",
        "  - O PennyLane √© uma biblioteca de c√≥digo aberto para **computa√ß√£o qu√¢ntica diferencial**. Ele integra computa√ß√£o qu√¢ntica com aprendizado de m√°quina (AM) e frameworks como PyTorch, TensorFlow e NumPy.\n",
        "\n",
        "- **Principais Recursos do PennyLane:**\n",
        "  - Suporte a **diferencia√ß√£o autom√°tica**: Permite calcular gradientes de circuitos qu√¢nticos para ajustar par√¢metros durante o treinamento.\n",
        "  - Compatibilidade com dispositivos qu√¢nticos reais e simuladores.\n",
        "  - Ferramentas para implementar algoritmos h√≠bridos (qu√¢nticos e cl√°ssicos).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Criar modelos h√≠bridos que combinam redes neurais e circuitos qu√¢nticos.\n",
        "  - Aplicar aprendizado de m√°quina qu√¢ntico em tarefas como classifica√ß√£o, regress√£o e redu√ß√£o de dimensionalidade.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `!pip install tensorflow-quantum`**\n",
        "- **O que √© o TensorFlow Quantum (TFQ)?**\n",
        "  - O TensorFlow Quantum √© uma extens√£o do TensorFlow que facilita a integra√ß√£o de circuitos qu√¢nticos com aprendizado de m√°quina cl√°ssico.\n",
        "  - Ele √© desenvolvido pela Google AI e permite:\n",
        "    - Construir e treinar modelos h√≠bridos (qu√¢nticos e cl√°ssicos).\n",
        "    - Simular circuitos qu√¢nticos dentro do fluxo de trabalho do TensorFlow.\n",
        "\n",
        "- **Principais Recursos do TFQ:**\n",
        "  - **Integra√ß√£o com TensorFlow**: Usado com outras APIs TensorFlow, como `tf.keras` e `tf.data`.\n",
        "  - **Diferencia√ß√£o autom√°tica** para par√¢metros de circuitos qu√¢nticos.\n",
        "  - **Simuladores de dispositivos qu√¢nticos** otimizados para desempenho.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver modelos h√≠bridos para tarefas de aprendizado supervisionado, n√£o supervisionado e refor√ßado.\n",
        "  - Aplicar computa√ß√£o qu√¢ntica em AM em escala usando a infraestrutura do TensorFlow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `!pip install matplotlib`**\n",
        "- **O que √© o Matplotlib?**\n",
        "  - O Matplotlib √© uma biblioteca de Python usada para criar gr√°ficos est√°ticos, interativos e animados.\n",
        "\n",
        "- **Principais Recursos do Matplotlib:**\n",
        "  - Cria√ß√£o de gr√°ficos de linha, dispers√£o, histogramas, barras e muito mais.\n",
        "  - Personaliza√ß√£o total de estilos, r√≥tulos, t√≠tulos e cores.\n",
        "  - Compatibilidade com notebooks interativos (Jupyter Notebook, Google Colab).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Visualizar resultados de simula√ß√µes e treinamentos de modelos qu√¢nticos e cl√°ssicos.\n",
        "  - Interpretar dados e m√©tricas por meio de gr√°ficos.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `!pip install pillow`**\n",
        "- **O que √© o Pillow?**\n",
        "  - O Pillow (ou PIL, Python Imaging Library) √© uma biblioteca de manipula√ß√£o de imagens.\n",
        "\n",
        "- **Principais Recursos do Pillow:**\n",
        "  - Abrir, modificar e salvar imagens em v√°rios formatos (JPEG, PNG, BMP, etc.).\n",
        "  - Redimensionar, cortar, converter para escala de cinza e normalizar imagens.\n",
        "  - Integrar pipelines de vis√£o computacional.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Pr√©-processar dados de imagens antes de us√°-los em modelos qu√¢nticos ou cl√°ssicos.\n",
        "  - Trabalhar com datasets de imagens em tarefas de classifica√ß√£o ou detec√ß√£o de objetos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo e Prop√≥sito Geral**\n",
        "Esses pacotes combinados permitem a constru√ß√£o de modelos de aprendizado de m√°quina qu√¢nticos e h√≠bridos. Com eles, voc√™ pode:\n",
        "1. **Simular e executar circuitos qu√¢nticos**: Usando Qiskit e PennyLane.\n",
        "2. **Integrar computa√ß√£o qu√¢ntica e aprendizado de m√°quina cl√°ssico**: Com PennyLane e TensorFlow Quantum.\n",
        "3. **Pr√©-processar e visualizar dados**: Usando Matplotlib e Pillow.\n",
        "\n"
      ],
      "metadata": {
        "id": "JbK2j_xVL92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C√≥digo Completo para Carregar, Visualizar e Salvar as Imagens no Drive\n",
        "\n",
        "Aqui est√° o c√≥digo ajustado para solicitar o arquivo `melanomas.zip`, organizar, visualizar as imagens das classes, e salvar os dados processados na pasta \"quantum\" no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "#### **C√≥digo Ajustado**\n",
        "\n",
        "```python\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo n√£o encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extra√≠dos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"N√∫mero total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extra√≠dos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Fun√ß√£o para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padr√£o para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Passo a Passo do C√≥digo**\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para armazenar os dados processados.\n",
        "2. **Solicitar o Arquivo `melanomas.zip`**:\n",
        "   - O c√≥digo pede ao usu√°rio o caminho do arquivo ZIP no Drive.\n",
        "   - Exemplo: `/content/drive/My Drive/melanomas.zip`.\n",
        "3. **Extrair Imagens**:\n",
        "   - As imagens s√£o extra√≠das para a pasta tempor√°ria `/content/melanomas`.\n",
        "   - Apenas arquivos com extens√µes `.jpg` e `.png` s√£o inclu√≠dos.\n",
        "4. **Visualizar Imagens por Classe**:\n",
        "   - As imagens s√£o agrupadas com base no nome das subpastas (representando as classes).\n",
        "   - As primeiras `n` imagens de cada classe s√£o exibidas em gr√°ficos.\n",
        "5. **Salvar Imagens no Google Drive**:\n",
        "   - As imagens s√£o redimensionadas para 64x64 pixels.\n",
        "   - Elas s√£o organizadas em pastas no Drive, em `My Drive/quantum/<nome_da_classe>`.\n",
        "6. **Exibir Imagens Redimensionadas**:\n",
        "   - Ap√≥s salvar, as imagens redimensionadas s√£o exibidas novamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Exemplo de Execu√ß√£o**\n",
        "- O c√≥digo ir√°:\n",
        "  - Solicitar o arquivo `melanomas.zip`.\n",
        "  - Extrair e organizar as imagens por classe.\n",
        "  - Exibir as primeiras 5 imagens de cada classe.\n",
        "  - Salvar as imagens redimensionadas no Google Drive para posterior uso.\n",
        "\n"
      ],
      "metadata": {
        "id": "jFku01OHyA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo n√£o encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extra√≠dos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"N√∫mero total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extra√≠dos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Fun√ß√£o para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padr√£o para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n"
      ],
      "metadata": {
        "id": "kMS-AgHXM7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sim, podemos ajustar o c√≥digo para:\n",
        "\n",
        "1. **Visualizar a imagem original e redimensionada**.\n",
        "2. **Salvar os dados redimensionados em um DataFrame e export√°-lo para um arquivo, se necess√°rio.**\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado para Visualiza√ß√£o e Cria√ß√£o de DataFrame\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fun√ß√£o para processar e redimensionar imagens\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "    \n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "sample_image_path = extracted_files[0]\n",
        "processed_image = process_and_visualize_image(sample_image_path)\n",
        "\n",
        "# Criar um DataFrame com os dados redimensionados\n",
        "def create_dataframe(image_paths, resize_to=(64, 64)):\n",
        "    \"\"\"Processa imagens e cria um DataFrame com arrays normalizados\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image_resized = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image_resized).flatten() / 255.0  # Achatar a matriz\n",
        "        \n",
        "        # Obter o r√≥tulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "    \n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "    return df\n",
        "\n",
        "# Criar o DataFrame com todas as imagens\n",
        "df = create_dataframe(extracted_files)\n",
        "\n",
        "# Visualizar parte do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "output_path = \"processed_images.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"DataFrame salvo em: {output_path}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explica√ß√£o do C√≥digo\n",
        "\n",
        "1. **Visualiza√ß√£o da Imagem**:\n",
        "   - A fun√ß√£o `process_and_visualize_image` exibe a imagem original e a redimensionada lado a lado.\n",
        "\n",
        "2. **Cria√ß√£o do DataFrame**:\n",
        "   - Cada imagem √© convertida para um array 1D (achatar a matriz).\n",
        "   - Os arrays s√£o armazenados como linhas no DataFrame, com uma coluna adicional para os r√≥tulos das classes.\n",
        "\n",
        "3. **Exporta√ß√£o para CSV**:\n",
        "   - O DataFrame √© salvo em um arquivo CSV (`processed_images.csv`), para ser reutilizado posteriormente.\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "- Voc√™ ver√° a imagem original e redimensionada para confirmar o processo de redimensionamento.\n",
        "- O DataFrame conter√° os dados de todas as imagens redimensionadas e seus r√≥tulos de classe.\n",
        "- O arquivo CSV permitir√° reutilizar os dados sem necessidade de processar as imagens novamente.\n",
        "\n",
        "Teste o c√≥digo e informe se precisar de mais ajustes! üòä"
      ],
      "metadata": {
        "id": "6PgjAaxZyotH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Fun√ß√£o para processar e visualizar uma √∫nica imagem\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "\n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "if len(extracted_files) > 0:\n",
        "    sample_image_path = extracted_files[0]\n",
        "    processed_image = process_and_visualize_image(sample_image_path)\n",
        "else:\n",
        "    print(\"Nenhuma imagem foi encontrada para processamento.\")\n",
        "\n",
        "# Fun√ß√£o para processar todas as imagens e criar um DataFrame\n",
        "def create_dataframe_and_save_images(image_paths, resize_to=(64, 64), save_dir=output_dir):\n",
        "    \"\"\"Processa imagens, cria um DataFrame e salva imagens redimensionadas\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image).flatten() / 255.0  # Achatar a matriz\n",
        "\n",
        "        # Obter o r√≥tulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame na pasta \"quantum\"\n",
        "    df_output_path = os.path.join(save_dir, \"processed_images.csv\")\n",
        "    df.to_csv(df_output_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {df_output_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar imagens e salvar no Google Drive\n",
        "if len(extracted_files) > 0:\n",
        "    df = create_dataframe_and_save_images(extracted_files)\n",
        "    print(\"Primeiras linhas do DataFrame:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Nenhuma imagem encontrada para criar o DataFrame.\")\n"
      ],
      "metadata": {
        "id": "aw1NqaInzH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C√≥digo Ajustado para Visualizar, Normalizar Imagens e Salvar no Drive\n",
        "\n",
        "Este √© o c√≥digo modificado para salvar o DataFrame e imagens no Google Drive dentro da pasta \"quantum\". Ele processa as imagens, exibe as visualiza√ß√µes necess√°rias, cria um DataFrame e salva os resultados.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Fun√ß√£o para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "    \n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normaliza√ß√£o\n",
        "        \n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "        \n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diret√≥rio\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualiza√ß√£o e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Fun√ß√£o para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "    \n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explica√ß√£o do C√≥digo**\n",
        "\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para salvar os arquivos na pasta \"quantum\".\n",
        "\n",
        "2. **Visualiza√ß√£o e Processamento das Imagens**:\n",
        "   - Processa as imagens para redimension√°-las a um tamanho padr√£o de \\(64 \\times 64\\).\n",
        "   - Normaliza os valores dos pixels para o intervalo \\([0, 1]\\).\n",
        "   - Exibe as imagens originais e redimensionadas lado a lado.\n",
        "\n",
        "3. **Salvar Imagens Processadas**:\n",
        "   - As imagens redimensionadas s√£o salvas na pasta \"quantum\", organizadas por subpastas das classes.\n",
        "\n",
        "4. **Cria√ß√£o do DataFrame**:\n",
        "   - Cria um DataFrame com:\n",
        "     - Vetores achatados das imagens (uma linha por imagem).\n",
        "     - R√≥tulos das classes como uma coluna separada.\n",
        "   - Salva o DataFrame no formato CSV na pasta \"quantum\".\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualiza√ß√£o de Imagens**:\n",
        "   - As imagens originais e redimensionadas s√£o exibidas no Colab.\n",
        "\n",
        "2. **Pasta `quantum` no Drive**:\n",
        "   - Cont√©m subpastas para cada classe, com as imagens redimensionadas salvas.\n",
        "   - Um arquivo `processed_images_with_labels.csv` com os arrays das imagens e os r√≥tulos.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - Um DataFrame com as imagens processadas e normalizadas, incluindo os r√≥tulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "me-sYB307FFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Fun√ß√£o para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normaliza√ß√£o\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diret√≥rio\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualiza√ß√£o e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Fun√ß√£o para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "rk1TQzrJ6HJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado para salvar na pasta `quantum` no Google Drive e incluir todas as funcionalidades mencionadas: visualiza√ß√£o, normaliza√ß√£o, divis√£o dos dados e salvamento em DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo r√≥tulos de texto para valores num√©ricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualiza√ß√£o de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar r√≥tulo num√©rico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os r√≥tulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os r√≥tulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Este C√≥digo Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Monta o Google Drive para salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "2. **Processamento de R√≥tulos e Dados**:\n",
        "   - Converte r√≥tulos textuais em valores num√©ricos usando `LabelEncoder`.\n",
        "   - Redimensiona e achata as imagens processadas para vetores 1D.\n",
        "\n",
        "3. **Divis√£o de Dados**:\n",
        "   - Divide os dados em conjuntos de treino e teste usando `train_test_split`.\n",
        "\n",
        "4. **Visualiza√ß√£o**:\n",
        "   - Exibe algumas imagens do conjunto de treino com seus r√≥tulos decodificados.\n",
        "   - Mostra parte das matrizes normalizadas de cada imagem.\n",
        "\n",
        "5. **Cria√ß√£o de DataFrames**:\n",
        "   - Cria DataFrames para os conjuntos de treino e teste.\n",
        "   - Adiciona os r√≥tulos decodificados como uma coluna.\n",
        "\n",
        "6. **Salvamento**:\n",
        "   - Salva os DataFrames como arquivos CSV (`train_data.csv` e `test_data.csv`) na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualiza√ß√µes**:\n",
        "   - Exibi√ß√£o de 5 imagens do conjunto de treino com seus r√≥tulos decodificados.\n",
        "   - Matrizes normalizadas das imagens para an√°lise.\n",
        "\n",
        "2. **Arquivos CSV**:\n",
        "   - Arquivos `train_data.csv` e `test_data.csv` contendo os dados processados e os r√≥tulos, salvos na pasta `quantum`.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - DataFrames contendo:\n",
        "     - Colunas com os valores achatados dos pixels.\n",
        "     - Coluna `label` com os r√≥tulos das imagens.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TROm3P5W8Isd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo r√≥tulos de texto para valores num√©ricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualiza√ß√£o de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar r√≥tulo num√©rico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os r√≥tulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os r√≥tulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado para salvar os resultados no Google Drive na pasta **quantum**, com todas as explica√ß√µes e etapas necess√°rias para an√°lise e visualiza√ß√£o avan√ßada:\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribui√ß√£o das Previs√µes por Classe\")\n",
        "    plt.xlabel(\"Previs√£o\")\n",
        "    plt.ylabel(\"Frequ√™ncia\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar r√≥tulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simula√ß√£o de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipot√©tico para rodar o c√≥digo:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com r√≥tulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Esse C√≥digo Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Salva os arquivos na pasta `quantum` no Google Drive.\n",
        "\n",
        "2. **Processamento Qu√¢ntico**:\n",
        "   - Cada amostra de imagem √© normalizada, redimensionada e processada por um circuito qu√¢ntico.\n",
        "   - O circuito aplica rota√ß√µes \\( RY \\) para incorporar os dados e usa camadas de entanglement para capturar correla√ß√µes.\n",
        "\n",
        "3. **Divis√£o de Dados**:\n",
        "   - As imagens e os r√≥tulos s√£o divididos em conjuntos de treino e teste.\n",
        "\n",
        "4. **Cria√ß√£o de DataFrames**:\n",
        "   - Cria DataFrames para treino e teste contendo:\n",
        "     - `features`: Dados normalizados e achatados.\n",
        "     - `label`: Classe da amostra.\n",
        "     - `prediction`: Sa√≠da do circuito qu√¢ntico.\n",
        "     - `residual`: Diferen√ßa entre previs√£o e r√≥tulo.\n",
        "\n",
        "5. **Salvamento de Resultados**:\n",
        "   - Salva os DataFrames (`train_data_quantum.csv`, `test_data_quantum.csv`) na pasta `quantum`.\n",
        "\n",
        "6. **Visualiza√ß√£o**:\n",
        "   - Exibe histogramas das previs√µes para cada classe.\n",
        "   - Mostra o circuito qu√¢ntico usado para processar algumas amostras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `train_data_quantum.csv` e `test_data_quantum.csv` contendo os resultados processados.\n",
        "\n",
        "2. **Visualiza√ß√µes**:\n",
        "   - Histogramas mostrando a distribui√ß√£o das previs√µes por classe.\n",
        "   - Circuitos desenhados para algumas amostras, mostrando as rota√ß√µes \\( RY \\) e as camadas de entanglement.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VemAfafo_VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribui√ß√£o das Previs√µes por Classe\")\n",
        "    plt.xlabel(\"Previs√£o\")\n",
        "    plt.ylabel(\"Frequ√™ncia\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar r√≥tulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simula√ß√£o de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipot√©tico para rodar o c√≥digo:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com r√≥tulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o **c√≥digo ajustado para salvar todos os resultados na pasta \"quantum\"** do Google Drive. Ele inclui as etapas de treinamento, visualiza√ß√£o e an√°lise de res√≠duos, com os resultados salvos no formato adequado.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Aumentar o n√∫mero de camadas para maior expressividade\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicializa√ß√£o de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configura√ß√£o do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustando os dados para o n√∫mero de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previs√µes\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Cria√ß√£o do DataFrame com res√≠duos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "\n",
        "# 1. Gr√°fico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(steps), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(steps), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolu√ß√£o do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gr√°fico de dispers√£o (predi√ß√£o vs r√≥tulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispers√£o: Previs√£o vs R√≥tulo\")\n",
        "plt.xlabel(\"R√≥tulo Verdadeiro\")\n",
        "plt.ylabel(\"Previs√£o\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de res√≠duos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribui√ß√£o dos Res√≠duos\")\n",
        "plt.xlabel(\"Res√≠duo\")\n",
        "plt.ylabel(\"Frequ√™ncia\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explica√ß√£o do C√≥digo\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Os resultados s√£o salvos na pasta `quantum` dentro do Google Drive.\n",
        "\n",
        "2. **Treinamento e Custo**:\n",
        "   - O modelo ajusta os pesos com base no custo m√©dio quadr√°tico, registrado para cada passo.\n",
        "\n",
        "3. **DataFrame com Resultados**:\n",
        "   - Inclui previs√µes, res√≠duos, e recursos (features) para an√°lise posterior.\n",
        "   - Salvo como `quantum_model_results.csv`.\n",
        "\n",
        "4. **Visualiza√ß√µes**:\n",
        "   - **Gr√°fico de custo**: Mostra a evolu√ß√£o do custo de treino e teste durante o treinamento.\n",
        "   - **Dispers√£o**: Indica a correspond√™ncia entre os r√≥tulos reais e as previs√µes.\n",
        "   - **Histograma de res√≠duos**: Analisa a distribui√ß√£o dos erros das previs√µes.\n",
        "\n",
        "5. **Salvamento de Gr√°ficos**:\n",
        "   - Cada gr√°fico √© salvo no Google Drive na pasta `quantum` como imagem (`.png`).\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `quantum_model_results.csv`\n",
        "   - `training_costs.png`\n",
        "   - `scatter_predictions.png`\n",
        "   - `residuals_histogram.png`\n",
        "\n",
        "2. **Insights**:\n",
        "   - **Redu√ß√£o do Custo**: A curva de custo deve diminuir ao longo das itera√ß√µes.\n",
        "   - **Rela√ß√£o Previs√£o-R√≥tulo**: Idealmente, os pontos de dispers√£o devem estar pr√≥ximos da linha \\( y = x \\).\n",
        "   - **Res√≠duos Pequenos**: Um bom modelo ter√° res√≠duos concentrados pr√≥ximos a 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "doIDRTIDAane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Aumentar o n√∫mero de camadas para maior expressividade\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Fun√ß√£o do modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicializa√ß√£o de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configura√ß√£o do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustando os dados para o n√∫mero de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previs√µes\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Cria√ß√£o do DataFrame com res√≠duos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "\n",
        "# 1. Gr√°fico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(steps), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(steps), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolu√ß√£o do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gr√°fico de dispers√£o (predi√ß√£o vs r√≥tulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispers√£o: Previs√£o vs R√≥tulo\")\n",
        "plt.xlabel(\"R√≥tulo Verdadeiro\")\n",
        "plt.ylabel(\"Previs√£o\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de res√≠duos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribui√ß√£o dos Res√≠duos\")\n",
        "plt.xlabel(\"Res√≠duo\")\n",
        "plt.ylabel(\"Frequ√™ncia\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pJzLNFF-UlyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C√≥digo Ajustado com Early Stopping, Data Augmentation, e Armazenamento no Google Drive\n",
        "\n",
        "O c√≥digo a seguir inclui:\n",
        "1. **Early Stopping**: Parar o treinamento quando a melhoria no custo for insignificante.\n",
        "2. **Data Augmentation**: Balancear os embeddings criando varia√ß√µes nos dados.\n",
        "3. **Armazenamento dos Resultados no Google Drive**: Salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Circuito\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_cost = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def check(self, current_cost):\n",
        "        if self.best_cost is None or current_cost < self.best_cost - self.delta:\n",
        "            self.best_cost = current_cost\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "# Data Augmentation\n",
        "def augment_data(X, y):\n",
        "    classes = np.unique(y)\n",
        "    max_size = max([np.sum(y == c) for c in classes])\n",
        "    X_aug, y_aug = [], []\n",
        "    for c in classes:\n",
        "        X_class = X[y == c]\n",
        "        X_resampled = resample(X_class, replace=True, n_samples=max_size, random_state=42)\n",
        "        X_aug.append(X_resampled)\n",
        "        y_aug += [c] * max_size\n",
        "    return np.vstack(X_aug), np.array(y_aug)\n",
        "\n",
        "# Dados ajustados para n√∫mero de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "y_train_aug, y_train_aug = augment_data(X_train_resized, y_train)\n",
        "\n",
        "# Treinamento\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "early_stopper = EarlyStopping(patience=5, delta=0.0001)\n",
        "train_costs, test_costs = [], []\n",
        "\n",
        "for step in range(50):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    print(f\"Step {step} | Train Cost: {train_cost:.4f} | Test Cost: {test_cost:.4f}\")\n",
        "    if early_stopper.check(train_cost):\n",
        "        print(f\"Early stopping at step {step}\")\n",
        "        break\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar resultados\n",
        "df_results.to_csv(os.path.join(output_dir, \"quantum_model_results.csv\"), index=False)\n",
        "print(\"Resultados salvos na pasta quantum.\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_costs, label=\"Train Cost\", color=\"blue\")\n",
        "plt.plot(test_costs, label=\"Test Cost\", color=\"orange\")\n",
        "plt.title(\"Training Cost with Early Stopping\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_cost.png\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, label=\"Train\", alpha=0.7, color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, label=\"Test\", alpha=0.7, color=\"orange\")\n",
        "plt.title(\"Predictions vs True Labels\")\n",
        "plt.xlabel(\"True Labels\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"predictions_scatter.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Ajustes Inclu√≠dos\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Monitora o custo de treinamento.\n",
        "   - Interrompe o treinamento se a melhoria for insignificante por v√°rias itera√ß√µes.\n",
        "\n",
        "2. **Data Augmentation**:\n",
        "   - Balanceia o conjunto de dados aumentando o n√∫mero de amostras para a classe minorit√°ria.\n",
        "\n",
        "3. **Salvamento no Google Drive**:\n",
        "   - Resultados salvos em `quantum_model_results.csv`.\n",
        "   - Gr√°ficos salvos como imagens (`.png`).\n",
        "\n",
        "---\n",
        "\n",
        "### Arquivos Gerados\n",
        "\n",
        "- `quantum_model_results.csv`: Resultados do modelo.\n",
        "- `training_cost.png`: Gr√°fico do custo.\n",
        "- `predictions_scatter.png`: Gr√°fico de dispers√£o.\n",
        "\n",
        "### Benef√≠cios\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Evita treinamento desnecess√°rio, economizando recursos.\n",
        "\n",
        "2. **Data Augmentation**:\n",
        "   - Resolve o problema de classes desbalanceadas.\n",
        "\n",
        "3. **Resultados Salvos**:\n",
        "   - Os arquivos podem ser acessados posteriormente para an√°lise."
      ],
      "metadata": {
        "id": "ztUtdHcjEZI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do dispositivo qu√¢ntico\n",
        "n_qubits = 10\n",
        "n_layers = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Fun√ß√£o de embedding qu√¢ntico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Modelo qu√¢ntico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Circuito\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_cost = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def check(self, current_cost):\n",
        "        if self.best_cost is None or current_cost < self.best_cost - self.delta:\n",
        "            self.best_cost = current_cost\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "        return self.counter >= self.patience\n",
        "\n",
        "# Data Augmentation\n",
        "def augment_data(X, y):\n",
        "    classes = np.unique(y)\n",
        "    max_size = max([np.sum(y == c) for c in classes])\n",
        "    X_aug, y_aug = [], []\n",
        "    for c in classes:\n",
        "        X_class = X[y == c]\n",
        "        X_resampled = resample(X_class, replace=True, n_samples=max_size, random_state=42)\n",
        "        X_aug.append(X_resampled)\n",
        "        y_aug += [c] * max_size\n",
        "    return np.vstack(X_aug), np.array(y_aug)\n",
        "\n",
        "# Dados ajustados para n√∫mero de qubits\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "y_train_aug, y_train_aug = augment_data(X_train_resized, y_train)\n",
        "\n",
        "# Treinamento\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "early_stopper = EarlyStopping(patience=5, delta=0.0001)\n",
        "train_costs, test_costs = [], []\n",
        "\n",
        "for step in range(50):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train)\n",
        "    test_cost = cost(weights, X_test_resized, y_test)\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    print(f\"Step {step} | Train Cost: {train_cost:.4f} | Test Cost: {test_cost:.4f}\")\n",
        "    if early_stopper.check(train_cost):\n",
        "        print(f\"Early stopping at step {step}\")\n",
        "        break\n",
        "\n",
        "# Avalia√ß√£o final\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar resultados\n",
        "df_results.to_csv(os.path.join(output_dir, \"quantum_model_results.csv\"), index=False)\n",
        "print(\"Resultados salvos na pasta quantum.\")\n",
        "\n",
        "# Visualiza√ß√µes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_costs, label=\"Train Cost\", color=\"blue\")\n",
        "plt.plot(test_costs, label=\"Test Cost\", color=\"orange\")\n",
        "plt.title(\"Training Cost with Early Stopping\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_cost.png\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, label=\"Train\", alpha=0.7, color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, label=\"Test\", alpha=0.7, color=\"orange\")\n",
        "plt.title(\"Predictions vs True Labels\")\n",
        "plt.xlabel(\"True Labels\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"predictions_scatter.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "otA1OMV__y0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:50, :n_qubits], y_train[:50]), weights)  # Usando um subset para demonstra√ß√£o\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:50, :n_qubits], y_train[:50])\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o\n",
        "test_cost = cost(weights, X_test[:50, :n_qubits], y_test[:50])\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "22JKgaL78g7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribui√ß√£o dos r√≥tulos de treinamento:\", np.unique(y_train[:50], return_counts=True))\n",
        "print(\"Distribui√ß√£o dos r√≥tulos de teste:\", np.unique(y_test[:50], return_counts=True))\n"
      ],
      "metadata": {
        "id": "LjjjZYKCAa1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado confirma que o conjunto de treinamento cont√©m apenas a classe \\( 0 \\), e a classe \\( 1 \\) est√° ausente. Isso √© um problema, pois o modelo n√£o pode aprender a diferenciar entre as classes se apenas uma delas estiver presente.\n",
        "\n",
        "### Solu√ß√µes Poss√≠veis\n",
        "1. **Verificar o Dataset Original**:\n",
        "   - Certifique-se de que o dataset original cont√©m amostras de todas as classes e que os dados foram carregados corretamente.\n",
        "\n",
        "2. **Balancear o Dataset**:\n",
        "   - Se o dataset original for desequilibrado, tente aumentar ou incluir amostras da classe \\( 1 \\) no conjunto de treinamento.\n",
        "\n",
        "3. **Ajustar a Divis√£o dos Dados**:\n",
        "   - Reavalie a divis√£o de dados em treinamento e teste para garantir que ambos contenham todas as classes.\n",
        "\n",
        "4. **C√≥digo para Checar o Dataset Original**:\n",
        "   Para verificar a distribui√ß√£o das classes no dataset completo:\n",
        "   ```python\n",
        "   print(\"Distribui√ß√£o das classes no conjunto completo:\", np.unique(y_train + y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "5. **Exemplo de Balanceamento Manual**:\n",
        "   Caso o dataset original tenha classes suficientes, voc√™ pode aumentar a classe minorit√°ria:\n",
        "   ```python\n",
        "   # Reamostrando manualmente\n",
        "   if len(class_1_indices) > 0:\n",
        "       min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "       balanced_indices = np.hstack((\n",
        "           resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "           resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "       ))\n",
        "\n",
        "       X_train_balanced = X_train[balanced_indices]\n",
        "       y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "       print(\"Distribui√ß√£o balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "   else:\n",
        "       print(\"A classe 1 n√£o est√° presente no conjunto original.\")\n",
        "   ```\n",
        "\n",
        "Se o problema persistir, voc√™ pode me informar sobre os detalhes do dataset original para que possamos ajustar o pipeline de pr√©-processamento."
      ],
      "metadata": {
        "id": "6TjjTiZXEVVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as classes presentes no conjunto de treinamento\n",
        "print(\"Distribui√ß√£o original dos r√≥tulos:\", np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Se n√£o houver dados para uma classe, adicione ou corrija a amostragem\n",
        "if len(class_1_indices) == 0:\n",
        "    print(\"A classe 1 n√£o est√° presente no conjunto de treinamento.\")\n",
        "else:\n",
        "    # Balancear os dados se ambas as classes estiverem presentes\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    # Balancear X_train e y_train\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribui√ß√£o balanceada dos r√≥tulos de treinamento:\", np.unique(y_train_balanced, return_counts=True))\n"
      ],
      "metadata": {
        "id": "ScJ3rD3IBbqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reamostrando manualmente\n",
        "if len(class_1_indices) > 0:\n",
        "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
        "    balanced_indices = np.hstack((\n",
        "        resample(class_0_indices, n_samples=min_class_size, random_state=42),\n",
        "        resample(class_1_indices, n_samples=min_class_size, random_state=42)\n",
        "    ))\n",
        "\n",
        "    X_train_balanced = X_train[balanced_indices]\n",
        "    y_train_balanced = y_train[balanced_indices]\n",
        "\n",
        "    print(\"Distribui√ß√£o balanceada:\", np.unique(y_train_balanced, return_counts=True))\n",
        "else:\n",
        "    print(\"A classe 1 n√£o est√° presente no conjunto original.\")\n"
      ],
      "metadata": {
        "id": "AWhMOjvvBo0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado indica que a classe \\( 1 \\) est√° completamente ausente no dataset, n√£o apenas no conjunto de treinamento, mas aparentemente no conjunto original carregado. Isso pode ser causado por:\n",
        "\n",
        "1. **Problemas no Dataset Original**:\n",
        "   - O dataset fornecido cont√©m apenas amostras da classe \\( 0 \\).\n",
        "2. **Erro na Organiza√ß√£o do Dataset**:\n",
        "   - Pode haver uma falha no pr√©-processamento ou na separa√ß√£o das classes.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "#### 1. Verificar o Dataset Original\n",
        "Certifique-se de que o dataset original cont√©m amostras de ambas as classes. Se houver subdiret√≥rios como \"maligno\" e \"benigno\", confirme que ambos foram processados. Use o seguinte c√≥digo para listar os diret√≥rios e a contagem de arquivos em cada um:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Listar subdiret√≥rios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diret√≥rio: {root}, N√∫mero de arquivos: {len(files)}\")\n",
        "```\n",
        "\n",
        "#### 2. Corrigir o Pipeline de Pr√©-processamento\n",
        "Caso o problema esteja na sele√ß√£o dos dados, ajuste o pipeline para incluir todas as classes. Certifique-se de que o c√≥digo est√° capturando ambas as classes:\n",
        "\n",
        "```python\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribui√ß√£o\n",
        "print(\"Distribui√ß√£o das classes no dataset completo:\", np.unique(labels, return_counts=True))\n",
        "```\n",
        "\n",
        "#### 3. Adicionar Amostras da Classe Minorit√°ria\n",
        "Se o dataset original √© desequilibrado, voc√™ pode adicionar manualmente mais amostras da classe \\( 1 \\) (maligno). Isso pode ser feito coletando mais dados ou duplicando algumas amostras existentes para balancear.\n",
        "\n",
        "Se precisar de ajuda para investigar o dataset ou ajustar o pipeline, avise!"
      ],
      "metadata": {
        "id": "HNXMMkQMEIFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar subdiret√≥rios no dataset\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    print(f\"Diret√≥rio: {root}, N√∫mero de arquivos: {len(files)}\")\n"
      ],
      "metadata": {
        "id": "lYLT1udwB0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "\n",
        "# Processar imagens de todas as classes\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "processed_images, labels = process_images(all_image_paths, image_size)\n",
        "\n",
        "# Verificar distribui√ß√£o\n",
        "print(\"Distribui√ß√£o das classes no dataset completo:\", np.unique(labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "lqaO9eMjB-63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos uma distribui√ß√£o equilibrada no dataset completo:\n",
        "\n",
        "- **500 amostras da classe \"benigno\"**.\n",
        "- **500 amostras da classe \"maligno\"**.\n",
        "\n",
        "Isso confirma que ambas as classes est√£o presentes e foram corretamente processadas. O problema anterior foi causado por um desequil√≠brio ou erro na sele√ß√£o dos dados para treinamento.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "1. **Codificar os R√≥tulos**:\n",
        "   - Converter os r√≥tulos `['benigno', 'maligno']` para valores num√©ricos \\(0\\) e \\(1\\).\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "   # Codificar os r√≥tulos\n",
        "   label_encoder = LabelEncoder()\n",
        "   encoded_labels = label_encoder.fit_transform(labels)\n",
        "   print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n",
        "   ```\n",
        "\n",
        "2. **Dividir o Dataset**:\n",
        "   - Separar os dados em conjuntos de treinamento e teste de forma balanceada.\n",
        "   \n",
        "   ```python\n",
        "   from sklearn.model_selection import train_test_split\n",
        "\n",
        "   # Dividir os dados\n",
        "   X_train, X_test, y_train, y_test = train_test_split(\n",
        "       processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "       encoded_labels,\n",
        "       test_size=0.2,\n",
        "       stratify=encoded_labels,  # Garantir balanceamento\n",
        "       random_state=42\n",
        "   )\n",
        "   print(\"Distribui√ß√£o dos r√≥tulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "   print(\"Distribui√ß√£o dos r√≥tulos no teste:\", np.unique(y_test, return_counts=True))\n",
        "   ```\n",
        "\n",
        "3. **Treinar o Modelo Qu√¢ntico**:\n",
        "   - Use os dados balanceados para treinar o modelo qu√¢ntico e avaliar o desempenho.\n",
        "\n",
        "Deseja que eu implemente essas etapas ou passe direto para o treinamento?"
      ],
      "metadata": {
        "id": "jsWIBtxtDvUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar os r√≥tulos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "print(\"Classes codificadas:\", np.unique(encoded_labels, return_counts=True))\n"
      ],
      "metadata": {
        "id": "F53QU2yYCJSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "    encoded_labels,\n",
        "    test_size=0.2,\n",
        "    stratify=encoded_labels,  # Garantir balanceamento\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Distribui√ß√£o dos r√≥tulos no treinamento:\", np.unique(y_train, return_counts=True))\n",
        "print(\"Distribui√ß√£o dos r√≥tulos no teste:\", np.unique(y_test, return_counts=True))\n"
      ],
      "metadata": {
        "id": "SbRa_3cJCTO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora o dataset est√° devidamente balanceado:\n",
        "\n",
        "- **Treinamento**: 400 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "- **Teste**: 100 amostras de cada classe (\\( 0 \\) e \\( 1 \\)).\n",
        "\n",
        "Com os dados preparados, podemos seguir para o treinamento do modelo qu√¢ntico.\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "\n",
        "1. **Treinar o Modelo Qu√¢ntico**:\n",
        "   - Ajustar os pesos do circuito para minimizar a fun√ß√£o de custo.\n",
        "   - Utilizar o conjunto de treinamento balanceado (\\( X\\_train \\) e \\( y\\_train \\)).\n",
        "\n",
        "2. **Avaliar o Modelo**:\n",
        "   - Calcular a precis√£o e a perda no conjunto de teste (\\( X\\_test \\) e \\( y\\_test \\)).\n",
        "\n",
        "### C√≥digo para Treinamento\n",
        "Aqui est√° o c√≥digo atualizado para treinar e avaliar o modelo:\n",
        "\n",
        "```python\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        c = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "        print(f\"Step {step}: Cost = {c:.4f}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo no conjunto de teste: {test_cost:.4f}\")\n",
        "```\n",
        "\n",
        "### Explica√ß√£o\n",
        "1. **Fun√ß√£o de Custo**:\n",
        "   - Calcula o erro quadr√°tico m√©dio entre a previs√£o do circuito e os r√≥tulos reais.\n",
        "2. **Otimiza√ß√£o**:\n",
        "   - Usa Adam para ajustar os pesos do circuito.\n",
        "3. **Avalia√ß√£o**:\n",
        "   - Mede o custo no conjunto de teste para verificar a generaliza√ß√£o.\n",
        "\n",
        "Deseja executar este c√≥digo ou ajustar algum par√¢metro antes de seguir?"
      ],
      "metadata": {
        "id": "JEwGaoJzDhsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configurando o otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "weights = np.random.random(weights_shape)  # Reinicializando pesos\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "# Configurando o gr√°fico\n",
        "plt.ion()  # Ativando o modo interativo\n",
        "fig, ax = plt.subplots()\n",
        "line1, = ax.plot([], [], label='Custo de Treinamento', color='blue')\n",
        "line2, = ax.plot([], [], label='Custo de Teste', color='orange')\n",
        "ax.set_xlim(0, steps)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlabel(\"Passo\")\n",
        "ax.set_ylabel(\"Custo\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Treinamento\n",
        "start_time = time.time()\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train[:, :n_qubits], y_train), weights)\n",
        "    train_cost = cost(weights, X_train[:, :n_qubits], y_train)\n",
        "    test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "\n",
        "    # Armazenar custos\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Atualizar gr√°fico\n",
        "    line1.set_data(range(step + 1), train_costs)\n",
        "    line2.set_data(range(step + 1), test_costs)\n",
        "    ax.set_ylim(0, max(train_costs + test_costs) * 1.1)  # Ajustar limites do gr√°fico dinamicamente\n",
        "    clear_output(wait=True)\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)\n",
        "\n",
        "    # Print no console\n",
        "    print(f\"Passo {step}/{steps} | Custo de Treinamento: {train_cost:.4f} | Custo de Teste: {test_cost:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Treinamento conclu√≠do em {end_time - start_time:.2f} segundos.\")\n",
        "plt.ioff()  # Desativar o modo interativo\n",
        "plt.show()\n",
        "\n",
        "# Avalia√ß√£o Final no Conjunto de Teste\n",
        "final_test_cost = cost(weights, X_test[:, :n_qubits], y_test)\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "1TylwODwCjzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes no conjunto de teste\n",
        "y_pred = [round(float(circuit(weights, x))) for x in X_test[:, :n_qubits]]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "69mk3xhTdn-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Relat√≥rio de classifica√ß√£o\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Benigno\", \"Maligno\"]))\n"
      ],
      "metadata": {
        "id": "Flu_IGkneQT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Par√¢metros iniciais para testes\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Pesos aleat√≥rios\n",
        "features = np.random.random(n_qubits)  # Exemplo de entrada\n",
        "\n",
        "# Testando o circuito\n",
        "output = circuit(weights, features)\n",
        "print(f\"Sa√≠da do circuito: {output}\")\n"
      ],
      "metadata": {
        "id": "Pmx4JWJLe0lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com o dispositivo atualizado\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    return loss / len(X)\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "weights_shape = (4, n_qubits)  # 4 camadas e 12 qubits\n",
        "weights = np.random.random(weights_shape)  # Inicializa√ß√£o dos pesos aleat√≥rios\n",
        "opt = AdamOptimizer(stepsize=0.01)  # Otimizador Adam\n",
        "steps = 50  # N√∫mero de itera√ß√µes\n",
        "\n",
        "# Dados simulados para teste\n",
        "X_train = np.random.random((100, n_qubits))  # 100 amostras, cada uma com 12 qubits\n",
        "y_train = np.random.choice([0, 1], size=100)  # R√≥tulos bin√°rios simulados\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)  # Atualizar pesos\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado final\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final ap√≥s {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "ifCUQ5oBgKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane.numpy as pnp  # Usar NumPy do PennyLane para suporte a gradientes\n",
        "\n",
        "# Configura√ß√£o dos pesos ajustada\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Otimizador com taxa de aprendizado maior\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "\n",
        "# Treinamento com ajustes\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "final_cost = cost(weights, X_train, y_train)\n",
        "print(f\"Custo final ap√≥s {steps} passos: {final_cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "lq9f9d4ioAvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes com transforma√ß√£o para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "hH-ZFY7KsgFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Previs√µes com transforma√ß√£o para -1 ou 1\n",
        "y_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "FHYzN1xKs14i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui est√° o c√≥digo ajustado com melhorias para aumentar a expressividade do circuito, regulariza√ß√£o na fun√ß√£o de custo e valida√ß√£o em dados de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### C√≥digo Ajustado\n",
        "\n",
        "```python\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo com regulariza√ß√£o L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "n_layers = 6  # Aumentar o n√∫mero de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o n√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_accuracy:.2%}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### O Que Foi Ajustado\n",
        "1. **Camadas Adicionais no Circuito**:\n",
        "   - O n√∫mero de camadas foi aumentado para 6 para maior expressividade.\n",
        "2. **Regulariza√ß√£o L2**:\n",
        "   - Adicionada regulariza√ß√£o √† fun√ß√£o de custo para melhorar a estabilidade do modelo.\n",
        "3. **Mais Itera√ß√µes**:\n",
        "   - O n√∫mero de passos foi aumentado para 100 para permitir melhor converg√™ncia.\n",
        "4. **Avalia√ß√£o no Conjunto de Teste**:\n",
        "   - Adicionado c√≥digo para calcular a acur√°cia no conjunto de teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Pr√≥ximos Passos\n",
        "1. **Execute o C√≥digo**:\n",
        "   - Observe os custos e as acur√°cias no conjunto de treinamento e teste.\n",
        "2. **Analise os Resultados**:\n",
        "   - Verifique se h√° sinais de overfitting (acur√°cia no treino muito maior que no teste).\n",
        "\n",
        "Se precisar de mais ajustes, estou √† disposi√ß√£o! üòä"
      ],
      "metadata": {
        "id": "IS2WKZ4burMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as pnp\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "\n",
        "# Configurando o dispositivo qu√¢ntico\n",
        "n_qubits = 12  # N√∫mero de qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Redefinir o circuito com mais camadas\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Fun√ß√£o de custo com regulariza√ß√£o L2\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "\n",
        "# Configura√ß√£o do treinamento\n",
        "n_layers = 6  # Aumentar o n√∫mero de camadas\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = pnp.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "opt = AdamOptimizer(stepsize=0.1)\n",
        "steps = 100  # Aumentar o n√∫mero de itera√ß√µes\n",
        "\n",
        "# Ajustar r√≥tulos para intervalo compat√≠vel\n",
        "y_train = 2 * y_train - 1  # Converte 0, 1 para -1, 1\n",
        "y_test = 2 * y_test - 1  # Converte 0, 1 para -1, 1\n",
        "\n",
        "# Treinamento\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "    if step % 10 == 0:  # Exibir progresso a cada 10 itera√ß√µes\n",
        "        current_cost = cost(weights, X_train, y_train)\n",
        "        print(f\"Passo {step}/{steps} | Custo: {current_cost:.4f}\")\n",
        "\n",
        "# Resultado no conjunto de treinamento\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Acur√°cia no conjunto de treinamento: {train_accuracy:.2%}\")\n",
        "\n",
        "# Avalia√ß√£o no conjunto de teste\n",
        "y_test_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_test]\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Acur√°cia no conjunto de teste: {test_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "aBdq7hhAtuWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O c√≥digo implementa um pipeline qu√¢ntico-cl√°ssico para classifica√ß√£o bin√°ria usando circuitos qu√¢nticos e o otimizador Adam para ajustar os par√¢metros. Aqui est√° uma explica√ß√£o detalhada do processo qu√¢ntico envolvido:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Dispositivo Qu√¢ntico**\n",
        "```python\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "```\n",
        "- **Descri√ß√£o**: Um dispositivo qu√¢ntico simulado, configurado para usar 12 qubits.\n",
        "- **Papel**: Serve como o \"computador qu√¢ntico virtual\" onde os circuitos ser√£o executados.\n",
        "- **Simula√ß√£o Cl√°ssica**: O dispositivo `default.qubit` √© um simulador baseado em estado vetorial.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Defini√ß√£o do Circuito**\n",
        "```python\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    # Embedding das features no circuito usando rota√ß√µes RY\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(features[i], wires=i)\n",
        "    # Camadas parametrizadas\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Medida no primeiro qubit\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "\n",
        "#### a. **Embedding dos Dados**\n",
        "```python\n",
        "for i in range(n_qubits):\n",
        "    qml.RY(features[i], wires=i)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Os dados cl√°ssicos (features) s√£o mapeados para estados qu√¢nticos usando rota√ß√µes \\( RY \\).\n",
        "  - Cada feature √© usada para parametrizar uma rota√ß√£o em torno do eixo \\( Y \\) para o qubit correspondente.\n",
        "- **Papel**:\n",
        "  - Cria uma representa√ß√£o qu√¢ntica dos dados.\n",
        "\n",
        "#### b. **Camadas Parametrizadas**\n",
        "```python\n",
        "qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Aplica camadas de entrela√ßamento entre os qubits, usando par√¢metros trein√°veis (\\( weights \\)).\n",
        "  - Permite que o modelo qu√¢ntico capture interdepend√™ncias complexas entre as features.\n",
        "- **Papel**:\n",
        "  - Adiciona expressividade ao circuito, permitindo que ele represente fun√ß√µes mais complexas.\n",
        "\n",
        "#### c. **Medida**\n",
        "```python\n",
        "return qml.expval(qml.PauliZ(0))\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Mede a expectativa do operador \\( Z \\) no primeiro qubit.\n",
        "  - Retorna um valor cont√≠nuo no intervalo \\([-1, 1]\\).\n",
        "- **Papel**:\n",
        "  - Converte o estado qu√¢ntico final em um valor cl√°ssico utiliz√°vel.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Fun√ß√£o de Custo**\n",
        "```python\n",
        "def cost(weights, X, y):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i])\n",
        "        loss += (pred - y[i]) ** 2  # Erro quadr√°tico\n",
        "    reg_term = 0.01 * pnp.sum(weights**2)  # Regulariza√ß√£o L2\n",
        "    return loss / len(X) + reg_term\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula o erro quadr√°tico m√©dio (\\( MSE \\)) entre as previs√µes do circuito e os r√≥tulos reais.\n",
        "  - Adiciona um termo de regulariza√ß√£o L2 para penalizar pesos altos e evitar overfitting.\n",
        "- **Papel**:\n",
        "  - Orienta o treinamento para ajustar os pesos e minimizar a discrep√¢ncia entre previs√µes e r√≥tulos.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Treinamento**\n",
        "```python\n",
        "weights = opt.step(lambda w: cost(w, X_train, y_train), weights)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - O otimizador Adam ajusta os pesos do circuito qu√¢ntico, minimizando a fun√ß√£o de custo.\n",
        "- **Papel**:\n",
        "  - Integra o aprendizado qu√¢ntico ao pipeline cl√°ssico, otimizando os par√¢metros do circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Classifica√ß√£o Bin√°ria**\n",
        "```python\n",
        "y_train_pred = [1 if float(circuit(weights, x)) >= 0 else -1 for x in X_train]\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Converte as previs√µes cont√≠nuas do circuito (\\([-1, 1]\\)) em r√≥tulos bin√°rios (\\( -1, 1 \\)) usando uma fun√ß√£o de ativa√ß√£o baseada em threshold.\n",
        "- **Papel**:\n",
        "  - Permite que o modelo fa√ßa classifica√ß√µes compat√≠veis com os r√≥tulos ajustados.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **M√©tricas de Desempenho**\n",
        "```python\n",
        "accuracy = accuracy_score(y_train, y_train_pred)\n",
        "```\n",
        "- **O que faz**:\n",
        "  - Calcula a propor√ß√£o de previs√µes corretas.\n",
        "- **Papel**:\n",
        "  - Avalia o desempenho do modelo no conjunto de treinamento e teste.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumo do Processo Qu√¢ntico\n",
        "1. **Embedding**:\n",
        "   - Os dados cl√°ssicos s√£o mapeados para estados qu√¢nticos usando rota√ß√µes \\( RY \\).\n",
        "2. **Camadas Parametrizadas**:\n",
        "   - O circuito aprende padr√µes complexos nos dados ajustando os pesos.\n",
        "3. **Medida**:\n",
        "   - A expectativa do operador \\( Z \\) no primeiro qubit traduz o estado qu√¢ntico final em um valor cl√°ssico.\n",
        "4. **Treinamento**:\n",
        "   - A fun√ß√£o de custo e o otimizador ajustam os pesos para melhorar as previs√µes.\n",
        "5. **Classifica√ß√£o**:\n",
        "   - O valor cont√≠nuo retornado pelo circuito √© transformado em r√≥tulos bin√°rios.\n",
        "\n",
        "Se precisar de mais detalhes ou ajustes no modelo, estou √† disposi√ß√£o! üòä"
      ],
      "metadata": {
        "id": "Ic9V71bYvaCY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t_RiqRv-vXW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}