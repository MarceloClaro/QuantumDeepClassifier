{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRZq/btk58AjqAgKNowW4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarceloClaro/QuantumDeepClassifier/blob/main/QuantumDeepClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explicação dos Comandos de Instalação**\n",
        "\n",
        "Os comandos listados utilizam o gerenciador de pacotes **pip** para instalar bibliotecas específicas que são usadas em computação quântica, aprendizado de máquina e visualização de dados. Abaixo, explico cada uma delas:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. `!pip install qiskit`**\n",
        "- **O que é o Qiskit?**\n",
        "  - O Qiskit é uma biblioteca de código aberto para computação quântica desenvolvida pela IBM. Ele permite:\n",
        "    - Criar, simular e executar circuitos quânticos.\n",
        "    - Realizar experimentos em computadores quânticos reais da IBM Quantum ou simuladores locais.\n",
        "    - Trabalhar com algoritmos quânticos, como **VQE**, **QAOA** e **Shor**.\n",
        "\n",
        "- **Principais Módulos do Qiskit:**\n",
        "  - **`qiskit.circuit`**: Criação de circuitos quânticos.\n",
        "  - **`qiskit.aer`**: Simulação de circuitos quânticos.\n",
        "  - **`qiskit.ibmq`**: Conexão com dispositivos quânticos reais na nuvem.\n",
        "  - **`qiskit.visualization`**: Visualização de circuitos quânticos.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver aplicações quânticas em áreas como criptografia, otimização, química e aprendizado de máquina.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `!pip install pennylane`**\n",
        "- **O que é o PennyLane?**\n",
        "  - O PennyLane é uma biblioteca de código aberto para **computação quântica diferencial**. Ele integra computação quântica com aprendizado de máquina (AM) e frameworks como PyTorch, TensorFlow e NumPy.\n",
        "\n",
        "- **Principais Recursos do PennyLane:**\n",
        "  - Suporte a **diferenciação automática**: Permite calcular gradientes de circuitos quânticos para ajustar parâmetros durante o treinamento.\n",
        "  - Compatibilidade com dispositivos quânticos reais e simuladores.\n",
        "  - Ferramentas para implementar algoritmos híbridos (quânticos e clássicos).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Criar modelos híbridos que combinam redes neurais e circuitos quânticos.\n",
        "  - Aplicar aprendizado de máquina quântico em tarefas como classificação, regressão e redução de dimensionalidade.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `!pip install tensorflow-quantum`**\n",
        "- **O que é o TensorFlow Quantum (TFQ)?**\n",
        "  - O TensorFlow Quantum é uma extensão do TensorFlow que facilita a integração de circuitos quânticos com aprendizado de máquina clássico.\n",
        "  - Ele é desenvolvido pela Google AI e permite:\n",
        "    - Construir e treinar modelos híbridos (quânticos e clássicos).\n",
        "    - Simular circuitos quânticos dentro do fluxo de trabalho do TensorFlow.\n",
        "\n",
        "- **Principais Recursos do TFQ:**\n",
        "  - **Integração com TensorFlow**: Usado com outras APIs TensorFlow, como `tf.keras` e `tf.data`.\n",
        "  - **Diferenciação automática** para parâmetros de circuitos quânticos.\n",
        "  - **Simuladores de dispositivos quânticos** otimizados para desempenho.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Desenvolver modelos híbridos para tarefas de aprendizado supervisionado, não supervisionado e reforçado.\n",
        "  - Aplicar computação quântica em AM em escala usando a infraestrutura do TensorFlow.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `!pip install matplotlib`**\n",
        "- **O que é o Matplotlib?**\n",
        "  - O Matplotlib é uma biblioteca de Python usada para criar gráficos estáticos, interativos e animados.\n",
        "\n",
        "- **Principais Recursos do Matplotlib:**\n",
        "  - Criação de gráficos de linha, dispersão, histogramas, barras e muito mais.\n",
        "  - Personalização total de estilos, rótulos, títulos e cores.\n",
        "  - Compatibilidade com notebooks interativos (Jupyter Notebook, Google Colab).\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Visualizar resultados de simulações e treinamentos de modelos quânticos e clássicos.\n",
        "  - Interpretar dados e métricas por meio de gráficos.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `!pip install pillow`**\n",
        "- **O que é o Pillow?**\n",
        "  - O Pillow (ou PIL, Python Imaging Library) é uma biblioteca de manipulação de imagens.\n",
        "\n",
        "- **Principais Recursos do Pillow:**\n",
        "  - Abrir, modificar e salvar imagens em vários formatos (JPEG, PNG, BMP, etc.).\n",
        "  - Redimensionar, cortar, converter para escala de cinza e normalizar imagens.\n",
        "  - Integrar pipelines de visão computacional.\n",
        "\n",
        "- **Para que serve?**\n",
        "  - Pré-processar dados de imagens antes de usá-los em modelos quânticos ou clássicos.\n",
        "  - Trabalhar com datasets de imagens em tarefas de classificação ou detecção de objetos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo e Propósito Geral**\n",
        "Esses pacotes combinados permitem a construção de modelos de aprendizado de máquina quânticos e híbridos. Com eles, você pode:\n",
        "1. **Simular e executar circuitos quânticos**: Usando Qiskit e PennyLane.\n",
        "2. **Integrar computação quântica e aprendizado de máquina clássico**: Com PennyLane e TensorFlow Quantum.\n",
        "3. **Pré-processar e visualizar dados**: Usando Matplotlib e Pillow.\n",
        "\n"
      ],
      "metadata": {
        "id": "JbK2j_xVL92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pennylane\n",
        "!pip install tensorflow-quantum\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "id": "rFFY-BPO5Pm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Completo para Carregar, Visualizar e Salvar as Imagens no Drive\n",
        "\n",
        "Aqui está o código ajustado para solicitar o arquivo `melanomas.zip`, organizar, visualizar as imagens das classes, e salvar os dados processados na pasta \"quantum\" no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Código Ajustado**\n",
        "\n",
        "```python\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo não encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extraídos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Número total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extraídos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Função para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padrão para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Passo a Passo do Código**\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para armazenar os dados processados.\n",
        "2. **Solicitar o Arquivo `melanomas.zip`**:\n",
        "   - O código pede ao usuário o caminho do arquivo ZIP no Drive.\n",
        "   - Exemplo: `/content/drive/My Drive/melanomas.zip`.\n",
        "3. **Extrair Imagens**:\n",
        "   - As imagens são extraídas para a pasta temporária `/content/melanomas`.\n",
        "   - Apenas arquivos com extensões `.jpg` e `.png` são incluídos.\n",
        "4. **Visualizar Imagens por Classe**:\n",
        "   - As imagens são agrupadas com base no nome das subpastas (representando as classes).\n",
        "   - As primeiras `n` imagens de cada classe são exibidas em gráficos.\n",
        "5. **Salvar Imagens no Google Drive**:\n",
        "   - As imagens são redimensionadas para 64x64 pixels.\n",
        "   - Elas são organizadas em pastas no Drive, em `My Drive/quantum/<nome_da_classe>`.\n",
        "6. **Exibir Imagens Redimensionadas**:\n",
        "   - Após salvar, as imagens redimensionadas são exibidas novamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Exemplo de Execução**\n",
        "- O código irá:\n",
        "  - Solicitar o arquivo `melanomas.zip`.\n",
        "  - Extrair e organizar as imagens por classe.\n",
        "  - Exibir as primeiras 5 imagens de cada classe.\n",
        "  - Salvar as imagens redimensionadas no Google Drive para posterior uso.\n",
        "\n"
      ],
      "metadata": {
        "id": "jFku01OHyA4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_path = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# 2. Solicitar o arquivo melanomas.zip\n",
        "zip_path = input(\"Insira o caminho do arquivo melanomas.zip no seu Google Drive: \")\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Arquivo não encontrado! Verifique o caminho e tente novamente.\")\n",
        "else:\n",
        "    # 3. Extrair o arquivo ZIP\n",
        "    extract_path = \"/content/melanomas\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # 4. Listar os arquivos extraídos\n",
        "    extracted_files = []\n",
        "    for root, dirs, files in os.walk(extract_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".jpg\", \".png\")):  # Apenas imagens\n",
        "                extracted_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Número total de imagens: {len(extracted_files)}\")\n",
        "    print(\"Exemplo de arquivos extraídos:\", extracted_files[:5])\n",
        "\n",
        "    # 5. Função para visualizar imagens por classe\n",
        "    def visualize_images(files, n=5):\n",
        "        \"\"\"Visualizar as primeiras N imagens de cada classe\"\"\"\n",
        "        classes = {}\n",
        "        for file in files:\n",
        "            class_name = os.path.basename(os.path.dirname(file))\n",
        "            if class_name not in classes:\n",
        "                classes[class_name] = []\n",
        "            classes[class_name].append(file)\n",
        "\n",
        "        for class_name, images in classes.items():\n",
        "            print(f\"Classe: {class_name} | Total de imagens: {len(images)}\")\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.suptitle(f\"Exemplos da classe: {class_name}\")\n",
        "            for i, img_path in enumerate(images[:n]):\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n, i + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.axis(\"off\")\n",
        "                plt.title(f\"{class_name} {i+1}\")\n",
        "            plt.show()\n",
        "\n",
        "    # 6. Visualizar as imagens\n",
        "    visualize_images(extracted_files, n=5)\n",
        "\n",
        "    # 7. Salvar as imagens redimensionadas no Google Drive\n",
        "    image_size = (64, 64)  # Tamanho padrão para redimensionar\n",
        "    classes = {}\n",
        "    for file in extracted_files:\n",
        "        class_name = os.path.basename(os.path.dirname(file))\n",
        "        class_path = os.path.join(output_path, class_name)\n",
        "        os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "        img = Image.open(file)\n",
        "        img_resized = img.resize(image_size)  # Redimensionar imagem\n",
        "        save_path = os.path.join(class_path, os.path.basename(file))\n",
        "        img_resized.save(save_path)\n",
        "\n",
        "        if class_name not in classes:\n",
        "            classes[class_name] = []\n",
        "        classes[class_name].append(save_path)\n",
        "\n",
        "    print(f\"Imagens redimensionadas e salvas em {output_path}\")\n",
        "\n",
        "    # 8. Mostrar exemplos das imagens redimensionadas\n",
        "    visualize_images(extracted_files, n=5)\n"
      ],
      "metadata": {
        "id": "kMS-AgHXM7eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sim, podemos ajustar o código para:\n",
        "\n",
        "1. **Visualizar a imagem original e redimensionada**.\n",
        "2. **Salvar os dados redimensionados em um DataFrame e exportá-lo para um arquivo, se necessário.**\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado para Visualização e Criação de DataFrame\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Função para processar e redimensionar imagens\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "    \n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "sample_image_path = extracted_files[0]\n",
        "processed_image = process_and_visualize_image(sample_image_path)\n",
        "\n",
        "# Criar um DataFrame com os dados redimensionados\n",
        "def create_dataframe(image_paths, resize_to=(64, 64)):\n",
        "    \"\"\"Processa imagens e cria um DataFrame com arrays normalizados\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image_resized = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image_resized).flatten() / 255.0  # Achatar a matriz\n",
        "        \n",
        "        # Obter o rótulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "    \n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "    return df\n",
        "\n",
        "# Criar o DataFrame com todas as imagens\n",
        "df = create_dataframe(extracted_files)\n",
        "\n",
        "# Visualizar parte do DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "output_path = \"processed_images.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"DataFrame salvo em: {output_path}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explicação do Código\n",
        "\n",
        "1. **Visualização da Imagem**:\n",
        "   - A função `process_and_visualize_image` exibe a imagem original e a redimensionada lado a lado.\n",
        "\n",
        "2. **Criação do DataFrame**:\n",
        "   - Cada imagem é convertida para um array 1D (achatar a matriz).\n",
        "   - Os arrays são armazenados como linhas no DataFrame, com uma coluna adicional para os rótulos das classes.\n",
        "\n",
        "3. **Exportação para CSV**:\n",
        "   - O DataFrame é salvo em um arquivo CSV (`processed_images.csv`), para ser reutilizado posteriormente.\n",
        "\n",
        "---\n",
        "\n",
        "### Resultados Esperados\n",
        "- Você verá a imagem original e redimensionada para confirmar o processo de redimensionamento.\n",
        "- O DataFrame conterá os dados de todas as imagens redimensionadas e seus rótulos de classe.\n",
        "- O arquivo CSV permitirá reutilizar os dados sem necessidade de processar as imagens novamente.\n",
        "\n",
        "Teste o código e informe se precisar de mais ajustes! 😊"
      ],
      "metadata": {
        "id": "6PgjAaxZyotH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Função para processar e visualizar uma única imagem\n",
        "def process_and_visualize_image(image_path, resize_to=(64, 64)):\n",
        "    \"\"\"Processa a imagem, redimensiona e visualiza\"\"\"\n",
        "    # Abrir a imagem\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Redimensionar a imagem\n",
        "    image_resized = image.resize(resize_to)\n",
        "\n",
        "    # Converter para array normalizado\n",
        "    image_array = np.array(image_resized) / 255.0\n",
        "\n",
        "    # Visualizar a imagem original e redimensionada\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Imagem Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(image_resized)\n",
        "    plt.title(f\"Imagem Redimensionada {resize_to}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    return image_array\n",
        "\n",
        "# Exemplo com a primeira imagem\n",
        "if len(extracted_files) > 0:\n",
        "    sample_image_path = extracted_files[0]\n",
        "    processed_image = process_and_visualize_image(sample_image_path)\n",
        "else:\n",
        "    print(\"Nenhuma imagem foi encontrada para processamento.\")\n",
        "\n",
        "# Função para processar todas as imagens e criar um DataFrame\n",
        "def create_dataframe_and_save_images(image_paths, resize_to=(64, 64), save_dir=output_dir):\n",
        "    \"\"\"Processa imagens, cria um DataFrame e salva imagens redimensionadas\"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for image_path in image_paths:\n",
        "        # Processar a imagem\n",
        "        image = Image.open(image_path).resize(resize_to)\n",
        "        image_array = np.array(image).flatten() / 255.0  # Achatar a matriz\n",
        "\n",
        "        # Obter o rótulo da classe\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        data.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Criar o DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame na pasta \"quantum\"\n",
        "    df_output_path = os.path.join(save_dir, \"processed_images.csv\")\n",
        "    df.to_csv(df_output_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {df_output_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar imagens e salvar no Google Drive\n",
        "if len(extracted_files) > 0:\n",
        "    df = create_dataframe_and_save_images(extracted_files)\n",
        "    print(\"Primeiras linhas do DataFrame:\")\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"Nenhuma imagem encontrada para criar o DataFrame.\")\n"
      ],
      "metadata": {
        "id": "aw1NqaInzH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Ajustado para Visualizar, Normalizar Imagens e Salvar no Drive\n",
        "\n",
        "Este é o código modificado para salvar o DataFrame e imagens no Google Drive dentro da pasta \"quantum\". Ele processa as imagens, exibe as visualizações necessárias, cria um DataFrame e salva os resultados.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Função para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "    \n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "        \n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normalização\n",
        "        \n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "        \n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "        \n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diretório\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualização e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Função para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "    \n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explicação do Código**\n",
        "\n",
        "1. **Montar o Google Drive**:\n",
        "   - Monta o Google Drive no Colab para salvar os arquivos na pasta \"quantum\".\n",
        "\n",
        "2. **Visualização e Processamento das Imagens**:\n",
        "   - Processa as imagens para redimensioná-las a um tamanho padrão de \\(64 \\times 64\\).\n",
        "   - Normaliza os valores dos pixels para o intervalo \\([0, 1]\\).\n",
        "   - Exibe as imagens originais e redimensionadas lado a lado.\n",
        "\n",
        "3. **Salvar Imagens Processadas**:\n",
        "   - As imagens redimensionadas são salvas na pasta \"quantum\", organizadas por subpastas das classes.\n",
        "\n",
        "4. **Criação do DataFrame**:\n",
        "   - Cria um DataFrame com:\n",
        "     - Vetores achatados das imagens (uma linha por imagem).\n",
        "     - Rótulos das classes como uma coluna separada.\n",
        "   - Salva o DataFrame no formato CSV na pasta \"quantum\".\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualização de Imagens**:\n",
        "   - As imagens originais e redimensionadas são exibidas no Colab.\n",
        "\n",
        "2. **Pasta `quantum` no Drive**:\n",
        "   - Contém subpastas para cada classe, com as imagens redimensionadas salvas.\n",
        "   - Um arquivo `processed_images_with_labels.csv` com os arrays das imagens e os rótulos.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - Um DataFrame com as imagens processadas e normalizadas, incluindo os rótulos.\n",
        "\n"
      ],
      "metadata": {
        "id": "me-sYB307FFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Caminho das pastas para cada classe\n",
        "class_dirs = [os.path.join(extract_path, \"benigno\"), os.path.join(extract_path, \"maligno\")]\n",
        "image_size = (64, 64)\n",
        "\n",
        "# Função para processar, visualizar e salvar imagens\n",
        "def process_images_with_visualization_and_save(image_paths, image_size, n_visualizations=5, save_dir=output_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    visualized = 0  # Contador de imagens visualizadas\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        # Identificar a classe a partir do caminho\n",
        "        label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "        # Abrir, redimensionar e normalizar a imagem\n",
        "        image = Image.open(image_path)\n",
        "        image_resized = image.resize(image_size)\n",
        "        image_array = np.array(image_resized) / 255.0  # Normalização\n",
        "\n",
        "        # Salvar imagem redimensionada na pasta \"quantum\"\n",
        "        class_dir = os.path.join(save_dir, label)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        image_save_path = os.path.join(class_dir, os.path.basename(image_path))\n",
        "        image_resized.save(image_save_path)\n",
        "\n",
        "        # Adicionar ao dataset\n",
        "        images.append(image_array)\n",
        "        labels.append(label)\n",
        "\n",
        "        # Visualizar algumas imagens\n",
        "        if visualized < n_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image)\n",
        "            plt.title(\"Original\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(image_resized)\n",
        "            plt.title(f\"Redimensionada ({image_size}) e Normalizada\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            print(f\"Array Normalizado ({image_array.shape}):\")\n",
        "            print(image_array[:5, :5, 0])  # Mostrar parte da matriz normalizada\n",
        "            visualized += 1\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Coletar todas as imagens do diretório\n",
        "all_image_paths = [img for class_dir in class_dirs for img in glob.glob(f\"{class_dir}/*.jpg\")]\n",
        "\n",
        "# Processar imagens com visualização e salvar\n",
        "processed_images, labels = process_images_with_visualization_and_save(all_image_paths, image_size)\n",
        "\n",
        "# Função para criar e salvar o DataFrame\n",
        "def create_dataframe_and_save(images, labels, save_path):\n",
        "    flattened_images = [img.flatten() for img in images]  # Achatar as imagens\n",
        "    df = pd.DataFrame(flattened_images)\n",
        "    df['label'] = labels\n",
        "\n",
        "    # Salvar o DataFrame no caminho especificado\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"DataFrame salvo em: {save_path}\")\n",
        "    return df\n",
        "\n",
        "# Criar e salvar o DataFrame\n",
        "df_output_path = os.path.join(output_dir, \"processed_images_with_labels.csv\")\n",
        "df = create_dataframe_and_save(processed_images, labels, df_output_path)\n",
        "\n",
        "# Visualizar o DataFrame\n",
        "print(\"Amostra do DataFrame:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "rk1TQzrJ6HJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado para salvar na pasta `quantum` no Google Drive e incluir todas as funcionalidades mencionadas: visualização, normalização, divisão dos dados e salvamento em DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo rótulos de texto para valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualização de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar rótulo numérico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os rótulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os rótulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Este Código Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Monta o Google Drive para salvar os arquivos na pasta `quantum`.\n",
        "\n",
        "2. **Processamento de Rótulos e Dados**:\n",
        "   - Converte rótulos textuais em valores numéricos usando `LabelEncoder`.\n",
        "   - Redimensiona e achata as imagens processadas para vetores 1D.\n",
        "\n",
        "3. **Divisão de Dados**:\n",
        "   - Divide os dados em conjuntos de treino e teste usando `train_test_split`.\n",
        "\n",
        "4. **Visualização**:\n",
        "   - Exibe algumas imagens do conjunto de treino com seus rótulos decodificados.\n",
        "   - Mostra parte das matrizes normalizadas de cada imagem.\n",
        "\n",
        "5. **Criação de DataFrames**:\n",
        "   - Cria DataFrames para os conjuntos de treino e teste.\n",
        "   - Adiciona os rótulos decodificados como uma coluna.\n",
        "\n",
        "6. **Salvamento**:\n",
        "   - Salva os DataFrames como arquivos CSV (`train_data.csv` e `test_data.csv`) na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Visualizações**:\n",
        "   - Exibição de 5 imagens do conjunto de treino com seus rótulos decodificados.\n",
        "   - Matrizes normalizadas das imagens para análise.\n",
        "\n",
        "2. **Arquivos CSV**:\n",
        "   - Arquivos `train_data.csv` e `test_data.csv` contendo os dados processados e os rótulos, salvos na pasta `quantum`.\n",
        "\n",
        "3. **Exemplo de DataFrame**:\n",
        "   - DataFrames contendo:\n",
        "     - Colunas com os valores achatados dos pixels.\n",
        "     - Coluna `label` com os rótulos das imagens.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TROm3P5W8Isd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convertendo rótulos de texto para valores numéricos\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Transformando imagens em vetores unidimensionais\n",
        "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualização de amostras do conjunto de treino\n",
        "def visualize_data_split(X, y, label_encoder, n=5):\n",
        "    \"\"\"Visualiza algumas imagens do conjunto de treino ou teste\"\"\"\n",
        "    for i in range(n):\n",
        "        image = X[i].reshape(64, 64, 3)  # Restaurar formato original\n",
        "        label = label_encoder.inverse_transform([y[i]])[0]  # Decodificar rótulo numérico para texto\n",
        "        plt.imshow(image)\n",
        "        plt.title(f\"Classe: {label}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(f\"Matriz Normalizada (amostra {i+1}):\")\n",
        "        print(image[:5, :5, 0])  # Exibe uma parte da matriz normalizada\n",
        "\n",
        "# Visualizar amostras do conjunto de treino\n",
        "print(\"Amostras do conjunto de treino:\")\n",
        "visualize_data_split(X_train, y_train, label_encoder, n=5)\n",
        "\n",
        "# Criar DataFrame com os dados de treino e teste\n",
        "def create_dataframe(X, y, label_encoder):\n",
        "    \"\"\"Cria um DataFrame com as imagens achatadas e os rótulos\"\"\"\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = label_encoder.inverse_transform(y)  # Adicionar os rótulos decodificados\n",
        "    return df\n",
        "\n",
        "# Criar DataFrames para treino e teste\n",
        "train_df = create_dataframe(X_train, y_train, label_encoder)\n",
        "test_df = create_dataframe(X_test, y_test, label_encoder)\n",
        "\n",
        "# Salvar os DataFrames em arquivos CSV na pasta quantum\n",
        "train_csv_path = os.path.join(output_dir, \"train_data.csv\")\n",
        "test_csv_path = os.path.join(output_dir, \"test_data.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv_path, index=False)\n",
        "test_df.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame de treino salvo em: {train_csv_path}\")\n",
        "print(f\"DataFrame de teste salvo em: {test_csv_path}\")\n",
        "\n",
        "# Exibir amostras dos DataFrames\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"Amostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "DPVnmGLZ69_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado para salvar os resultados no Google Drive na pasta **quantum**, com todas as explicações e etapas necessárias para análise e visualização avançada:\n",
        "\n",
        "---\n",
        "\n",
        "### Código Ajustado\n",
        "\n",
        "```python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribuição das Previsões por Classe\")\n",
        "    plt.xlabel(\"Previsão\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar rótulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simulação de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipotético para rodar o código:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com rótulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **O Que Esse Código Faz**\n",
        "\n",
        "1. **Montagem do Google Drive**:\n",
        "   - Salva os arquivos na pasta `quantum` no Google Drive.\n",
        "\n",
        "2. **Processamento Quântico**:\n",
        "   - Cada amostra de imagem é normalizada, redimensionada e processada por um circuito quântico.\n",
        "   - O circuito aplica rotações \\( RY \\) para incorporar os dados e usa camadas de entanglement para capturar correlações.\n",
        "\n",
        "3. **Divisão de Dados**:\n",
        "   - As imagens e os rótulos são divididos em conjuntos de treino e teste.\n",
        "\n",
        "4. **Criação de DataFrames**:\n",
        "   - Cria DataFrames para treino e teste contendo:\n",
        "     - `features`: Dados normalizados e achatados.\n",
        "     - `label`: Classe da amostra.\n",
        "     - `prediction`: Saída do circuito quântico.\n",
        "     - `residual`: Diferença entre previsão e rótulo.\n",
        "\n",
        "5. **Salvamento de Resultados**:\n",
        "   - Salva os DataFrames (`train_data_quantum.csv`, `test_data_quantum.csv`) na pasta `quantum`.\n",
        "\n",
        "6. **Visualização**:\n",
        "   - Exibe histogramas das previsões para cada classe.\n",
        "   - Mostra o circuito quântico usado para processar algumas amostras.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "\n",
        "1. **Arquivos Salvos**:\n",
        "   - `train_data_quantum.csv` e `test_data_quantum.csv` contendo os resultados processados.\n",
        "\n",
        "2. **Visualizações**:\n",
        "   - Histogramas mostrando a distribuição das previsões por classe.\n",
        "   - Circuitos desenhados para algumas amostras, mostrando as rotações \\( RY \\) e as camadas de entanglement.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VemAfafo_VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pennylane as qml\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico\n",
        "def data_embedding(features, wires):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i], wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features):\n",
        "    data_embedding(features, range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode com Pennylane\n",
        "n_layers = 4\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features):\n",
        "    return quantum_model(weights, features)\n",
        "\n",
        "# Processamento das amostras\n",
        "def process_samples(X, y, n_qubits, weights):\n",
        "    data = []\n",
        "    for i in range(len(X)):\n",
        "        features = X[i][:n_qubits]\n",
        "        features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "        prediction = float(circuit(weights, features))\n",
        "        residual = prediction - y[i]\n",
        "        data.append({\"features\": features.tolist(), \"label\": y[i], \"prediction\": prediction, \"residual\": residual})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Visualizar e salvar histogramas\n",
        "def plot_histograms(df, output_dir):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for label in df['label'].unique():\n",
        "        subset = df[df['label'] == label]\n",
        "        plt.hist(subset['prediction'], bins=20, alpha=0.7, label=f\"Classe {label}\")\n",
        "    plt.title(\"Distribuição das Previsões por Classe\")\n",
        "    plt.xlabel(\"Previsão\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, \"histogram_predictions.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar circuitos\n",
        "def plot_circuits(X, y, n_samples=2):\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)[0][:n_samples]\n",
        "        for idx in indices:\n",
        "            features = X[idx][:n_qubits]\n",
        "            features = np.pad(features, (0, n_qubits - len(features))) if len(features) < n_qubits else features[:n_qubits]\n",
        "            print(f\"Circuito para a amostra {idx} (Classe {label}):\")\n",
        "            drawer = qml.draw(circuit)(weights, features)\n",
        "            print(drawer)\n",
        "            print()\n",
        "\n",
        "# Dividir os dados e criar DataFrames\n",
        "def create_train_test_data(processed_images, labels, n_qubits):\n",
        "    # Codificar rótulos\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Flatten imagens e dividir em treino/teste\n",
        "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(flattened_images, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Criar DataFrames\n",
        "    train_df = process_samples(X_train, y_train, n_qubits, weights)\n",
        "    test_df = process_samples(X_test, y_test, n_qubits, weights)\n",
        "\n",
        "    # Salvar DataFrames no Google Drive\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train_data_quantum.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(output_dir, \"test_data_quantum.csv\"), index=False)\n",
        "    print(f\"DataFrames salvos na pasta 'quantum':\")\n",
        "    print(\"- train_data_quantum.csv\")\n",
        "    print(\"- test_data_quantum.csv\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Simulação de processamento (substitua processed_images e labels pelos dados reais)\n",
        "# Exemplo hipotético para rodar o código:\n",
        "processed_images = np.random.random((100, 64, 64, 3))  # Substitua com imagens reais\n",
        "labels = np.random.choice([\"benigno\", \"maligno\"], size=100)  # Substitua com rótulos reais\n",
        "\n",
        "# Criar os DataFrames\n",
        "train_df, test_df = create_train_test_data(processed_images, labels, n_qubits)\n",
        "\n",
        "# Exibir amostras e histogramas\n",
        "print(\"Amostra do DataFrame de treino:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nAmostra do DataFrame de teste:\")\n",
        "print(test_df.head())\n",
        "plot_histograms(train_df, output_dir)\n",
        "\n",
        "# Visualizar circuitos para algumas amostras\n",
        "plot_circuits(processed_images, labels)\n"
      ],
      "metadata": {
        "id": "Sd73-igo7OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está o código ajustado que inclui **Early Stopping** e **parametrização dos embeddings** para um melhor equilíbrio durante o treinamento e avaliação do modelo quântico, salvando todos os resultados na pasta `quantum` no Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "### **Código com Early Stopping e Parametrização**\n",
        "\n",
        "```python\n",
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Camadas do modelo quântico\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico parametrizada\n",
        "def data_embedding(features, wires, scale=1.0):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i] * scale, wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features, scale=1.0):\n",
        "    data_embedding(features, range(n_qubits), scale)\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features, scale=1.0):\n",
        "    return quantum_model(weights, features, scale)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y, scale=1.0):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i], scale)\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicialização de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configuração do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # Número de iterações\n",
        "early_stopping_patience = 10  # Critério de Early Stopping\n",
        "min_delta = 1e-4  # Tolerância mínima para melhoria no custo\n",
        "\n",
        "# Dados ajustados\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Variáveis para Early Stopping\n",
        "best_weights = None\n",
        "best_test_cost = float('inf')\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train, scale=1.0), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "    test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "    \n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "    \n",
        "    # Early Stopping\n",
        "    if test_cost < best_test_cost - min_delta:\n",
        "        best_test_cost = test_cost\n",
        "        best_weights = weights\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "    \n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Parada antecipada no passo {step}. Melhor custo no teste: {best_test_cost:.4f}\")\n",
        "        break\n",
        "    \n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Usar os melhores pesos encontrados\n",
        "weights = best_weights\n",
        "\n",
        "# Avaliação final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previsões\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Criação do DataFrame com resíduos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualizações\n",
        "\n",
        "# 1. Gráfico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(len(train_costs)), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(len(test_costs)), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolução do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gráfico de dispersão (predição vs rótulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispersão: Previsão vs Rótulo\")\n",
        "plt.xlabel(\"Rótulo Verdadeiro\")\n",
        "plt.ylabel(\"Previsão\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de resíduos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribuição dos Resíduos\")\n",
        "plt.xlabel(\"Resíduo\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explicações Adicionais**\n",
        "\n",
        "1. **Early Stopping**:\n",
        "   - Interrompe o treinamento se não houver melhoria significativa no custo do conjunto de teste por um número definido de iterações (`early_stopping_patience`).\n",
        "\n",
        "2. **Parametrização dos Embeddings**:\n",
        "   - Permite ajustar o impacto dos valores de entrada nos qubits, usando o parâmetro `scale`.\n",
        "\n",
        "3. **Resultados Salvos**:\n",
        "   - Arquivo `quantum_model_results.csv` com previsões, resíduos e features.\n",
        "   - Gráficos salvos na pasta `quantum`:\n",
        "     - `training_costs.png`\n",
        "     - `scatter_predictions.png`\n",
        "     - `residuals_histogram.png`\n",
        "\n"
      ],
      "metadata": {
        "id": "ztUtdHcjEZI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código em execução combina **aprendizado quântico** e **otimização clássica** para treinar um modelo quântico, salvando os resultados e visualizações no Google Drive, dentro da pasta `quantum`. Aqui está o que ocorre em cada etapa e o que esperar dos resultados:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Configuração do Ambiente**\n",
        "- Monta o Google Drive e cria a pasta `quantum` para armazenar os resultados.\n",
        "- Configura o dispositivo quântico `default.qubit` com 10 qubits e 4 camadas no circuito.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Embedding Quântico**\n",
        "- Converte os dados clássicos (`features`) em rotações \\( RY \\), mapeando-os para o espaço quântico.\n",
        "- O parâmetro `scale` ajusta a amplitude das rotações, permitindo balancear a influência dos dados.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Modelo e Circuito**\n",
        "- **Camadas Entangled**:\n",
        "  - Introduzem correlações quânticas entre os qubits, aumentando a capacidade do modelo.\n",
        "- **Expectativa \\( \\langle Z \\rangle \\)**:\n",
        "  - Mede a projeção dos estados quânticos no eixo \\( Z \\), gerando uma saída contínua para cada entrada.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Função de Custo**\n",
        "- Calcula o **Erro Quadrático Médio (MSE)** entre as previsões e os rótulos verdadeiros.\n",
        "- É usado pelo otimizador para ajustar os pesos do modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Otimização com Early Stopping**\n",
        "- **AdamOptimizer**:\n",
        "  - Atualiza os pesos do circuito para minimizar o custo.\n",
        "- **Early Stopping**:\n",
        "  - Monitora o custo no conjunto de teste.\n",
        "  - Para o treinamento se não houver melhoria após 10 iterações consecutivas (definido por `early_stopping_patience`).\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Avaliação**\n",
        "- Após o treinamento, calcula o custo final para os conjuntos de treino e teste.\n",
        "- Usa os pesos ajustados para gerar previsões para ambos os conjuntos.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Resultados no DataFrame**\n",
        "- O `df_results` inclui:\n",
        "  - **`train_features`** e **`test_features`**: Dados de entrada (após redimensionamento).\n",
        "  - **`train_labels`** e **`test_labels`**: Rótulos verdadeiros.\n",
        "  - **`train_predictions`** e **`test_predictions`**: Previsões do modelo.\n",
        "  - **`train_residuals`** e **`test_residuals`**: Diferença entre previsão e rótulo verdadeiro (erros).\n",
        "- Salva o DataFrame como `quantum_model_results.csv` na pasta `quantum`.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Visualizações**\n",
        "#### **Gráfico de Custo**\n",
        "- Mostra a evolução do custo durante o treinamento.\n",
        "- **Azul**: Custo no conjunto de treino.\n",
        "- **Laranja**: Custo no conjunto de teste.\n",
        "  \n",
        "#### **Gráfico de Dispersão**\n",
        "- Compara previsões e rótulos verdadeiros.\n",
        "- Padrão esperado:\n",
        "  - Pontos próximos à linha \\( y = x \\) indicam previsões precisas.\n",
        "\n",
        "#### **Histograma de Resíduos**\n",
        "- Mostra a distribuição dos erros (previsão - rótulo).\n",
        "- Resíduos próximos de zero indicam um bom ajuste.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados Esperados**\n",
        "1. **Treinamento**:\n",
        "   - Redução do custo nos conjuntos de treino e teste ao longo das iterações.\n",
        "   - Early Stopping pode ocorrer se o custo no teste estabilizar.\n",
        "\n",
        "2. **Visualizações**:\n",
        "   - Gráficos salvos na pasta `quantum`:\n",
        "     - `training_costs.png`: Evolução do custo.\n",
        "     - `scatter_predictions.png`: Dispersão previsão vs rótulo.\n",
        "     - `residuals_histogram.png`: Distribuição dos resíduos.\n",
        "\n",
        "3. **Arquivo CSV**:\n",
        "   - **`quantum_model_results.csv`**: Contém previsões, resíduos e features, permitindo análise detalhada.\n",
        "\n",
        "Se o processamento ainda está em andamento, aguarde os gráficos e o arquivo `quantum_model_results.csv` no Drive para validação dos resultados. 😊"
      ],
      "metadata": {
        "id": "B9b2wMTMYqrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive e criar a pasta 'quantum'\n",
        "drive.mount('/content/drive')\n",
        "output_dir = \"/content/drive/My Drive/quantum\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuração do dispositivo quântico\n",
        "n_qubits = 10\n",
        "n_layers = 4  # Camadas do modelo quântico\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# Função de embedding quântico parametrizada\n",
        "def data_embedding(features, wires, scale=1.0):\n",
        "    for i, wire in enumerate(wires):\n",
        "        qml.RY(features[i] * scale, wires=wire)\n",
        "\n",
        "# Função do modelo quântico\n",
        "def quantum_model(weights, features, scale=1.0):\n",
        "    data_embedding(features, range(n_qubits), scale)\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode\n",
        "weights_shape = (n_layers, n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, features, scale=1.0):\n",
        "    return quantum_model(weights, features, scale)\n",
        "\n",
        "# Função de custo\n",
        "def cost(weights, X, y, scale=1.0):\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "        pred = circuit(weights, X[i], scale)\n",
        "        loss += (pred - y[i])**2\n",
        "    return loss / len(X)\n",
        "\n",
        "# Inicialização de pesos\n",
        "weights = np.random.uniform(low=-0.1, high=0.1, size=weights_shape, requires_grad=True)\n",
        "\n",
        "# Configuração do otimizador\n",
        "opt = AdamOptimizer(stepsize=0.01)\n",
        "steps = 100  # Número de iterações\n",
        "early_stopping_patience = 10  # Critério de Early Stopping\n",
        "min_delta = 1e-4  # Tolerância mínima para melhoria no custo\n",
        "\n",
        "# Dados ajustados\n",
        "X_train_resized = X_train[:, :n_qubits]\n",
        "X_test_resized = X_test[:, :n_qubits]\n",
        "\n",
        "# Variáveis para Early Stopping\n",
        "best_weights = None\n",
        "best_test_cost = float('inf')\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Treinamento\n",
        "train_costs = []\n",
        "test_costs = []\n",
        "\n",
        "for step in range(steps):\n",
        "    weights = opt.step(lambda w: cost(w, X_train_resized, y_train, scale=1.0), weights)\n",
        "    train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "    test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "\n",
        "    train_costs.append(train_cost)\n",
        "    test_costs.append(test_cost)\n",
        "\n",
        "    # Early Stopping\n",
        "    if test_cost < best_test_cost - min_delta:\n",
        "        best_test_cost = test_cost\n",
        "        best_weights = weights\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(f\"Parada antecipada no passo {step}. Melhor custo no teste: {best_test_cost:.4f}\")\n",
        "        break\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}/{steps}: Train Cost = {train_cost:.4f} | Test Cost = {test_cost:.4f}\")\n",
        "\n",
        "# Usar os melhores pesos encontrados\n",
        "weights = best_weights\n",
        "\n",
        "# Avaliação final\n",
        "final_train_cost = cost(weights, X_train_resized, y_train, scale=1.0)\n",
        "final_test_cost = cost(weights, X_test_resized, y_test, scale=1.0)\n",
        "print(f\"Custo final no conjunto de treino: {final_train_cost:.4f}\")\n",
        "print(f\"Custo final no conjunto de teste: {final_test_cost:.4f}\")\n",
        "\n",
        "# Previsões\n",
        "y_train_pred = [float(circuit(weights, x)) for x in X_train_resized]\n",
        "y_test_pred = [float(circuit(weights, x)) for x in X_test_resized]\n",
        "\n",
        "# Criação do DataFrame com resíduos\n",
        "df_results = pd.DataFrame({\n",
        "    \"train_features\": [x.tolist() for x in X_train_resized],\n",
        "    \"train_labels\": y_train,\n",
        "    \"train_predictions\": y_train_pred,\n",
        "    \"train_residuals\": [pred - y for pred, y in zip(y_train_pred, y_train)],\n",
        "    \"test_features\": [x.tolist() for x in X_test_resized],\n",
        "    \"test_labels\": y_test,\n",
        "    \"test_predictions\": y_test_pred,\n",
        "    \"test_residuals\": [pred - y for pred, y in zip(y_test_pred, y_test)]\n",
        "})\n",
        "\n",
        "# Salvar os resultados no Google Drive\n",
        "results_path = os.path.join(output_dir, \"quantum_model_results.csv\")\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados salvos no arquivo: {results_path}\")\n",
        "\n",
        "# Visualizações\n",
        "\n",
        "# 1. Gráfico de custo durante o treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(len(train_costs)), train_costs, label=\"Custo de Treinamento\", color=\"blue\")\n",
        "plt.plot(range(len(test_costs)), test_costs, label=\"Custo de Teste\", color=\"orange\")\n",
        "plt.title(\"Evolução do Custo Durante o Treinamento\")\n",
        "plt.xlabel(\"Passos\")\n",
        "plt.ylabel(\"Custo\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"training_costs.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 2. Gráfico de dispersão (predição vs rótulo)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_train_pred, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Dispersão: Previsão vs Rótulo\")\n",
        "plt.xlabel(\"Rótulo Verdadeiro\")\n",
        "plt.ylabel(\"Previsão\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"scatter_predictions.png\"))\n",
        "plt.show()\n",
        "\n",
        "# 3. Histograma de resíduos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_results[\"train_residuals\"], bins=20, alpha=0.7, label=\"Treino\", color=\"blue\")\n",
        "plt.hist(df_results[\"test_residuals\"], bins=20, alpha=0.7, label=\"Teste\", color=\"orange\")\n",
        "plt.title(\"Distribuição dos Resíduos\")\n",
        "plt.xlabel(\"Resíduo\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(output_dir, \"residuals_histogram.png\"))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MTG1MV9QDpw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}